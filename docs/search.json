[
  {
    "objectID": "template_qmds/26-pvalues-discussion-notes.html",
    "href": "template_qmds/26-pvalues-discussion-notes.html",
    "title": "P-value Discussion (Notes)",
    "section": "",
    "text": "In this activity, you will read an article about p-values and then discuss a set of prompts as a group. Each group will then share out some highlights of your discussion to the class.\n\n\nYour instructor will assign you to one of four groups, each with a different reading to complete ahead of class time. You are of course welcome to read more than only your assigned reading if you choose to! The group reading assignments are as follows:\n\nGroup 1: The ASA Statement on p-values\nGroup 2: Scientific method: Statistical error\nGroup 3: Moving to a World Beyond “p &lt; 0.05”\nGroup 4: Statistical tests, p-values, confidence intervals, and power: a guide to misinterpretations"
  },
  {
    "objectID": "template_qmds/26-pvalues-discussion-notes.html#readings-and-videos",
    "href": "template_qmds/26-pvalues-discussion-notes.html#readings-and-videos",
    "title": "P-value Discussion (Notes)",
    "section": "",
    "text": "Your instructor will assign you to one of four groups, each with a different reading to complete ahead of class time. You are of course welcome to read more than only your assigned reading if you choose to! The group reading assignments are as follows:\n\nGroup 1: The ASA Statement on p-values\nGroup 2: Scientific method: Statistical error\nGroup 3: Moving to a World Beyond “p &lt; 0.05”\nGroup 4: Statistical tests, p-values, confidence intervals, and power: a guide to misinterpretations"
  },
  {
    "objectID": "template_qmds/26-pvalues-discussion-notes.html#step-1-review",
    "href": "template_qmds/26-pvalues-discussion-notes.html#step-1-review",
    "title": "P-value Discussion (Notes)",
    "section": "Step 1: Review",
    "text": "Step 1: Review\nTake a few minutes to review the assigned reading. Make note of the things you found most important, the things you found most confusing, or the things you still have questions about."
  },
  {
    "objectID": "template_qmds/26-pvalues-discussion-notes.html#step-2-discuss",
    "href": "template_qmds/26-pvalues-discussion-notes.html#step-2-discuss",
    "title": "P-value Discussion (Notes)",
    "section": "Step 2: Discuss",
    "text": "Step 2: Discuss\nOnce everyone in your group is ready, find an empty space at the whiteboard.\nYou’ll discuss the following questions with your group and write down your key takeaways from your conversation on the board. After a few minutes, rotate to the next station: respond/react to the previous responses (e.g., add a + if you agree) and add your own. Repeat until you’ve visited all stations.\nQuestions:\n\nHow does this reading relate to your previous knowledge about p-values?\nWas anything that you learned from the reading particularly surprising?\nWhat are some of the ways in which p-values are often misinterpreted and/or misused?\nWhat suggestions does the article offer in terms of how p-values should be used?\nDoes the article provide any suggestions in terms of other tools that we should use instead of or in addition to p-values?\nWhat are your main takeaways from the reading?"
  },
  {
    "objectID": "template_qmds/26-pvalues-discussion-notes.html#step-3-share-out",
    "href": "template_qmds/26-pvalues-discussion-notes.html#step-3-share-out",
    "title": "P-value Discussion (Notes)",
    "section": "Step 3: Share out",
    "text": "Step 3: Share out\nDesignate someone from your group who will share the highlights of your discussion with the full class!"
  },
  {
    "objectID": "template_qmds/26-pvalues-discussion-notes.html#done",
    "href": "template_qmds/26-pvalues-discussion-notes.html#done",
    "title": "P-value Discussion (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/24-hypothesis-testing-considerations-notes.html",
    "href": "template_qmds/24-hypothesis-testing-considerations-notes.html",
    "title": "Hypothesis testing: additional considerations (Notes)",
    "section": "",
    "text": "No template file today - all exercises can be viewed from the webpage\n\n\n\nBy the end of this lesson, you should be able to:\n\nDifferentiate between more and less accurate interpretations of p-values\nExplain how different factors affect statistical power\nExplain the difference between practical and statistical significance\nExplain how multiple testing impacts the conduct and interpretation of statistical research\n\n\n\n\nNo new readings or videos for today."
  },
  {
    "objectID": "template_qmds/24-hypothesis-testing-considerations-notes.html#learning-goals",
    "href": "template_qmds/24-hypothesis-testing-considerations-notes.html#learning-goals",
    "title": "Hypothesis testing: additional considerations (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDifferentiate between more and less accurate interpretations of p-values\nExplain how different factors affect statistical power\nExplain the difference between practical and statistical significance\nExplain how multiple testing impacts the conduct and interpretation of statistical research"
  },
  {
    "objectID": "template_qmds/24-hypothesis-testing-considerations-notes.html#readings-and-videos",
    "href": "template_qmds/24-hypothesis-testing-considerations-notes.html#readings-and-videos",
    "title": "Hypothesis testing: additional considerations (Notes)",
    "section": "",
    "text": "No new readings or videos for today."
  },
  {
    "objectID": "template_qmds/24-hypothesis-testing-considerations-notes.html#exercise-1-conceptual-understanding",
    "href": "template_qmds/24-hypothesis-testing-considerations-notes.html#exercise-1-conceptual-understanding",
    "title": "Hypothesis testing: additional considerations (Notes)",
    "section": "Exercise 1: Conceptual understanding",
    "text": "Exercise 1: Conceptual understanding\n\nSuppose that you and a friend are in two different sections (each with the same number of students) of the same class. On your respective midterm exams, you each obtained 85%, and the class average in both of your classes was 80%. Could one of you or your friend still be considered further above the class average than the other? Briefly explain.\nNow suppose that your section’s test scores were more tightly packed around 80%: maybe the standard deviation of your section’s scores was 2.5, whereas the standard deviation of your friend’s section’s scores was 5. Which of you or your friend was further above the class average? Explain/justify your answer.\nBroadly speaking, does a p-value measure the chance of a hypothesis being true, or, the chance of the data having occurred?\nWhy can’t a p-value measure the other quantity that you didn’t choose in Part c?\nExplain in words why, in calculating a p-value, we need to assume that the null hypothesis is true.\nSuppose that a hypothesis test yields a p-value of 1e-6 (\\(1\\times 10^{-6}\\)). What can you tell about the magnitude of the effect or the uncertainty of the effect from this p-value? (i.e., What can you tell about the coefficient estimate or the standard error?)"
  },
  {
    "objectID": "template_qmds/24-hypothesis-testing-considerations-notes.html#exercise-2-statistical-vs.-practical-significance",
    "href": "template_qmds/24-hypothesis-testing-considerations-notes.html#exercise-2-statistical-vs.-practical-significance",
    "title": "Hypothesis testing: additional considerations (Notes)",
    "section": "Exercise 2: Statistical vs. practical significance",
    "text": "Exercise 2: Statistical vs. practical significance\nMusic researchers compiled information on 16,216 Spotify songs. They looked at the relationship between a song’s genre (latin vs. not latin) and song duration in seconds. Their modeling code and output is below:\nspotify_model &lt;- lm(duration ~ latin_genre, data = spotify)\ncoef(summary(spotify_model))\n##                   Estimate Std. Error   t value   Pr(&gt;|t|)\n## (Intercept)     212.673908  0.4165491 510.56143 0.00000000\n## latin_genreTRUE   1.555355  0.7435700   2.09174 0.03647731\n\nInterpret the latin_genreTRUE coefficient.\nIn the context of song listening, is this a large or small effect size?\nReport and interpret the p-value for the latin_genreTRUE coefficient.\nUse the p-value to make a yes/no decision about the evidence for a relationship between genre and song duration.\nThis exercise highlights the difference between statistical significance and practical significance—explain how. That is, when might we observe statistically significant results that aren’t practically significant?"
  },
  {
    "objectID": "template_qmds/24-hypothesis-testing-considerations-notes.html#exercise-3-power",
    "href": "template_qmds/24-hypothesis-testing-considerations-notes.html#exercise-3-power",
    "title": "Hypothesis testing: additional considerations (Notes)",
    "section": "Exercise 3: Power",
    "text": "Exercise 3: Power\nStatistical power is the probability of rejecting the null hypothesis when the alternative hypothesis is true. We are frequently testing hypotheses to investigate differences or relationships, so in this context, statistical power is the probability of detecting a relationship when there truly is a relationship.\nNavigate to this page to look at an interactive visualization of the factors that influence statistical power.\nUnder “Settings”, next to the “Solve for?” text, click “Power”. You will vary the 3 different parameters (significance level, sample size, and effect size) one at a time to understand how these factors affect power.\nSome context behind this interactive visualization:\n\nVisualization is based on a one sample Z-test:\nThis is a test for whether the true population mean equals a particular value. (e.g., true mean = 30)\nThe effect size slider is measured with a metric called Cohen’s d:\n\nCohen’s d = magnitude of effect/standard deviation of response variable\nHere: how far is the true mean from the null value in units of SD?\ne.g., If the null value is 30, true mean is 40, and the true population SD of the quantity is 5, the Cohen’s d effect size is (40-30)/5 = 2.\n\n\n\nWhat is your intuition about how changing the significance level will change power? Check your intuition with the visualization and explain why this happens.\nRepeat Part a for the sample size.\nRepeat Part a for the effect size."
  },
  {
    "objectID": "template_qmds/24-hypothesis-testing-considerations-notes.html#exercise-4-ethical-considerations",
    "href": "template_qmds/24-hypothesis-testing-considerations-notes.html#exercise-4-ethical-considerations",
    "title": "Hypothesis testing: additional considerations (Notes)",
    "section": "Exercise 4: Ethical considerations",
    "text": "Exercise 4: Ethical considerations\n\nVisit this page and look at both the comic at the top and the various ways in which researchers have described p-values that do not fall below the \\(\\alpha = 0.05\\) significance level threshold. What ethical consideration is arising here? (Just for fun: a related xkcd comic)\nTake a look at the xkcd comic here. What ethical consideration is arising here?"
  },
  {
    "objectID": "template_qmds/24-hypothesis-testing-considerations-notes.html#done",
    "href": "template_qmds/24-hypothesis-testing-considerations-notes.html#done",
    "title": "Hypothesis testing: additional considerations (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/22-hypothesis-testing-discovery-notes.html",
    "href": "template_qmds/22-hypothesis-testing-discovery-notes.html",
    "title": "Hypothesis testing: discovery (Notes)",
    "section": "",
    "text": "You can download a template file to work with here.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.\n\n\n\nBy the end of this lesson, you should be able to:\n\nUnderstand how standard errors and confidence intervals enable us to make statistical inferences\nArticulate how we can formalize a research question as a testable, statistical hypothesis\n\n\n\n\nThis is a discovery activity, so no assigned readings/videos today."
  },
  {
    "objectID": "template_qmds/22-hypothesis-testing-discovery-notes.html#learning-goals",
    "href": "template_qmds/22-hypothesis-testing-discovery-notes.html#learning-goals",
    "title": "Hypothesis testing: discovery (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nUnderstand how standard errors and confidence intervals enable us to make statistical inferences\nArticulate how we can formalize a research question as a testable, statistical hypothesis"
  },
  {
    "objectID": "template_qmds/22-hypothesis-testing-discovery-notes.html#readings-and-videos",
    "href": "template_qmds/22-hypothesis-testing-discovery-notes.html#readings-and-videos",
    "title": "Hypothesis testing: discovery (Notes)",
    "section": "",
    "text": "This is a discovery activity, so no assigned readings/videos today."
  },
  {
    "objectID": "template_qmds/22-hypothesis-testing-discovery-notes.html#exercise-1",
    "href": "template_qmds/22-hypothesis-testing-discovery-notes.html#exercise-1",
    "title": "Hypothesis testing: discovery (Notes)",
    "section": "Exercise 1",
    "text": "Exercise 1\nResearch question: Is there evidence that the mercury concentration in fish (Concen) differs according to the River they were sampled from?\n\npart a: fit the model\nFit a simple linear regression model that would address our research question\n\nmod_fish &lt;- ___\nsummary(mod_fish)\n## Error in parse(text = input): &lt;text&gt;:1:14: unexpected input\n## 1: mod_fish &lt;- __\n##                  ^\n\nInterpret the intercept from this model.\n\nResponse\n\n\n\npart b: construct a CI\nUsing the 68-95-99.7 rule, construct an approximate 95% confidence interval for the intercept term, and provide an appropriate interpretation.\n\nResponse\n\nCompare your CI to an exact 95% confidence interval for the model coefficients:\n\nconfint(mod_fish, level=0.95)\n## Error: object 'mod_fish' not found\n\n\n\npart c: what can we conclude from multiple samples?\nSuppose we take 200 different samples of fish from the Lumber River. Based on these results, in how many of those samples would you expect to observe mean mercury concentration greater than 1.25ppm?\n\nResponse\n\n\n\npart d: intuition for constructing & interpreting test statistics\nSuppose previous environmental studies have found little evidence of mercury pollution in other rivers in the area, so perhaps our “default” assumption is that fish from the Lumber river should have an expected mercury concentration of 0ppm. How many standard errors is our sample estimate (1.078ppm) away from this expectation? What are three possible conclusions?\n\nResponse\n\n\n\npart e: do individual observations contradict our conclusions?\nNow suppose we sample a single fish from the Lumber River and find it has a mercury concentration of 2.5ppm. Are you surprised by this result? Why or why not? (Hint: create a code chunk that calculates the mean, standard deviation, and maximum of the Concen variable in each river in our original sample)\n\nResponse"
  },
  {
    "objectID": "template_qmds/22-hypothesis-testing-discovery-notes.html#exercise-2",
    "href": "template_qmds/22-hypothesis-testing-discovery-notes.html#exercise-2",
    "title": "Hypothesis testing: discovery (Notes)",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet’s look at the model summary output again:\n\nsummary(mod_fish)\n## Error: object 'mod_fish' not found\n\n\npart a: interpret model coefficient\nNow, let’s interpret the RiverWacamaw coefficient. Based only on the coefficient (don’t think about the standard error yet), what can we say about the difference in mercury concentration among fish in the two rivers?\n\nResponse\n\n\n\npart b: construct a CI\nUsing the 68-95-99.7 rule, construct an approximate 95% confidence interval for the RiverWacamaw coefficient, and provide an appropriate interpretation.\n\nResponse\n\n\n\npart c: interpreting the CI\nDo you believe it plausible that the mean mercury concentration of the fish population in the Wacamaw River is approximately the same as that of the fish population in the Lumber River? How would you confirm this? What assumptions are you making?\n\nResponse\n\n\n\npart d: effect of sample size on our conclusions\nSuppose we sample 10 times as many fish from the Wacamaw River, and get a similar coefficient estimate (0.2). Thinking back to the Central Limit Theorem, what should happen to the standard error of the RiverWacamaw coefficient? How small of a standard error would we need to more conclusively say that there is an actual difference in mean mercury concentrations of the Lumber River and Wacamaw River fish populations?\n\nResponse\n\n\n\npart e: reconciling parameter estimates and uncertainty\nSuppose the true population coefficient for the RiverWacamawparameter is 0.02 (i.e. the average mercury concentration is 0.02ppm higher for the Wacamaw River fish population compared to that of the Lumber River). Is this meaningful?\n\nResponse\n\n\n\npart f (CHALLENGE)\nUsing the model summary output, report the mean mercury concentration for our sample of fish from the Wacamaw River:\n\nsummary(mod_fish)\n## Error: object 'mod_fish' not found\n\n\nResponse:\n\nWhich of the following values do you think is the standard error of the sample mean for the Wacamaw River?\n\n0.11712\n0.08866\n0.11712 + 0.08866 = 0.20578\n0.11712 - 0.08866 = 0.02846\nsomething else\n\nTo answer this question, look at the code chunk below, which fits the same model, but uses the Wacamaw River as our reference category instead of the Lumber River:\n\nmod_fish2 &lt;- lm(Concen ~ River, data=fish %&gt;% mutate(River=ifelse(River == \"Wacamaw\", paste0(\"_\", River), River)))\nsummary(mod_fish2)\n## \n## Call:\n## lm(formula = Concen ~ River, data = fish %&gt;% mutate(River = ifelse(River == \n##     \"Wacamaw\", paste0(\"_\", River), River)))\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1664 -0.5681 -0.1764  0.4219  2.4219 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  1.27643    0.07652  16.681   &lt;2e-16 ***\n## RiverLumber -0.19835    0.11712  -1.694   0.0922 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7575 on 169 degrees of freedom\n## Multiple R-squared:  0.01669,    Adjusted R-squared:  0.01087 \n## F-statistic: 2.868 on 1 and 169 DF,  p-value: 0.09218\n\nCompare this to the output for mod_fish. What do you notice about the standard errors of the intercepts (i.e., the standard errors of the means for each river) compared to the standard errors of the RiverWacamaw and RiverLumber coefficients (i.e., the standard errors of the differences between the means)?\n\nResponse:"
  },
  {
    "objectID": "template_qmds/22-hypothesis-testing-discovery-notes.html#reflection",
    "href": "template_qmds/22-hypothesis-testing-discovery-notes.html#reflection",
    "title": "Hypothesis testing: discovery (Notes)",
    "section": "Reflection",
    "text": "Reflection\nBased on this activity and the inference tools you’ve learned about so far (sampling distributions, standard errors, confidence intervals), can you think of and describe a way that you can quantify evidence “for” or “against” a coefficient being equal to some particular value? (for example, we have evidence that the average mercury concentration in Lumber River fish is ~1.08ppm, and the standard error of this estimate suggests that observing a fish with 0ppm is very unlikely. How can we quantify that evidence?)\n\nResponse:"
  },
  {
    "objectID": "template_qmds/22-hypothesis-testing-discovery-notes.html#done",
    "href": "template_qmds/22-hypothesis-testing-discovery-notes.html#done",
    "title": "Hypothesis testing: discovery (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html",
    "href": "template_qmds/20-bootstrapping-notes.html",
    "title": "Bootstrapping (Notes)",
    "section": "",
    "text": "You will not be able to render this document until you’ve filled in the code!\n\n\nLet \\(\\beta\\) be some population parameter and \\(\\hat{\\beta}\\) be a sample estimate of \\(\\beta\\). In order to study the potential error in \\(\\hat{\\beta}\\), you will…\n\nexplore two approaches to approximating the sampling distribution of \\(\\hat{\\beta}\\):\n\nCentral Limit Theorem (CLT)\nbootstrapping\n\nidentify the difference between sampling and resampling\nintuit how bootstrapping results can be used to make inferences about \\(\\beta\\)\n\n\n\n\nPlease watch the following video after class:\n\nbootstrapping"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#learning-goals",
    "href": "template_qmds/20-bootstrapping-notes.html#learning-goals",
    "title": "Bootstrapping (Notes)",
    "section": "",
    "text": "Let \\(\\beta\\) be some population parameter and \\(\\hat{\\beta}\\) be a sample estimate of \\(\\beta\\). In order to study the potential error in \\(\\hat{\\beta}\\), you will…\n\nexplore two approaches to approximating the sampling distribution of \\(\\hat{\\beta}\\):\n\nCentral Limit Theorem (CLT)\nbootstrapping\n\nidentify the difference between sampling and resampling\nintuit how bootstrapping results can be used to make inferences about \\(\\beta\\)"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#readings-and-videos",
    "href": "template_qmds/20-bootstrapping-notes.html#readings-and-videos",
    "title": "Bootstrapping (Notes)",
    "section": "",
    "text": "Please watch the following video after class:\n\nbootstrapping"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-1-sample-vs-population",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-1-sample-vs-population",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 1: sample vs population",
    "text": "Exercise 1: sample vs population\n\nIn the summary table, is the Length coefficient 0.058 the population slope \\(\\beta_1\\) or a sample estimate \\(\\hat{\\beta}_1\\)?\nIf it’s a sample estimate, how accurate do you think it is?"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-2-the-rub",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-2-the-rub",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 2: The rub",
    "text": "Exercise 2: The rub\nSince we don’t know \\(\\beta_1\\), we can’t know the exact error in \\(\\hat{\\beta}_1\\)! This is where sampling distributions come in. They describe how estimates \\(\\hat{\\beta}_1\\) might vary from sample to sample, thus how far these estimates might fall from \\(\\beta_1\\):\n\nIn past activities, we used simulations to approximate the sampling distribution. For example, we took and evaluated 500 different samples of 10 counties from the population of 3142 counties. Why can’t we do that here in our fish example?"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-3-clt",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-3-clt",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 3: CLT",
    "text": "Exercise 3: CLT\nIn practice, we can’t observe the sampling distribution and its corresponding standard error. But we can approximate them. When our sample size n is “large enough”, we might approximate the sampling distribution using the CLT:\n\\[\\hat{\\beta}_1 \\sim N(\\beta_1, \\text{standard error}^2)\\]\nThe standard error in the CLT is approximated from our sample via some formula \\(c / \\sqrt{n}\\) where “c” is complicated. Obtain and interpret this standard error from the model summary table:\n\ncoef(summary(fish_model))\n##                Estimate  Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -1.13164542 0.213614796 -5.297598 3.617750e-07\n## Length       0.05812749 0.005227593 11.119359 6.641225e-22"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#reflect",
    "href": "template_qmds/20-bootstrapping-notes.html#reflect",
    "title": "Bootstrapping (Notes)",
    "section": "REFLECT",
    "text": "REFLECT\nGreat! We can approximate the sampling distribution and standard error using the CLT. BUT:\n\nthe quality of this approximation hinges upon the validity of the Central Limit theorem which hinges upon the validity of the theoretical model assumptions\nthe CLT uses complicated formulas for the standard error estimates, thus can feel a little mysterious\n\nLet’s explore how we can use bootstrapping to complement (not entirely replace) the CLT. The saying “to pull oneself up by the bootstraps” is often attributed to Rudolf Erich Raspe’s 1781 The Surprising Adventures of Baron Munchausen in which the character pulls himself out of a swamp by his hair (not bootstraps). In short, it means to get something from nothing, through your own effort:\n\nIn this spirit, statistical bootstrapping doesn’t make any probability model assumptions. It uses only the information from our one sample to approximate standard errors."
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-4-challenge",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-4-challenge",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 4: Challenge",
    "text": "Exercise 4: Challenge\nRecall that we have a sample size of 171 fish:\n\nnrow(fish)\n## [1] 171\n\nWe’ll obtain a bootstrapping distribution of \\(\\hat{\\beta}_1\\) by taking many (500) different samples of 171 fish and exploring the degree to which \\(\\hat{\\beta}_1\\) varies from sample to sample. Let’s try doing this as we did in past activities:\n\n# Build 500 models using samples of size 171\nfish_models_bad_simulation &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 171, replace = FALSE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n\nhead(fish_models_bad_simulation)\n##   Intercept     Length     sigma r.squared        F numdf dendf .row .index\n## 1 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      1\n## 2 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      2\n## 3 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      3\n## 4 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      4\n## 5 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      5\n## 6 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      6\n\nWhat’s funny about the results? Why do you think this happened? How might you adjust the code to “fix” things?"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-5-resampling",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-5-resampling",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 5: Resampling",
    "text": "Exercise 5: Resampling\nIn practice, we take one sample of size n from the population. To obtain a bootstrapping distribution of some sample estimate \\(\\hat{\\beta}\\), we…\n\ntake many resamples of size n with replacement from the sample\ncalculate \\(\\hat{\\beta}\\) using each resample\n\n\nLet’s wrap our minds around the idea of resampling using a small example of 5 fish:\n\n# Define data\nsmall_sample &lt;- data.frame(\n  id = 1:5,\n  Length = c(44, 43, 54, 52, 40))\n\nsmall_sample\n##   id Length\n## 1  1     44\n## 2  2     43\n## 3  3     54\n## 4  4     52\n## 5  5     40\n\nThis sample has a mean Length of 46.6 cm:\n\nsmall_sample %&gt;% \n  summarize(mean(Length))\n##   mean(Length)\n## 1         46.6\n\n\nThe chunk below samples 5 fish without replacement from our small_sample of 5 fish, and calculates their mean length. Run it several times. How do the sample and resulting mean change?\n\n\nsample_1 &lt;- sample_n(small_sample, size = 5, replace = FALSE)\nsample_1\n##   id Length\n## 1  2     43\n## 2  4     52\n## 3  1     44\n## 4  3     54\n## 5  5     40\n\nsample_1 %&gt;% \n  summarize(mean(Length))\n##   mean(Length)\n## 1         46.6\n\n\nSampling our sample without replacement merely returns our original sample. Instead, resample 5 fish from our small_sample with replacement. Run it several times. What do you notice about the samples? About their mean lengths?\n\n\nsample_2 &lt;- sample_n(small_sample, size = 5, replace = TRUE)\nsample_2\n##   id Length\n## 1  5     40\n## 2  2     43\n## 3  2     43\n## 4  5     40\n## 5  3     54\n\nsample_2 %&gt;% \n  summarize(mean(Length))\n##   mean(Length)\n## 1           44\n\n\nResampling our sample provides insight into the variability, hence potential error, in our sample estimates. (This works better when we have a sample bigger than 5!) As you observed in part b, each resample might include some fish from the original sample several times and others not at all. Why is this ok?"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-6-bootstrapping",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-6-bootstrapping",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 6: Bootstrapping",
    "text": "Exercise 6: Bootstrapping\nWe’re ready to bootstrap! Fix one line of the code below to obtain 500 bootstrap estimates of the model of Concen by Length:\n\n# Set the seed so we get the same results\nset.seed(155)\n\n# Build 500 bootstrap models using REsamples of size 171\nfish_models_bootstrap &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 171, replace = FALSE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n\nhead(fish_models_bootstrap)\n##   Intercept     Length     sigma r.squared        F numdf dendf .row .index\n## 1 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      1\n## 2 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      2\n## 3 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      3\n## 4 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      4\n## 5 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      5\n## 6 -1.131645 0.05812749 0.5805245 0.4224989 123.6401     1   169    1      6"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-7-bootstrap-results",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-7-bootstrap-results",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 7: Bootstrap results",
    "text": "Exercise 7: Bootstrap results\nRecall that we started with 1 sample, thus 1 estimate of the model:\n\ncoef(summary(fish_model))\n##                Estimate  Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -1.13164542 0.213614796 -5.297598 3.617750e-07\n## Length       0.05812749 0.005227593 11.119359 6.641225e-22\n\n\nWe now have 500 (resample) bootstrap estimates of the model. These vary around the red line in the plot below. What does the red line represent: the actual population model or fish_model (the estimated model calculated from our original fish sample)?\n\n\nfish %&gt;% \n  ggplot(aes(y = Concen, x = Length)) +\n  geom_abline(data = fish_models_bootstrap, aes(intercept = Intercept, slope = Length), color = \"gray\") + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\n\nNow focus on just the 500 (resample) bootstrap estimates of the slope Length coefficient. Before plotting the distribution of these resampled slopes, what do you anticipate? What shape do you expect the distribution will have? Around what value do you expect it to be centered?\nCheck your intuition with the plot below. Was your intuition right?\n\n\nfish_models_bootstrap %&gt;% \n  ggplot(aes(x = Length)) + \n  geom_density()"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-8-bootstrap-standard-errors",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-8-bootstrap-standard-errors",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 8: Bootstrap standard errors",
    "text": "Exercise 8: Bootstrap standard errors\nSince they’re calculated from resamples of our sample, not different samples from the population, the 500 bootstrap estimates of the slope are centered around our original sample estimate. Importantly:\nThe degree to which the bootstrap estimates vary from the original sample estimate provides insight in the degree to which our original sample estimate might vary from the actual population slope (i.e. its standard error)!\n\nUse the bootstrap estimates of the Length slope coefficient to approximate the standard error of 0.05813, our original sample estimate. HINT: standard deviation\n\n\n# fish_models_bootstrap %&gt;% \n#   ___(___(Length))\n\n\nHow does this bootstrapped approximation of standard error compare to that calculated via (a complicated mystery) formula and reported in the model summary table?\n\n\ncoef(summary(fish_model))\n##                Estimate  Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -1.13164542 0.213614796 -5.297598 3.617750e-07\n## Length       0.05812749 0.005227593 11.119359 6.641225e-22"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#pause-powerful-stuff",
    "href": "template_qmds/20-bootstrapping-notes.html#pause-powerful-stuff",
    "title": "Bootstrapping (Notes)",
    "section": "Pause: Powerful stuff!",
    "text": "Pause: Powerful stuff!\nJust pause here to appreciate how awesome it is that you approximated the potential error in our sample estimates using simulation and your sample data alone – no “theorems” or complicated formulas. You might say we pulled ourselves up by the bootstraps."
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-9-looking-ahead-at-intervals",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-9-looking-ahead-at-intervals",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 9: Looking ahead at intervals",
    "text": "Exercise 9: Looking ahead at intervals\nIn the past few activities, we’ve been exploring sampling variability and error. These tools are critical in using our sample to make inferences about the broader population. We’ll explore inference more formally in the weeks ahead. Here, use your intuition to apply our bootstrapping results:\n\nfish %&gt;% \n  ggplot(aes(y = Concen, x = Length)) +\n  geom_abline(data = fish_models_bootstrap, aes(intercept = Intercept, slope = Length), color = \"gray\")\n\n\n\n\n\n\n\n\n\nfish_models_bootstrap %&gt;% \n  ggplot(aes(x = Length)) + \n  geom_density()\n\n\n\n\n\n\n\n\n\nOur original sample estimate of the Length coefficient, 0.0581, was simply our best guess of the actual coefficient among all fish. But we know it’s wrong. Based on the plots above, provide a bigger range or interval of plausible values for the actual coefficient among all fish.\nWe can do better than visual approximations. Use the fish_models_bootstrap results to provide a more specific interval of plausible values for the actual Length coefficient. THINK: Do you think we should use the full range of observed bootstrap estimates? Just a fraction?\n\n\n# fish_models_bootstrap %&gt;% \n#   summarize(___(Length, ___), ___(Length, ___))"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#exercise-10-looking-ahead-at-hypothesis-testing",
    "href": "template_qmds/20-bootstrapping-notes.html#exercise-10-looking-ahead-at-hypothesis-testing",
    "title": "Bootstrapping (Notes)",
    "section": "Exercise 10: Looking ahead at hypothesis testing",
    "text": "Exercise 10: Looking ahead at hypothesis testing\nSome researchers claim that mercury content is associated with the length of a fish. Let’s use our bootstrapping results to test this hypothesis.\n\nBased on only the plot below of our bootstrap models, do you think our sample data supports this hypothesis?\n\n\nfish %&gt;% \n  ggplot(aes(y = Concen, x = Length)) +\n  geom_abline(data = fish_models_bootstrap, aes(intercept = Intercept, slope = Length), color = \"gray\")\n\n\n\n\n\n\n\n\n\nWhat about numerical evidence? Based on the interval you calculated in part b of the previous exercise, do you think our sample data supports this hypothesis?"
  },
  {
    "objectID": "template_qmds/20-bootstrapping-notes.html#done",
    "href": "template_qmds/20-bootstrapping-notes.html#done",
    "title": "Bootstrapping (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "",
    "text": "Let \\(\\beta\\) be some population parameter and \\(\\hat{\\beta}\\) be a sample estimate of \\(\\beta\\). Our goals for the day are to:\n\nuse simulation to solidify our understanding of sampling distributions and standard errors\nexplore and compare two approaches to approximating the sampling distribution of \\(\\hat{\\beta}\\):\n\nCentral Limit Theorem (CLT)\nbootstrapping\n\nexplore the impact of sample size on sampling distributions and standard errors\n\n\n\n\nPlease watch/do the following videos and readings before class:\n\nReading: Section 6.7 in the STAT 155 Notes\nVideo 1: sampling distributions\nVideo 2: Central Limit Theorem\nVideo 3: bootstrapping"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#learning-goals",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#learning-goals",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "",
    "text": "Let \\(\\beta\\) be some population parameter and \\(\\hat{\\beta}\\) be a sample estimate of \\(\\beta\\). Our goals for the day are to:\n\nuse simulation to solidify our understanding of sampling distributions and standard errors\nexplore and compare two approaches to approximating the sampling distribution of \\(\\hat{\\beta}\\):\n\nCentral Limit Theorem (CLT)\nbootstrapping\n\nexplore the impact of sample size on sampling distributions and standard errors"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#readings-and-videos",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#readings-and-videos",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "",
    "text": "Please watch/do the following videos and readings before class:\n\nReading: Section 6.7 in the STAT 155 Notes\nVideo 1: sampling distributions\nVideo 2: Central Limit Theorem\nVideo 3: bootstrapping"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#reflect",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#reflect",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "REFLECT",
    "text": "REFLECT\nGreat! We have two options. Here are some things to think about / reflect on:\n\nWe can approximate the sampling distribution and standard error using the CLT. BUT:\n\nthe quality of this approximation hinges upon the validity of the Central Limit theorem which hinges upon the validity of the theoretical model assumptions, as well as a large sample size\nthe CLT uses theoretical formulas for the standard error estimates, thus can feel a little mysterious without a solid foundation in probability theory\n\nWe can approxiate the sampling distribution and standard error using bootstrapping. BUT:\n\nit feels magical. The statistical theory behind bootstrapping is quite complicated, and there are certain obscure cases (none that we will encounter in Stat 155) where the assumptions underlying bootstrapping fail to hold\n\n\nNeither approach is perfect, but they complement one another. Bootrapping in particular, while it cannot and should not replace the CLT, gives us some nice intuition behind the idea of resampling, which is fundamental for hypothesis testing (which we’ll get to shortly!).\n\nReflect: Before testing them out, what questions do you have about either approach? What do you think would help you build more intuition for the CLT and/or bootstrapping? Does one approach resonate with you more than the other?"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-1-500-samples-of-size-10",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-1-500-samples-of-size-10",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 1: 500 samples of size 10",
    "text": "Exercise 1: 500 samples of size 10\nRecall that we can sample 10 observations from our dataset using sample_n():\n\n# Run this chunk a few times to explore the different samples you get\nfish %&gt;% \n  sample_n(size = 10, replace = TRUE)\n## # A tibble: 10 × 5\n##    River   Station Length Weight Concen\n##    &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n##  1 Lumber        1   33.5   1146   0.57\n##  2 Lumber        1   41     1059   1.8 \n##  3 Wacamaw      14   44.7   1454   2.4 \n##  4 Wacamaw      15   49.5   1924   2.3 \n##  5 Wacamaw      14   48     1743   1.9 \n##  6 Lumber        5   30.5    400   0.5 \n##  7 Wacamaw      14   56.1   2629   3.4 \n##  8 Wacamaw      10   39      977   1.5 \n##  9 Wacamaw       8   47      586   1.3 \n## 10 Wacamaw      11   41.5   1018   0.83\n\nWe can also take a sample and then use the data to estimate the model:\n\n# Run this chunk a few times to explore the different sample models you get\nfish %&gt;% \n  sample_n(size = 10, replace = TRUE) %&gt;% \n  with(lm(Concen ~ Length))\n## \n## Call:\n## lm(formula = Concen ~ Length)\n## \n## Coefficients:\n## (Intercept)       Length  \n##     0.18884      0.02125\n\nWe can also take multiple unique samples and build a sample model from each.\nThe code below obtains 500 separate samples of 10 fish, and stores the model estimates from each:\n\n# Set the seed so that we all get the same results\nset.seed(155)\n\n# Store the sample models\nsample_models_10 &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 10, replace = TRUE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n\n# Check it out\nhead(sample_models_10)\n##    Intercept     Length     sigma r.squared          F numdf dendf .row .index\n## 1 -2.7811151 0.09635286 0.5737186 0.7273700  21.343798     1     8    1      1\n## 2 -3.0684939 0.10953496 0.3797853 0.9347767 114.655478     1     8    1      2\n## 3 -1.2880671 0.05933243 0.7457468 0.3776855   4.855237     1     8    1      3\n## 4 -0.9248832 0.05411299 0.6251621 0.4796674   7.374782     1     8    1      4\n## 5 -1.0882523 0.05349699 0.3441272 0.4985134   7.952571     1     8    1      5\n## 6 -0.4558309 0.04074788 0.7785389 0.1719987   1.661820     1     8    1      6\ndim(sample_models_10)\n## [1] 500   9\n\n\nWhat’s the point of the do() function?!? If you’ve taken any COMP classes, what process do you think do() is a shortcut for?\nWhat is stored in the Intercept, Length, and r.squared columns of the results?\nWe’ll obtain a bootstrapping distribution of \\(\\hat{\\beta}_1\\) by taking many (500, in this case) different samples of every fish in our dataset (171 of them) and exploring the degree to which \\(\\hat{\\beta}_1\\) varies from sample to sample.\n\nEdit the code below to obtain a bootstrapping distribution.\n\n# Set the seed so that we all get the same results\nset.seed(155)\n\n# Store the sample models\nsample_models_boot &lt;- mosaic::do(___)*(\n  fish %&gt;% \n    sample_n(size = ___, replace = TRUE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n## Error in parse(text = input): &lt;text&gt;:5:35: unexpected input\n## 4: # Store the sample models\n## 5: sample_models_boot &lt;- mosaic::do(__\n##                                      ^"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-2-why-resampling-replace-true",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-2-why-resampling-replace-true",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 2: Why “resampling” (replace = TRUE)?",
    "text": "Exercise 2: Why “resampling” (replace = TRUE)?\nLet’s wrap our minds around the idea of resampling, before coming back to our boostrapping distribution, using a small example of 5 fish:\n\n# Define data\nsmall_sample &lt;- data.frame(\n  id = 1:5,\n  Length = c(44, 43, 54, 52, 40))\n\nsmall_sample\n##   id Length\n## 1  1     44\n## 2  2     43\n## 3  3     54\n## 4  4     52\n## 5  5     40\n\nThis sample has a mean Length of 46.6 cm:\n\nsmall_sample %&gt;% \n  summarize(mean(Length))\n##   mean(Length)\n## 1         46.6\n\n\nThe chunk below samples 5 fish without replacement from our small_sample of 5 fish, and calculates their mean length. Run it several times. How do the sample and resulting mean change?\n\n\nsample_1 &lt;- sample_n(small_sample, size = 5, replace = FALSE)\nsample_1\n##   id Length\n## 1  4     52\n## 2  2     43\n## 3  3     54\n## 4  5     40\n## 5  1     44\n\nsample_1 %&gt;% \n  summarize(mean(Length))\n##   mean(Length)\n## 1         46.6\n\n\nSampling our sample without replacement merely returns our original sample. Instead, resample 5 fish from our small_sample with replacement. Run it several times. What do you notice about the samples? About their mean lengths?\n\n\nsample_2 &lt;- sample_n(small_sample, size = 5, replace = TRUE)\nsample_2\n##   id Length\n## 1  1     44\n## 2  5     40\n## 3  1     44\n## 4  4     52\n## 5  5     40\n\nsample_2 %&gt;% \n  summarize(mean(Length))\n##   mean(Length)\n## 1           44\n\nResampling our sample provides insight into the variability, hence potential error, in our sample estimates. (This works better when we have a sample bigger than 5!) As you observed in part b, each resample might include some fish from the original sample several times and others not at all.\nBonus Fact: Sampling with replacement also ensures that our resampled observations are independent, which we need in order for bootstrapping to “work”!"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-3-sampling-distribution",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-3-sampling-distribution",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 3: Sampling distribution",
    "text": "Exercise 3: Sampling distribution\nCheck out the resulting 500 bootstrapped sample models:\n\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_abline(data = sample_models_boot, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n## Error: object 'sample_models_boot' not found\n\nLet’s focus on the slopes of these 500 sample models.\nA plot of the 500 slopes approximates the sampling distribution of the sample slopes.\n\nsample_models_boot %&gt;% \n  ggplot(aes(x = Length)) + \n  geom_density() + \n  geom_vline(xintercept = 0.05813, color = \"red\") \n## Error: object 'sample_models_boot' not found\n\nDescribe the sampling distribution:\n\nWhat’s its general shape?\nWhere is it roughly centered?\nRoughly what’s its spread / i.e. what’s the range of estimates you observed?"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-4-standard-error",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-4-standard-error",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 4: Standard error",
    "text": "Exercise 4: Standard error\nFor a more rigorous assessment of the spread among the sample slopes, let’s calculate their standard deviation:\n\nsample_models_boot %&gt;% \n  summarize(sd(Length))\n## Error: object 'sample_models_boot' not found\n\nRecall: The standard deviation of sample estimates is called a “standard error”.\nIt measures the typical distance of a sample estimate from the actual population value.\nCompare the bootstrapped standard error to the standard error reported from our regression model (see the Std. Error column):\n\ncoef(summary(fish_model))\n##                Estimate  Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -1.13164542 0.213614796 -5.297598 3.617750e-07\n## Length       0.05812749 0.005227593 11.119359 6.641225e-22\n\nAre they roughly equivalent?\n\nYour response here"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-5-central-limit-theorem-clt",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-5-central-limit-theorem-clt",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 5: Central Limit Theorem (CLT)",
    "text": "Exercise 5: Central Limit Theorem (CLT)\nRecall that the CLT assumes that, so long as our sample size is “big enough”, the sampling distribution of the sample slope will be Normal.\nSpecifically, all possible sample slopes will vary Normally around the population slope.\n\nDo your simulation results support this assumption? Why or why not?\nWant more intuition into the CLT? Watch this video explanation using bunnies and dragons: https://www.youtube.com/watch?v=jvoxEYmQHNM"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-6-using-the-clt",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-6-using-the-clt",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 6: Using the CLT",
    "text": "Exercise 6: Using the CLT\nLet \\(\\hat{\\beta}_1\\) be an estimate of the (super)population slope parameter \\(\\beta_1\\) calculated from a sample of 10 fish (sample_models_10).\nEstimate the standard error of the slope from these resampled estimates\n\n# Hint: Adapt the code from Exercise 5...\n\nYou should get a SE of roughly 0.026.\nThus, by the CLT, the sampling distribution of \\(\\hat{\\beta}_1\\) is:\n\\[\\hat{\\beta}_1 \\sim N(\\beta_1, 0.26^2)\\]\nUse this result with the 68-95-99.7 property of the Normal model to understand the potential error in a slope estimate.\n\nThere are many possible samples of 10 fish. What percent of these will produce an estimate \\(\\hat{\\beta}_1\\) that’s within 0.052, i.e. 2 standard errors, of the actual population slope \\(\\beta_1\\)?\nMore than 2 standard errors from \\(\\beta_1\\)?\nMore than 0.079, i.e. 3 standard errors, above \\(\\beta_1\\)?"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-7-clt-and-the-68-95-99.7-rule",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-7-clt-and-the-68-95-99.7-rule",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 7: CLT and the 68-95-99.7 Rule",
    "text": "Exercise 7: CLT and the 68-95-99.7 Rule\nFill in the blanks below to complete some general properties assumed by the CLT:\n\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 1 st. err. of \\(\\beta_1\\)\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 2 st. err. of \\(\\beta_1\\)\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 3 st. err. of \\(\\beta_1\\)"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-8-increasing-sample-size",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-8-increasing-sample-size",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 8: Increasing sample size",
    "text": "Exercise 8: Increasing sample size\nNow that we have a sense of the potential variability and error in sample estimates, let’s consider the impact of sample size.\nSuppose we were to increase our sample size from n = 10 to n = 50 or n = 100 fish. What impact do you anticipate this having on our sample estimates of the population parameters:\n\nDo you expect there to be more or less variability among the sample model lines?\nAround what value would you expect the sampling distribution of sample slopes to be centered?\nWhat general shape would you expect that sampling distribution to have?\nIn comparison to estimates based on the samples of size 10, do you think the estimates based on samples of size 50 will be closer to or farther from the true slope (on average)?"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-9-500-samples-of-size-n",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-9-500-samples-of-size-n",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 9: 500 samples of size n",
    "text": "Exercise 9: 500 samples of size n\nLet’s increase the sample size in our simulation.\nFill in the blanks to take 500 samples of size 50, and build a sample model from each.\n\nset.seed(155)\nsample_models_50 &lt;- mosaic::do(___)*(\n  fish %&gt;% \n    ___(size = ___, replace = FALSE) %&gt;% \n    ___(___(Concen ~ Length))\n)\n\n# Check it out\nhead(sample_models_50)\n## Error in parse(text = input): &lt;text&gt;:2:33: unexpected input\n## 1: set.seed(155)\n## 2: sample_models_50 &lt;- mosaic::do(__\n##                                    ^\n\nSimilarly, take 500 samples of size 100, and build a sample model from each.\n\nset.seed(155)\nsample_models_100 &lt;- mosaic::do(___)*(\n  fish %&gt;% \n    ___(size = ___, replace = FALSE) %&gt;% \n    ___(___(Concen ~ Length))\n)\n\n# Check it out\nhead(sample_models_100)\n## Error in parse(text = input): &lt;text&gt;:2:34: unexpected input\n## 1: set.seed(155)\n## 2: sample_models_100 &lt;- mosaic::do(__\n##                                     ^"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-10-impact-of-sample-size-part-i",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-10-impact-of-sample-size-part-i",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 10: Impact of sample size (part I)",
    "text": "Exercise 10: Impact of sample size (part I)\nCompare and contrast the 500 sets of sample models when using samples of size 10, 50, and 100.\n\n# 500 sample models using samples of size 10\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_10, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\n\n# 500 sample models using samples of size 50\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_50, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n## Error: object 'sample_models_50' not found\n\n\n# 500 sample models using samples of size 100\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_100, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n## Error: object 'sample_models_100' not found\n\n\nWhat happens to our sample models as sample size increases? Was this what you expected?"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-11-impact-of-sample-size-part-ii",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-11-impact-of-sample-size-part-ii",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 11: Impact of sample size (part II)",
    "text": "Exercise 11: Impact of sample size (part II)\nLet’s focus on just the sampling distributions of our 500 slope estimates \\(\\hat{\\beta}_1\\).\nFor easy comparison, plot the estimates based on samples of size 10, 50, and 100 on the same frame:\n\n# Don't think too hard about this code!\n# Combine the estimates & sample size into a new data set\n# Then plot it\n\ndata.frame(estimates = c(sample_models_10$Length, sample_models_50$Length, sample_models_100$Length),\n           sample_size = rep(c(\"10\",\"50\",\"100\"), each = 500)) %&gt;% \n  mutate(sample_size = fct_relevel(sample_size, c(\"10\", \"50\", \"100\"))) %&gt;% \n  ggplot(aes(x = estimates, color = sample_size)) + \n  geom_density() + \n  geom_vline(xintercept = 0.05813, color = \"red\", linetype = \"dashed\") + \n  labs(title = \"Sampling distributions of the sample slope\")\n## Error: object 'sample_models_50' not found\n\n\nHow do the shapes, centers, and spreads of these sampling distributions compare? Was this what you expected?"
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-12-properties-of-sampling-distributions",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#exercise-12-properties-of-sampling-distributions",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Exercise 12: Properties of sampling distributions",
    "text": "Exercise 12: Properties of sampling distributions\nIn light of your observations, complete the following statements about the sampling distribution of the sample slope.\n\nFor all sample sizes, the shape of the sampling distribution is roughly ___ and the sampling distribution is roughly centered around ___, the sample estimate from our original data.\nAs sample size increases:\nThe average sample slope estimate INCREASES / DECREASES / IS FAIRLY STABLE.\nThe standard error of the sample slopes INCREASES / DECREASES / IS FAIRLY STABLE.\nThus, as sample size increases, our sample slopes become MORE RELIABLE / LESS RELIABLE."
  },
  {
    "objectID": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#done",
    "href": "template_qmds/19-20-sampling-dist-clt-bootstrap-notes.html#done",
    "title": "Sampling distributions, the CLT, and Bootstrapping (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html",
    "title": "Multiple logistic regression (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nConstruct multiple logistic regression models in R\nInterpret coefficients in multiple logistic regression models\nUse multiple logistic regression models to make predictions\nEvaluate the quality of logistic regression models by using predicted probability boxplots and by computing and interpreting accuracy, sensitivity, specificity, false positive rate, and false negative rate\n\n\n\n\nPlease go through the following reading or videos before class.\n\nReading: Section 4.4 in the STAT 155 Notes\nVideos:\n\nPart 1: Concepts (script)\nPart 2: R Code (script)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#learning-goals",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#learning-goals",
    "title": "Multiple logistic regression (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nConstruct multiple logistic regression models in R\nInterpret coefficients in multiple logistic regression models\nUse multiple logistic regression models to make predictions\nEvaluate the quality of logistic regression models by using predicted probability boxplots and by computing and interpreting accuracy, sensitivity, specificity, false positive rate, and false negative rate"
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#readings-and-videos",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#readings-and-videos",
    "title": "Multiple logistic regression (Notes)",
    "section": "",
    "text": "Please go through the following reading or videos before class.\n\nReading: Section 4.4 in the STAT 155 Notes\nVideos:\n\nPart 1: Concepts (script)\nPart 2: R Code (script)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-1-graphical-and-numerical-summaries",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-1-graphical-and-numerical-summaries",
    "title": "Multiple logistic regression (Notes)",
    "section": "Exercise 1: Graphical and numerical summaries",
    "text": "Exercise 1: Graphical and numerical summaries\nOur research question involves three categorical variables: received_callback (1 = yes, 0 = no), gender (f = female, m = male), and race (Black, White). Let’s start by creating a mosaic plot to visually compare inferred binary gender and callbacks:\n\n# create mosaic plot of callback vs gender\nggplot(resume) + \n    geom_mosaic(aes(x = product(gender), fill = received_callback)) +\n    scale_fill_manual(\"Received Callback? \\n(1 = yes, 0 = no)\", values = c(\"lightblue\", \"steelblue\")) + \n    labs(x = \"Inferred Binary Gender (f = female, m = male)\", y = \"Received Callback? (1 = yes, 0 = no)\")\n## Error in geom_mosaic(aes(x = product(gender), fill = received_callback)): could not find function \"geom_mosaic\"\n\nIn this activity, we’re also interested in looking at the relationship between inferred race and callbacks. One way we can add a third variable to a plot is to use the facet_grid function, particularly when that third variable is categorical. Let’s try that now:\n\n# create mosaic plot of callback vs gender and race\nggplot(resume) + \n    geom_mosaic(aes(x = product(gender), fill = received_callback)) +\n    facet_grid(. ~ race) +\n    scale_fill_manual(\"Received Callback? \\n(1 = yes, 0 = no)\", values = c(\"lightblue\", \"steelblue\")) + \n    labs(x = \"Inferred Binary Gender (f = female, m = male)\", y = \"Received Callback? (1 = yes, 0 = no)\")\n## Error in geom_mosaic(aes(x = product(gender), fill = received_callback)): could not find function \"geom_mosaic\"\n\nHere’s another way of looking at the relationship between these three variables, switching the placement of gender and race in the mosaic plot:\n\n# create mosaic plot of callback vs gender and race\nggplot(resume) + \n    geom_mosaic(aes(x = product(received_callback, race), fill = received_callback)) +\n    facet_grid(. ~ gender) +\n    scale_fill_manual(\"Received Callback? \\n(1 = yes, 0 = no)\", values = c(\"lightblue\", \"steelblue\")) + \n    labs(x = \"Inferred Race\", y = \"Received Callback? (1 = yes, 0 = no)\")\n## Error in geom_mosaic(aes(x = product(received_callback, race), fill = received_callback)): could not find function \"geom_mosaic\"\n\nWhen we are comparing three categorical variables, a useful numerical summary is to calculate relative frequencies/proportions of cases falling into each category of the outcome variable, conditional on which categories of the explanatory variables they fall into. Run this code chunk to calculate the conditional proportion of resumes that did nor did not receive a callback, given the inferred gender and race of the applicant:\n\n# corresponding numerical summaries\nresume %&gt;%\n    group_by(race, gender) %&gt;%\n    count(received_callback) %&gt;%\n    group_by(race, gender) %&gt;%\n    mutate(condprop = n/sum(n))\n## # A tibble: 8 × 5\n## # Groups:   race, gender [4]\n##   race  gender received_callback     n condprop\n##   &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;\n## 1 black f                      0  1761   0.934 \n## 2 black f                      1   125   0.0663\n## 3 black m                      0   517   0.942 \n## 4 black m                      1    32   0.0583\n## 5 white f                      0  1676   0.901 \n## 6 white f                      1   184   0.0989\n## 7 white m                      0   524   0.911 \n## 8 white m                      1    51   0.0887\n\nWrite a short description that summarizes the information you gain from these visualizations and numerical summaries. Write this summary using good sentences that tell a story and do not resemble a checklist. Don’t forget to consider the context of the data, and make sure that your summary addresses our research question: does an applicant’s inferred gender or race have an effect on the chance that they receive a callback?"
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-2-logistic-regression-modeling",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-2-logistic-regression-modeling",
    "title": "Multiple logistic regression (Notes)",
    "section": "Exercise 2: Logistic regression modeling",
    "text": "Exercise 2: Logistic regression modeling\nNext, we’ll fit a logistic regression model to these data, modeling the log odds of receiving a callback as a function of the applicant’s inferred gender and race:\n\\[\\log(Odds[ReceivedCallback = 1 \\mid gender, race]) = \\beta_0 + \\beta_1 genderm + \\beta_2 racewhite\\]\nFill in the blanks in the code below to fit this logistic regression model.\n\n# fit logistic model and save it as object called \"mod1\"\nmod1 &lt;- glm(received_callback ~ gender + race, data = ___, family = ___)\n## Error in parse(text = input): &lt;text&gt;:2:56: unexpected input\n## 1: # fit logistic model and save it as object called \"mod1\"\n## 2: mod1 &lt;- glm(received_callback ~ gender + race, data = __\n##                                                           ^\n\nThen, run the code chunk below to get the coefficient estimates and exponentiated estimates, presented in a nicely formatted table:\n\n# print out tidy summary of mod, focusing on estimates & exponentiated estimates\ntidy(mod1) %&gt;%\n    select(term, estimate) %&gt;%\n    mutate(estimate_exp = exp(estimate))\n## Error: object 'mod1' not found\n\nWrite an interpretation of each of the exponentiated coefficients in your logistic regression model."
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-3-interaction-terms",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-3-interaction-terms",
    "title": "Multiple logistic regression (Notes)",
    "section": "Exercise 3: Interaction terms",
    "text": "Exercise 3: Interaction terms\n\nDo you think it would make sense to add an interaction term (between gender and race) to our logistic regression model? Why/why not?\nLet’s try adding an interaction between gender and race. Update the code below to fit this new interaction model.\n\n\n# fit logistic model and save it as object called \"mod2\"\nmod2 &lt;- glm(received_callback ~ ___, data = resume, family = ___)\n## Error in parse(text = input): &lt;text&gt;:2:34: unexpected input\n## 1: # fit logistic model and save it as object called \"mod2\"\n## 2: mod2 &lt;- glm(received_callback ~ __\n##                                     ^\n\nThen, run the code chunk below to get the coefficient estimates and exponentiated estimates for this interaction model, presented in a nicely formatted table:\n\n# print out tidy summary of mod, focusing on estimates & exponentiated estimates\ntidy(mod2) %&gt;%\n    select(term, estimate) %&gt;%\n    mutate(estimate_exp = exp(estimate))\n## Error: object 'mod2' not found\n\n\n(CHALLENGE) Write out the logistic regression model formula separately for males and for females. Based on this how would we interpret the exponentiated coefficients in this model?"
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-4-prediction",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-4-prediction",
    "title": "Multiple logistic regression (Notes)",
    "section": "Exercise 4: Prediction",
    "text": "Exercise 4: Prediction\nWe can use our models to predict whether or not a resume will receive a call back based on the inferred gender and race of the applicant. Run the code below to use the predict() function to predict the probability of getting a call back for four job applicants: a person inferred to be a black female, a person inferred to be black male, a person inferred to be a white female, and a person inferred to be a white male.\n\n# set up data frame with people we want to predict for\npredict_data &lt;- data.frame(\n    gender = c(\"f\", \"m\", \"f\", \"m\"),\n    race = c(\"black\", \"black\", \"white\", \"white\")\n)\nprint(predict_data)\n##   gender  race\n## 1      f black\n## 2      m black\n## 3      f white\n## 4      m white\n\n# prediction based on model without interaction\nmod1 %&gt;%\n    predict(newdata = predict_data, type = \"response\")\n## Error: object 'mod1' not found\n\n# prediction based on model with interaction\nmod2 %&gt;%\n    predict(newdata = predict_data, type = \"response\")\n## Error: object 'mod2' not found\n\nReport and compare the predictions we get from predict(). Do they make sense to you based on your understanding of the data? Combine insights from visualizations and modeling to write a few sentences summarizing findings for our research question: does an applicant’s inferred gender and race have an effect on the chance that they receive a callback after submitting their resume for an open job posting?"
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-5-evaluating-logistic-models-with-plots",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-5-evaluating-logistic-models-with-plots",
    "title": "Multiple logistic regression (Notes)",
    "section": "Exercise 5: Evaluating logistic models with plots",
    "text": "Exercise 5: Evaluating logistic models with plots\nWe’ll fit one more model that adds on to the interaction model to also include years of college, years of work experience, and resume quality. The augment() code takes our fitted models and stores the predicted probabilities in a variable called .fitted. Then we use boxplots to show the predicted probabilities of receiving a callback in those who actually did and did not receive a callback.\n\nmod3 &lt;- glm(received_callback ~ gender*race + years_college + years_experience + resume_quality, data = resume, family = \"binomial\")\n\nmod1_output &lt;- augment(mod1, type.predict = \"response\") # Store predicted probabilities in a variable called .fitted\n## Error: object 'mod1' not found\nmod2_output &lt;- augment(mod2, type.predict = \"response\")\n## Error: object 'mod2' not found\nmod3_output &lt;- augment(mod3, type.predict = \"response\")\n\nggplot(mod1_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot()\n## Error: object 'mod1_output' not found\nggplot(mod2_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot()\n## Error: object 'mod2_output' not found\nggplot(mod3_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nSummarize what you learn about the ability of the 3 models to differentiate those who actually did and did not receive a callback. What model seems best, and why?\nIf you had to draw a horizontal line across each of the boxplots that vertically separates the left and right boxplots well, where would you place them?"
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-6-evaluating-logistic-models-with-evaluation-metrics",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#exercise-6-evaluating-logistic-models-with-evaluation-metrics",
    "title": "Multiple logistic regression (Notes)",
    "section": "Exercise 6: Evaluating logistic models with evaluation metrics",
    "text": "Exercise 6: Evaluating logistic models with evaluation metrics\nSometimes we may need to go beyond the predicted probabilities from our model and try to classify individuals into one of the two binary outcomes (received or did not receive a callback). How high of a predicted probability would we need from our model in order to be convinced that the person actually got a callback? This is the idea behind the horizontal lines that we drew in the previous exercise.\nLet’s explore using a probability threshold of 0.08 (8%) to make a binary prediction for each case:\n\nIf a model’s predicted probability of getting a callback is greater than or equal to 8.5%, we’ll predict they got a callback.\nIf the predicted probability is below 8%, we’ll predict they didn’t get a callback.\n\nWe can visualize this threshold on our predicted probability boxplots:\n\nggplot(mod1_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot() +\n    geom_hline(yintercept = 0.08, color = \"red\")\n## Error: object 'mod1_output' not found\nggplot(mod2_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot() +\n    geom_hline(yintercept = 0.08, color = \"red\")\n## Error: object 'mod2_output' not found\nggplot(mod3_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot() +\n    geom_hline(yintercept = 0.08, color = \"red\")\n\n\n\n\n\n\n\n\nNext, we can use our threshold to classify each person in our dataset based on their predicted probability of getting a callback: we’ll predict that everyone with a predicted probability higher than our threshold got a callback, and otherwise they did not. Then, we’ll compare our model’s prediction to the true outcome (whether or not they actually did get a callback).\n\n# get binary predictions for mod1 and compare to truth\nthreshold &lt;- 0.08\nmod1_output %&gt;%\n    mutate(predictCallback = .fitted &gt;= threshold) %&gt;% ## predict callback if probability greater than or equal to threshold\n    count(received_callback, predictCallback) ## compare actual and predicted callbacks\n## Error: object 'mod1_output' not found\n\nmod2_output %&gt;%\n    mutate(predictCallback = .fitted &gt;= threshold) %&gt;%\n    count(received_callback, predictCallback)\n## Error: object 'mod2_output' not found\n\nmod3_output %&gt;%\n    mutate(predictCallback = .fitted &gt;= threshold) %&gt;%\n    count(received_callback, predictCallback)\n## # A tibble: 4 × 3\n##   received_callback predictCallback     n\n##               &lt;dbl&gt; &lt;lgl&gt;           &lt;int&gt;\n## 1                 0 FALSE            2465\n## 2                 0 TRUE             2013\n## 3                 1 FALSE             159\n## 4                 1 TRUE              233\n\nWe can use the count() output to fill create contingency tables of the results. (These tables are also called confusion matrices.)\n\nFill in the confusion matrix for Model 3.\n\n\nModels 1 and 2: (Both models result in the same confusion matrix.)\n\n\n\n\n\nPredict callback\nPredict no callback\nTotal\n\n\n\n\nActually got callback\n235\n157\n392\n\n\nActually did not\n2200\n2278\n4478\n\n\nTotal\n2435\n2435\n4870\n\n\n\n\nModel 3:\n\n\n\n\n\nPredict callback\nPredict no callback\nTotal\n\n\n\n\nActually got callback\n____\n____\n____\n\n\nActually did not\n____\n____\n____\n\n\nTotal\n____\n____\n____\n\n\n\n\nNow compute the following evaluation metrics for the models:\n\nModels 1 and 2:\n\nAccuracy: P(Predict Y Correctly)\nSensitivity: P(Predict Y = 1 | Actual Y = 1)\nSpecificity: P(Predict Y = 0 | Actual Y = 0)\nFalse negative rate: P(Predict Y = 0 | Actual Y = 1)\nFalse positive rate: P(Predict Y = 1 | Actual Y = 0)\n\nModel 3:\n\nAccuracy: P(Predict Y Correctly)\nSensitivity: P(Predict Y = 1 | Actual Y = 1)\nSpecificity: P(Predict Y = 0 | Actual Y = 0)\nFalse negative rate: P(Predict Y = 0 | Actual Y = 1)\nFalse positive rate: P(Predict Y = 1 | Actual Y = 0)\n\n\nImagine that we are a career center on a college campus and we want to use this model to help students that are looking for jobs. Consider the consequences of incorrectly predicting whether or not an individual will get a callback. What are the consequences of a false negative? What about a false positive? Which one is worse?"
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#reflection",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#reflection",
    "title": "Multiple logistic regression (Notes)",
    "section": "Reflection",
    "text": "Reflection\nWhat are some similarities and differences between how we interpret and evaluate linear and logistic regression models?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/17-logistic-multivariate-evaluation-notes.html#done",
    "href": "template_qmds/17-logistic-multivariate-evaluation-notes.html#done",
    "title": "Multiple logistic regression (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html",
    "href": "template_qmds/15-prob-odds-notes.html",
    "title": "Probability & Odds (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDistinguish between probabilities and odds, and convert one to the other\nMake appropriate visualizations for displaying relationships between multiple categorical variables (mosaic plots, stacked bar plots, etc.)\n\n\n\n\nGo through the following reading or videos before class:\n\nReading: Sections 2.5, and the Section 6.2 introduction in the STAT 155 Notes\nVideos:\n\nProb vs. Odds vs. Log Odds (script)\nCalculating Probability and Odds from 2x2 Tables (script)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html#learning-goals",
    "href": "template_qmds/15-prob-odds-notes.html#learning-goals",
    "title": "Probability & Odds (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDistinguish between probabilities and odds, and convert one to the other\nMake appropriate visualizations for displaying relationships between multiple categorical variables (mosaic plots, stacked bar plots, etc.)"
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html#readings-and-videos",
    "href": "template_qmds/15-prob-odds-notes.html#readings-and-videos",
    "title": "Probability & Odds (Notes)",
    "section": "",
    "text": "Go through the following reading or videos before class:\n\nReading: Sections 2.5, and the Section 6.2 introduction in the STAT 155 Notes\nVideos:\n\nProb vs. Odds vs. Log Odds (script)\nCalculating Probability and Odds from 2x2 Tables (script)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html#exercise-1-exploring-first-steps-enrollment-and-gestational-age",
    "href": "template_qmds/15-prob-odds-notes.html#exercise-1-exploring-first-steps-enrollment-and-gestational-age",
    "title": "Probability & Odds (Notes)",
    "section": "Exercise 1: Exploring First Steps enrollment and Gestational Age",
    "text": "Exercise 1: Exploring First Steps enrollment and Gestational Age\nA baby born prior to 37 weeks is considered premature. In figuring out whether we have evidence that the First Steps program is associated with better birth outcomes than those not in the First Steps program, we can look at whether the individuals in the program are more likely to have preterm babies.\nBelow, we make a 2x2 table in R:\n\n# 2x2 Table: preterm vs. First Steps\nfirststeps %&gt;% \n    count(preterm, firstep)\n## # A tibble: 4 × 3\n##   preterm firstep     n\n##   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n## 1 No            0  1879\n## 2 No            1   343\n## 3 Yes           0   218\n## 4 Yes           1    60\n\nYou may be wondering why this is called a 2x2 table, when it looks as though the table has four rows and three columns. The data can be re-arranged (and usually is, in a formal report) as follows…\n\ntable(firststeps$preterm, firststeps$firstep)\n##      \n##          0    1\n##   No  1879  343\n##   Yes  218   60\n\n… but it’s much cleaner to code up the original way!\n\nHow many birth parents were enrolled in the First Steps program? Which rows did you use to calculate this number?\nWhat percentage of people in the study were enrolled in the First Steps program? Recall: there were 2500 participants! You can confirm this by adding up the entire third column of the table\nHow many birth parents who were enrolled in First Steps had a premature baby?\nWhat percentage of birth parents in First Steps had a premature baby? Think carefully about the numerator and denominator you use to calculate this!\nWhat percentage of birth parents who had a premature baby were enrolled in First Steps? Think carefully about the numerator and denominator you use to calculate this!\n\nCongratulations! If you’ve made it to this point, you already intuitively know what marginal and conditional probabilities are. Formally,\n\na marginal probability, denoted \\(P(A)\\) for an event \\(A\\), is the probability that \\(A\\) occurs overall. You calculated the marginal probability that people were enrolled in First Steps in part (b)! In this case, the denominator used to calculate the probability was the total number of people in the study.\na conditional probability, denoted \\(P(A | B)\\) for events \\(A\\) and \\(B\\), is the probability that \\(A\\) occurs given that event \\(B\\) occurs. You calculated the conditional probability that a premature baby was born given that a parent was in First Steps in part (d)! In this case, the denominator used to calculate the probability was the total number of birth parents in the First Steps program. You also calculated a conditional probability in part (e).\n\nUsing formal probability notation, write the probabilities you calculated in parts (b), (d), and (e) as\n\n\n\\(P(\\text{First Steps})\\) = ___\n\n\n\n\n\\(P(\\text{Preterm} | \\text{First Steps})\\) = ___\n\n\n\n\n\\(P(___ | ___)\\) = __\n\n\nNote that the conditional probabilities calculated in parts (d) and (e) are not the same! This is because which event you condition on alters the denominator, and the event you’re interested in alters the numerator.\n\nTo determine if gestational age differed by enrollment in First Steps, we’ll want to calculate the conditional probability that a baby is born prematurely given First Steps enrollment (done!), and given that a parent is not enrolled in First Steps. Use the 2x2 table to calculated this conditional probability.\n\n\n\\(P(\\text{Preterm} |\\text{Not in First Steps})\\) = ___\n\n\nA ratio of conditional probabilities, where the conditioning event is the same for both, tells us how many times more likely an event is to occur for one group compared to another. Calculate how many times more likely a birth parent enrolled in First Steps is to have a premature baby compared to birth parents not enrolled in First Steps.\n\n\\[\n\\frac{(\\text{Preterm} | \\text{First Steps})}{P(\\text{Preterm} | \\text{Not in First Steps})} =\n\\]\n\nWrite a two-sentence summary, appropriate for a general audience, summarizing your results in terms of a ratio of probabilities. Does gestational age appear to differ greatly by First Steps enrollment? What does this imply about the effectiveness of the First Steps program, if anything?\nTo go along with your summary, let’s make a visualization! There are three basic options for visualization two categorical variables. All are perfectly valid, but some may be more useful to read than others, and display different information.\n\nYou’ll see one other fancier option (called a mosaic plot) in the next activity.\n\n# Side-by-side bar chart\nfirststeps %&gt;%\n  ggplot(aes(firstep, fill = preterm)) +\n  geom_bar(position = \"dodge\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n# Stacked bar chart\nfirststeps %&gt;%\n  ggplot(aes(firstep, fill = preterm)) +\n  geom_bar() +\n  theme_classic()\n\n\n\n\n\n\n\n\n# Stacked relative frequency bar chart\nfirststeps %&gt;%\n  ggplot(aes(firstep, fill = preterm)) +\n  geom_bar(position = \"fill\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nBonus Question: Which of the above three plots allows you to directly see the conditional probabilities we calculated previously?\n\nPlace your answer here"
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html#exercise-2-exploring-first-steps-enrollment-and-low-birthweights",
    "href": "template_qmds/15-prob-odds-notes.html#exercise-2-exploring-first-steps-enrollment-and-low-birthweights",
    "title": "Probability & Odds (Notes)",
    "section": "Exercise 2: Exploring First Steps enrollment and Low birthweights",
    "text": "Exercise 2: Exploring First Steps enrollment and Low birthweights\nAnother birth outcome we can consider when comparing those enrolled in the First Steps program to those not enrolled is birth weight. A baby is considered to have low birth weight when birth weight is less than 2500 grams.\n\nFill in the code below to make a table comparing low_bwt to firsteps.\n\n\n# 2x2 Table: low_bwt vs. First Steps\n\n\nUsing the table from part (a), calculate the following conditional probabilities:\n\n\n\\(P(\\text{Low birth weight} | \\text{First Steps})\\) = ___\n\n\n\\(P(\\text{Normal birth weight} | \\text{First Steps})\\) = ___\n\n\n\\(P(\\text{Low birth weight} | \\text{Not in First Steps})\\) = ___\n\n\n\\(P(\\text{Normal birth weight} | \\text{Not in First Steps})\\) = ___\n\nAn additional numerical summary that is often useful when working with indicator variables is odds. Odds are defined as\n\\[\nOdds = \\frac{p}{1 - p}\n\\]\nwhere \\(p\\) is the probability that an event occurs. Therefore, if we know \\(p\\), we can calculate the odds that an event happens! Similarly, if we know the odds, we can calculate \\(p\\) using\n\\[\np = Odds / (1 + Odds)\n\\]\nWe can also calculate odds from our 2x2 (or 3x2, 4x2, …) tables. In colloquial terms, probabilities are “yes”’s over “total”’s, and odds are “yes”’s over “no’s”. In pseudo-math:\n\\[\np = \\frac{Yes}{Total}, \\quad Odds = \\frac{Yes}{No}\n\\] We’ll see why odds are especially useful when we have binary outcome variables in a regression model in the next activity. For now, note that they’re also commonly used in lots of contexts: sports, gambling, case-control studies, etc.\n\nUsing your answer to part (b), calculate the following odds\n\n\n\\(Odds(\\text{Low birth weight} | \\text{First Steps})\\) = ___\n\n\n\\(Odds(\\text{Normal birth weight} | \\text{First Steps})\\) = ___\n\n\n\\(Odds(\\text{Low birth weight} | \\text{Not in First Steps})\\) = ___\n\n\n\\(Odds(\\text{Normal birth weight} | \\text{Not in First Steps})\\) = ___\n\n\nA ratio of odds (called an odds ratio, unsurprisingly) tells us how many times higher or greater the odds are that an event occurs, comparing one group to another. This might sound irritatingly circular. The key here is that while odds ratios do allow us to compare binary/indicator outcomes from one group to one another, they do not tell us how much more likely an event is to occur comparing those same groups. This is distinct from ratios of probabilities!\n\nCalculate the ratio of the odds of having a low-birth-weight baby, comparing those in the First Steps program to those not in the First Steps program (i.e., how many times higher/lower is the odds of having a low-birth-weight baby among those in First Steps as compared to those not in First Steps?)\n\nWrite a two-sentence summary, appropriate for a general audience, summarizing your results in terms of an odds ratio. Does birth weight appear to differ greatly by First Steps enrollment? What does this imply about the effectiveness of the First Steps program, if anything?\nTo go along with your summary, add code below to make one of the three visualization options we tried out in Exercise 1.\n\n\n# Insert code here..."
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html#reflection",
    "href": "template_qmds/15-prob-odds-notes.html#reflection",
    "title": "Probability & Odds (Notes)",
    "section": "Reflection",
    "text": "Reflection\nPrompt\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html#render-your-work",
    "href": "template_qmds/15-prob-odds-notes.html#render-your-work",
    "title": "Probability & Odds (Notes)",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check."
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html#exercise-3-conditional-vs.-marginal-probabilities",
    "href": "template_qmds/15-prob-odds-notes.html#exercise-3-conditional-vs.-marginal-probabilities",
    "title": "Probability & Odds (Notes)",
    "section": "Exercise 3: Conditional vs. Marginal probabilities",
    "text": "Exercise 3: Conditional vs. Marginal probabilities\nSuppose we select a person at random from the entire global population. For each of the following probabilities, which do you think is bigger? Explain your reasoning.\n\nP(lung cancer) or P(lung cancer | smoker)\n\n\nYour response here\n\n\nP(likes McDonald’s) or P(likes McDonald’s | vegetarian)\n\n\nYour response here\n\n\nP(smart | Mac grad) or P(Mac grad | smart)\n\n\nYour response here"
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html#exercise-4-probability-practice",
    "href": "template_qmds/15-prob-odds-notes.html#exercise-4-probability-practice",
    "title": "Probability & Odds (Notes)",
    "section": "Exercise 4: Probability practice",
    "text": "Exercise 4: Probability practice\nLet’s explore whether birthweight of a baby varies by whether or not it was the first child that a mother had, and whether this relationship differs by First Steps enrollment. We make a table below:\n\nfirststeps %&gt;%\n  count(firstchild, low_bwt, firstep)\n## # A tibble: 8 × 4\n##   firstchild low_bwt firstep     n\n##   &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n## 1 No         low           0    43\n## 2 No         low           1    13\n## 3 No         not low       0  1080\n## 4 No         not low       1   198\n## 5 Yes        low           0    59\n## 6 Yes        low           1    12\n## 7 Yes        not low       0   915\n## 8 Yes        not low       1   180\n\n\nWhat is the probability that a mother enrolled in First steps who is having their first child, has a baby who is born at a low birthweight? Calculate your answer, and write it using formal probability notation.\n\n\nP(___ | ___) = ?\n\n\nWhat is the probability that a mother not enrolled in First steps who is having their first child, has a baby who is born at a low birthweight? Calculate your answer, and write it using formal probability notation.\n\n\nP(___ | ___) = ?\n\n\nWhat is the probability that a mother’s first child has a low birthweight? Calculate your answer, and write it using formal probability notation.\n\n\nP(___ | ___) = ?\n\n\nHow many times more likely is a child to be born at a low birthweight, comparing children who are the first born to those not first born?\n\n\nP(___ | ) / P( | ___) = ?"
  },
  {
    "objectID": "template_qmds/15-prob-odds-notes.html#done",
    "href": "template_qmds/15-prob-odds-notes.html#done",
    "title": "Probability & Odds (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/13-mlr-model-building-1-notes.html",
    "href": "template_qmds/13-mlr-model-building-1-notes.html",
    "title": "Multiple linear regression: model building (part 1) (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDistinguish between descriptive, predictive, and causal research questions\nIterate on your group’s research question to make it more precise and answerable\nChoose appropriate model(s) for addressing your group’s research question\n\n\n\n\nPlease watch the following video before class.\n\nVideo: Causal Diagrams and Confounding Variables\n\nFile organization: If you would like to take notes in this document, download the template and save it in the “Activities” subfolder of your “STAT155” folder. You are more than welcome to take notes in a separate google document, shared with your project group, if you’d find that more useful!"
  },
  {
    "objectID": "template_qmds/13-mlr-model-building-1-notes.html#learning-goals",
    "href": "template_qmds/13-mlr-model-building-1-notes.html#learning-goals",
    "title": "Multiple linear regression: model building (part 1) (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDistinguish between descriptive, predictive, and causal research questions\nIterate on your group’s research question to make it more precise and answerable\nChoose appropriate model(s) for addressing your group’s research question"
  },
  {
    "objectID": "template_qmds/13-mlr-model-building-1-notes.html#readings-and-videos",
    "href": "template_qmds/13-mlr-model-building-1-notes.html#readings-and-videos",
    "title": "Multiple linear regression: model building (part 1) (Notes)",
    "section": "",
    "text": "Please watch the following video before class.\n\nVideo: Causal Diagrams and Confounding Variables\n\nFile organization: If you would like to take notes in this document, download the template and save it in the “Activities” subfolder of your “STAT155” folder. You are more than welcome to take notes in a separate google document, shared with your project group, if you’d find that more useful!"
  },
  {
    "objectID": "template_qmds/13-mlr-model-building-1-notes.html#step-1-review",
    "href": "template_qmds/13-mlr-model-building-1-notes.html#step-1-review",
    "title": "Multiple linear regression: model building (part 1) (Notes)",
    "section": "Step 1: Review",
    "text": "Step 1: Review\nTake a look at the first project checkpoint (your statistical analysis plan) that your group submitted. As part of this checkpoint, you should have come up with a research question. Record the research question you came up with: we’ll iterate on this question throughout the activity!\n\nRecord your research question here\n\nAnswer the following questions as a group (some of this may already be in your statistical analysis plan!):\n\nWho would be interested in the answer to this question?\nWhat variables do you need in a dataset to address this question?\nWhat data summaries (not models) would help you answer this question, and why?\nWhat plots (not models) would help you address your research question, and why?"
  },
  {
    "objectID": "template_qmds/13-mlr-model-building-1-notes.html#step-2-descriptive-research-questions",
    "href": "template_qmds/13-mlr-model-building-1-notes.html#step-2-descriptive-research-questions",
    "title": "Multiple linear regression: model building (part 1) (Notes)",
    "section": "Step 2: Descriptive Research Questions",
    "text": "Step 2: Descriptive Research Questions\nDescriptive research questions are questions that seek to better understand the relationships between variables, without interest in causality. In practice, nearly every research question asked is ultimately interested in causality, but practical constraints (such as unmeasured confounding) lead us to ask descriptive questions instead.\nIf we’re only interested in associations (not causality), we don’t need to adjust for potential confounding variables in our model.\n\nFor your group’s chosen research question, write a model statement that would address a descriptive version of your research question below:\n\nModel statement for a descriptive question here"
  },
  {
    "objectID": "template_qmds/13-mlr-model-building-1-notes.html#step-3-predictive-research-questions",
    "href": "template_qmds/13-mlr-model-building-1-notes.html#step-3-predictive-research-questions",
    "title": "Multiple linear regression: model building (part 1) (Notes)",
    "section": "Step 3: Predictive Research Questions",
    "text": "Step 3: Predictive Research Questions\nPredictive research questions seek to determine if (and how well) we can predict outcomes for new / future events, using the information we already have. We’ve seen a bit of prediction in this course when we talked about fitted values!\n\nWith your groups, discuss the following:\n\nIs your research question predictive, or inferential? Inferential questions seek to understand the relationships between variables.\nIf your question were predictive, who would be interested/invested in the results from your project? How could the results from your project be used in practice?\nAre there any variables that are not available to you in your data that you would include in your predictive model if you could? Why or why not?"
  },
  {
    "objectID": "template_qmds/13-mlr-model-building-1-notes.html#step-3-causal-research-questions",
    "href": "template_qmds/13-mlr-model-building-1-notes.html#step-3-causal-research-questions",
    "title": "Multiple linear regression: model building (part 1) (Notes)",
    "section": "Step 3: Causal Research Questions",
    "text": "Step 3: Causal Research Questions\nCausal research questions are ultimately what most inferential statistics is interested in, regardless of whether or not we end up being able to make causal conclusions. From the videos for today, you learned about different types of variables, and whether or not they should be included or excluded from a model, depending on your causal research question.\nWith your groups, make a causal diagram (DAG) on the whiteboard for your research question. Consider including all variables you wish you had access to, even if they aren’t available in your data (this will help you later when talking about limitations of your analysis in your final paper), but certainly include relevant variables that are available in your data.\nFor each variable in your DAG that is available in your dataset, determine whether it should be included or excluded from your model. Use this to update your descriptive model statement from Step 2.\n\nModel statement for a causal question here\n\nNow look back at your DAG, and note if any of the variables that are not available in your data are potential confounders. If so, record them here (this means you likely won’t be able to draw causal conclusions):\n\nList of “unmeasured” confounding variables here"
  },
  {
    "objectID": "template_qmds/13-mlr-model-building-1-notes.html#step-4-reflection",
    "href": "template_qmds/13-mlr-model-building-1-notes.html#step-4-reflection",
    "title": "Multiple linear regression: model building (part 1) (Notes)",
    "section": "Step 4: Reflection",
    "text": "Step 4: Reflection\nToday was all about iterating on a research question, and using those questions to guide the way we explore data and fit statistical models. How confident do you feel in distinguishing between descriptive, predictive, and causal research questions? How confident do you feel in knowing which components of a model matter more or less, in each specific case? What might help you feel more confident?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/13-mlr-model-building-1-notes.html#done",
    "href": "template_qmds/13-mlr-model-building-1-notes.html#done",
    "title": "Multiple linear regression: model building (part 1) (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/11-mlr-interaction-explore-notes.html",
    "href": "template_qmds/11-mlr-interaction-explore-notes.html",
    "title": "Multiple linear regression: exploring interaction (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDescribe when it would be useful to include an interaction term to a model\nWrite a model formula for an interaction model\nInterpret the coefficients in an interaction model in the data context\n\n\n\n\nToday is a day to discover ideas, so no readings or videos to go through before class.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/11-mlr-interaction-explore-notes.html#learning-goals",
    "href": "template_qmds/11-mlr-interaction-explore-notes.html#learning-goals",
    "title": "Multiple linear regression: exploring interaction (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDescribe when it would be useful to include an interaction term to a model\nWrite a model formula for an interaction model\nInterpret the coefficients in an interaction model in the data context"
  },
  {
    "objectID": "template_qmds/11-mlr-interaction-explore-notes.html#readings-and-videos",
    "href": "template_qmds/11-mlr-interaction-explore-notes.html#readings-and-videos",
    "title": "Multiple linear regression: exploring interaction (Notes)",
    "section": "",
    "text": "Today is a day to discover ideas, so no readings or videos to go through before class.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/11-mlr-interaction-explore-notes.html#exercise-1-wages-across-all-industries",
    "href": "template_qmds/11-mlr-interaction-explore-notes.html#exercise-1-wages-across-all-industries",
    "title": "Multiple linear regression: exploring interaction (Notes)",
    "section": "Exercise 1: Wages across all industries",
    "text": "Exercise 1: Wages across all industries\nThe plot below illustrates the relationship between wage and education for all of the industries in our cps dataset.\n\n# Plot\nggplot(cps, aes(y = wage, x = education, color = industry)) + \n    geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\nWhat about this plot indicates that it would be a good idea to fit an interaction model?\nWhat industry will R use as the reference category?\n(Challenge!) Before fitting the model in R, write down what you think the model formula will look like.\nFit a model that includes an interaction term between education and industry.\n\n\n# Fit an interaction model called wage_model\n\n\n# Display summarized model output\n\n\nIn what industry do wages increase the most per additional year of education? What is this increase?\nSimilarly, in what industry do wages increase the least per additional year of education? What is this increase?"
  },
  {
    "objectID": "template_qmds/11-mlr-interaction-explore-notes.html#exercise-2-thinking-beyond",
    "href": "template_qmds/11-mlr-interaction-explore-notes.html#exercise-2-thinking-beyond",
    "title": "Multiple linear regression: exploring interaction (Notes)",
    "section": "Exercise 2: Thinking beyond",
    "text": "Exercise 2: Thinking beyond\nDo you think there are other variables (which may or may not be in our cps data) that have an interaction with industry in affecting wages? If you were to fit an interaction model, what results might you expect to find?"
  },
  {
    "objectID": "template_qmds/11-mlr-interaction-explore-notes.html#reflection",
    "href": "template_qmds/11-mlr-interaction-explore-notes.html#reflection",
    "title": "Multiple linear regression: exploring interaction (Notes)",
    "section": "Reflection",
    "text": "Reflection\nThrough the exercises above, we developed ideas about when to fit interaction models and how to interpret results. Describe what makes sense and what is still unclear about this topic.\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/11-mlr-interaction-explore-notes.html#done",
    "href": "template_qmds/11-mlr-interaction-explore-notes.html#done",
    "title": "Multiple linear regression: exploring interaction (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html",
    "href": "template_qmds/09-mlr-principles-notes.html",
    "title": "Multiple regression principles (Notes)",
    "section": "",
    "text": "Working with multiple predictors in our plots and models can get complicated!\nThere are no recipes for this process.\nBUT there are some guiding principles that assist in long-term retention, deeper understanding, and the ability to generalize our tools in new settings.\nBy the end of this lesson, you should be familiar with some general principles for…\n\nincorporating additional quantitative or categorical predictors in a visualization\nhow additional quantitative or categorical predictors impact the physical representation of a model\ninterpreting quantitative or categorical coefficients in a multiple regression model\n\n\n\n\nPlease watch the following video before class.\n\nInterpreting multivariate models (slides)"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#learning-goals",
    "href": "template_qmds/09-mlr-principles-notes.html#learning-goals",
    "title": "Multiple regression principles (Notes)",
    "section": "",
    "text": "Working with multiple predictors in our plots and models can get complicated!\nThere are no recipes for this process.\nBUT there are some guiding principles that assist in long-term retention, deeper understanding, and the ability to generalize our tools in new settings.\nBy the end of this lesson, you should be familiar with some general principles for…\n\nincorporating additional quantitative or categorical predictors in a visualization\nhow additional quantitative or categorical predictors impact the physical representation of a model\ninterpreting quantitative or categorical coefficients in a multiple regression model"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#readings-and-videos",
    "href": "template_qmds/09-mlr-principles-notes.html#readings-and-videos",
    "title": "Multiple regression principles (Notes)",
    "section": "",
    "text": "Please watch the following video before class.\n\nInterpreting multivariate models (slides)"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-1-review-visualization",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-1-review-visualization",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 1: Review visualization",
    "text": "Exercise 1: Review visualization\nLet’s build a model of rides by windspeed (quantitative) and weekend status (categorical).\n\nWrite a model statement for this regression model.\nPlot & describe, in words, the relationship between these 3 variables.\n\n\n# Plot of rides vs windspeed & weekend\n# HINT: Start with a plot of rides vs windspeed, then add an aesthetic for weekend!"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-2-review-model",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-2-review-model",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 2: Review model",
    "text": "Exercise 2: Review model\nLet’s build the model. Run the following code:\n\nbike_model_1 &lt;- lm(rides ~ windspeed + weekend, data = bikes)\ncoef(summary(bike_model_1))\n##               Estimate Std. Error   t value      Pr(&gt;|t|)\n## (Intercept) 4738.38053  147.53653 32.116659 1.208405e-141\n## windspeed    -63.97072   10.45274 -6.119997  1.528443e-09\n## weekendTRUE -925.15701  119.86330 -7.718434  3.891082e-14\n\nThe model formula with our coefficient estimates filled in is therefore:\nE[rides | windspeed, weekendTRUE] = 4738.38 - 63.97 * windspeed - 925.16 * weekendTRUE\nThis model formula is represented by 2 lines, one corresponding to weekends and the other to weekdays. Simplify the model formula above for weekdays and weekends:\nweekdays: rides = ___ - ___ windspeed\nweekends: rides = ___ - ___ windspeed"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-3-review-coefficient-interpretation",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-3-review-coefficient-interpretation",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 3: Review coefficient interpretation",
    "text": "Exercise 3: Review coefficient interpretation\n\nThe intercept coefficient, 4738.38, represents the intercept of the sub-model for weekdays, the reference category. What’s its contextual interpretation?\nThe windspeed coefficient, -63.97, represents the shared slope of the weekend and weekday sub-models. What’s its contextual interpretation?\nThe weekendTRUE coefficient, -925.16, represents the change in intercept for the weekend vs weekday sub-model. What’s its contextual interpretation?"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-4-2-categorical-predictors-visualization",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-4-2-categorical-predictors-visualization",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 4: 2 categorical predictors – visualization",
    "text": "Exercise 4: 2 categorical predictors – visualization\nThus far, we’ve explored a couple examples of multiple regression models that have 2 predictors, 1 quantitative and 1 categorical.\nSo what happens when both predictors are categorical?!\nTo this end, let’s model rides by weekend status and season.\nThe below code plots rides vs season.\nModify this code to also include information about weekend.\nHINT: Remember the visualization principle that additional categorical predictors require some sort of grouping mechanism / mechanism that distinguishes between the 2 groups.\n\n# rides vs season\nbikes %&gt;% \n  ggplot(aes(y = rides, x = season)) + \n  geom_boxplot()\n\n# rides vs season AND weekend\nbikes %&gt;%\n  ggplot(aes(y = rides, x = season, ___ = ___)) +\n  geom_boxplot()\n## Error in parse(text = input): &lt;text&gt;:8:38: unexpected input\n## 7: bikes %&gt;%\n## 8:   ggplot(aes(y = rides, x = season, __\n##                                         ^"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-5-follow-up",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-5-follow-up",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 5: follow-up",
    "text": "Exercise 5: follow-up\n\nDescribe (in words) the relationship of ridership with season & weekend status.\nA model of rides by season alone would be represented by only 4 expected outcomes, 1 for each season. Considering this and the plot above, how do you anticipate a model of rides by season and weekend status will be represented?\n\n2 lines, 1 for each weekend status\n8 lines, 1 for each possible combination of season & weekend\n2 expected outcomes, 1 for each weekend status\n8 expected outcomes, 1 for each possible combination of season & weekend"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-6-2-categorical-predictors-build-the-model",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-6-2-categorical-predictors-build-the-model",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 6: 2 categorical predictors – build the model",
    "text": "Exercise 6: 2 categorical predictors – build the model\nLet’s build the multiple regression model of rides vs season and weekend:\n\nbike_model_2 &lt;- lm(rides ~ weekend + season, bikes)\ncoef(summary(bike_model_2))\n##                Estimate Std. Error     t value      Pr(&gt;|t|)\n## (Intercept)   4260.4492   99.16363  42.9638294 1.384994e-201\n## weekendTRUE   -912.3324  103.23016  -8.8378473  7.298199e-18\n## seasonspring  -116.3824  132.76018  -0.8766364  3.809741e-01\n## seasonsummer   438.4424  132.06413   3.3199205  9.454177e-04\n## seasonwinter -1719.0572  133.30505 -12.8956646  2.081758e-34\n\nThus the model formula with coefficient estimates filled in is given by:\nE[rides | weekend, season] = 4260.45 - 912.33 weekendTRUE - 116.38 seasonspring + 438.44 seasonsummer - 1719.06 seasonwinter\n\nUse this model to predict the ridership on the following days:\n\n\n# a fall weekday\n4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___\n\n# a winter weekday    \n4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___\n\n# a fall weekend day        \n4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___\n\n# a winter weekend day\n4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___\n## Error in parse(text = input): &lt;text&gt;:2:19: unexpected input\n## 1: # a fall weekday\n## 2: 4260.45 - 912.33*__\n##                      ^\n\n\nWe only made 4 predictions here. How many possible predictions does this model produce? Is this consistent with your intuition in the previous exercise?"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-7-2-categorical-predictors-interpret-the-model",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-7-2-categorical-predictors-interpret-the-model",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 7: 2 categorical predictors – interpret the model",
    "text": "Exercise 7: 2 categorical predictors – interpret the model\nUse your above predictions and visualization to fill in the below interpretations of the model coefficients.\nHint: What is the consequence of plugging in 0 or 1 for the different weekend and season categories?\n\nInterpreting 4260: On average, we expect there to be 4260 riders on (weekdays/weekends) during the (fall/spring/summer/winter).\nInterpreting -912: On average, in any season, we expect there to be 912 (more/fewer) riders on weekends than on ___.\n\nAn alternative interpretation: On average, we expect there to be 912 (more/fewer) riders on weekends than on ___, adjusting for season.\n\nInterpreting -1719: On average, on both weekdays and weekends, we expect there to be 1719 (more/fewer) riders in winter than in ___.\n\nAn alternative interpretation: On average, we expect there to be 1719 (more/fewer) riders in winter than in ___, controlling for weekday status."
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-8-2-quantitative-predictors-visualization",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-8-2-quantitative-predictors-visualization",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 8: 2 quantitative predictors – visualization",
    "text": "Exercise 8: 2 quantitative predictors – visualization\nNext, consider the relationship between rides and 2 quantitative predictors: windspeed and temp_feel. Check out the plot of this relationship below.\nThis reflect the visualization principle that quantitative variables require some sort of numerical scaling mechanism – rides and windspeed get numerical axes, and temp_feel gets a color scale.\n\nModify the code below to recreate this plot.\n\nbikes %&gt;%\n  ggplot(aes(y = rides, x = windspeed, ___ = ___)) +\n  geom_point()\n## Error in parse(text = input): &lt;text&gt;:2:41: unexpected input\n## 1: bikes %&gt;%\n## 2:   ggplot(aes(y = rides, x = windspeed, __\n##                                            ^"
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-9-follow-up",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-9-follow-up",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 9: follow-up",
    "text": "Exercise 9: follow-up\nDescribe (in words) the relationship of ridership with windspeed & temperature."
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-10-2-quantitative-predictors-modeling",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-10-2-quantitative-predictors-modeling",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 10: 2 quantitative predictors – modeling",
    "text": "Exercise 10: 2 quantitative predictors – modeling\nLet’s build the multiple regression model of rides vs windspeed and temp_feel:\n\nbike_model_3 &lt;- lm(rides ~ windspeed + temp_feel, data = bikes)\ncoef(summary(bike_model_3))\n##              Estimate Std. Error     t value     Pr(&gt;|t|)\n## (Intercept) -24.06464 299.303032 -0.08040225 9.359394e-01\n## windspeed   -36.54372   9.408116 -3.88427585 1.119805e-04\n## temp_feel    55.51648   3.330739 16.66791759 4.436963e-53\n\nThus the model formula with coefficient estimates filled in is given by,\nE[rides | windspeed, temp_feel] = -24.06 - 36.54 windspeed + 55.52 temp_feel\n\nInterpret the intercept coefficient, -24.06, in context.\nInterpret the windspeed coefficient, -36.54, in context.\nInterpret the temp_feel coefficient, 55.52, in context."
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-11-which-is-best",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-11-which-is-best",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 11: Which is “best”?",
    "text": "Exercise 11: Which is “best”?\nWe’ve now observed 3 different models of ridership, each having 2 predictors. The R-squared values of these models, along with those of the simple linear regression models with each predictor alone, are summarized below.\n\n\n\nmodel\npredictors\nR-squared\n\n\n\n\nbike_model_1\nwindspeed & weekend\n0.119\n\n\nbike_model_2\nweekend & season\n0.349\n\n\nbike_model_3\nwindspeed & temp_feel\n0.310\n\n\nbike_model_4\nwindspeed\n0.047\n\n\nbike_model_5\ntemp_feel\n0.296\n\n\nbike_model_6\nweekend\n0.074\n\n\nbike_model_7\nseason\n0.279\n\n\n\n\nWhich model does the best job of explaining the variability in ridership from day to day?\nIf you could only pick one predictor, which would it be?\nWhat happens to R-squared when we add a second predictor to our model, and why does this make sense? For example, how does the R-squared for model 1 (with both windspeed and weekend) compare to those of model 4 (only windspeed) and model 6 (only weekend)?\nAre 2 predictors always better than 1? Provide evidence and explain why this makes sense."
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-12-principles-of-interpretation",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-12-principles-of-interpretation",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 12: Principles of interpretation",
    "text": "Exercise 12: Principles of interpretation\nThese exercises have revealed some principles behind interpreting model coefficients, summarized below.\nReview and confirm that these make sense.\n\nPrinciples of interpretation\nConsider a multiple linear regression model:\n\\[E[Y | X_1, X_2, ..., X_p] = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\]\nWe can interpret the coefficients as follows:\n\n\\(\\beta_0\\) (“beta 0”) is the y-intercept. It describes the average value of \\(Y\\) when \\(X_1, X_2,..., X_k\\) are all 0, ie. when all quantitative predictors are set to 0 and the categorical predictors are set to their reference levels.\n\\(\\beta_i\\) (“beta i”) is the coefficient of \\(X_i\\).\n\nIf \\(X_i\\) is quantitative, \\(\\beta_i\\) describes the average change in \\(Y\\) associated with a 1-unit increase in \\(X_i\\) while at a fixed set of the other \\(X\\).\nIf \\(X_i\\) represents a category of a categorical variable, \\(\\beta_i\\) describes the average difference in \\(Y\\) between this category and the reference category, while at a fixed set of the other \\(X\\)."
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-13-practice-1",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-13-practice-1",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 13: Practice 1",
    "text": "Exercise 13: Practice 1\nConsider the relationship of rides vs weekend and weather_cat.\n\nConstruct a visualization of this relationship.\n\nConstruct a model of this relationship.\n\nInterpret the first 3 model coefficients."
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-14-practice-2",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-14-practice-2",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 14: Practice 2",
    "text": "Exercise 14: Practice 2\nConsider the relationship of rides vs temp_feel and humidity.\n\nConstruct a visualization of this relationship.\n\nConstruct a model of this relationship.\n\nInterpret the first 3 model coefficients."
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-15-practice-3",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-15-practice-3",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 15: Practice 3",
    "text": "Exercise 15: Practice 3\nConsider the relationship of rides vs temp_feel and weather_cat.\n\nConstruct a visualization of this relationship.\n\nConstruct a model of this relationship.\n\nInterpret the first 3 model coefficients."
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#exercise-16-challenge",
    "href": "template_qmds/09-mlr-principles-notes.html#exercise-16-challenge",
    "title": "Multiple regression principles (Notes)",
    "section": "Exercise 16: CHALLENGE",
    "text": "Exercise 16: CHALLENGE\nWe’ve explored models with 2 predictors. What about 3 predictors?! Consider the relationship of rides vs temp_feel, humidity, AND weekend.\n\nConstruct a visualization of this relationship.\n\nConstruct a model of this relationship.\n\nInterpret each model coefficient."
  },
  {
    "objectID": "template_qmds/09-mlr-principles-notes.html#done",
    "href": "template_qmds/09-mlr-principles-notes.html#done",
    "title": "Multiple regression principles (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html",
    "href": "template_qmds/07-slr-cat-predictor-notes.html",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nWrite a model formula for a simple linear regression model with a categorical predictor using indicator variables\nInterpret the intercept and slope coefficients in a simple linear regression model with a categorical predictor\n\n\n\n\nComplete both the reading and the videos to go through before class.\n\nReading: Section 3.9 in the STAT 155 Notes only up through section 3.9.1 Indicator Variables\nVideos:\n\nSimple linear regression: categorical predictor (slides)\nR Code for Categorical Predictors\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#learning-goals",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#learning-goals",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nWrite a model formula for a simple linear regression model with a categorical predictor using indicator variables\nInterpret the intercept and slope coefficients in a simple linear regression model with a categorical predictor"
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#readings-and-videos",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#readings-and-videos",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "",
    "text": "Complete both the reading and the videos to go through before class.\n\nReading: Section 3.9 in the STAT 155 Notes only up through section 3.9.1 Indicator Variables\nVideos:\n\nSimple linear regression: categorical predictor (slides)\nR Code for Categorical Predictors\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-1-get-to-know-the-data",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nWrite R code to answer the following:\n\nHow many cases and variables do we have? What does a case represent?\nWhat do the first few rows of the data look like?\nConstruct and interpret two different visualizations of the price variable.\nConstruct and interpret a visualization of the cut variable."
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-2-visualizations",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-2-visualizations",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 2: Visualizations",
    "text": "Exercise 2: Visualizations\nStart by visualizing this relationship of interest, that between price and cut.\n\nThe appropriate plot depends upon the type of variables we’re plotting. When exploring the relationship between a quantitative response (price) and a quantitative predictor (cut), a scatterplot was an effective choice. After running the code below, explain why a scatterplot is not effective for exploring the relationship between ridership and our categorical cut predictor.\n\n\n# Try a scatterplot\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_point()\n\n\n\n\n\n\n\n\n\nSeparately run each chunk below, with two plots. Comment (#) on what changes in the code / output.\n\n\n# Univariate boxplot\nggplot(diamonds, aes(y = price)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n# ???\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n# Univariate density plot\nggplot(diamonds, aes(x = price)) + \n    geom_density()\n\n\n\n\n\n\n\n\n\n# ???\nggplot(diamonds, aes(x = price, color = cut)) + \n    geom_density()\n\n\n\n\n\n\n\n\n\n# Univariate histogram\nggplot(diamonds, aes(x = price)) + \n    geom_histogram()\n\n\n\n\n\n\n\n\n\n# ???\nggplot(diamonds, aes(x = price)) + \n    geom_histogram() + \n    facet_wrap(~ cut)\n\n\n\n\n\n\n\n\n\nDo you notice anything interesting about the relationship between price and cut? What do you think might be happening here?"
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-3-numerical-summaries",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-3-numerical-summaries",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 3: Numerical summaries",
    "text": "Exercise 3: Numerical summaries\nLet’s follow up our plots with some numerical summaries.\n\nTo warm up, first calculate the mean price across all diamonds.\n\n\ndiamonds %&gt;% \n    ___(mean(___))\n## Error in parse(text = input): &lt;text&gt;:2:6: unexpected input\n## 1: diamonds %&gt;% \n## 2:     __\n##         ^\n\n\nTo summarize the trends we observed in the grouped plots above, we can calculate the mean price for each type of cut. This requires the inclusion of the group_by() function:\n\n\n# Calculate mean price by cut\ndiamonds %&gt;% \n    group_by(cut) %&gt;% \n    ___(mean(___))\n## Error in parse(text = input): &lt;text&gt;:4:6: unexpected input\n## 3:     group_by(cut) %&gt;% \n## 4:     __\n##         ^\n\n\nExamine the group mean measurements, and make sure that you can match these numbers up with what you see in the plots.\nBased on the results above, we can see that, on average, diamonds with a “Fair” cut tend to cost more than higher-quality cuts. Let’s construct a new variable named cutFair, using on the following criteria:\n\n\ncutFair = 1 if the diamond is of Fair cut\ncutFair = 0 otherwise (any other value of cut (Good, Very Good, Premium, Ideal))\n\nThe ifelse function allows to create a new variable from an existing one, based on whether or not the values in that variable meet a certain “condition” (remember, you can always look up function documentation in R by typing ?ifelse in the Console, and hitting enter!).\nFill in the following code to create cutFair. The condition was given to you already. Try to use this to complete the code.\n\n# In the first blank, put what value cutFair should have if the condition is \"met\", or TRUE\n# In the second blank, put what value cutFair should have if the condition is \"not met\", or FALSE\ndiamonds &lt;- diamonds %&gt;%\n  mutate(cutFair=ifelse(cut == \"Fair\", ___, ___))\n## Error in parse(text = input): &lt;text&gt;:4:41: unexpected input\n## 3: diamonds &lt;- diamonds %&gt;%\n## 4:   mutate(cutFair=ifelse(cut == \"Fair\", __\n##                                            ^\n\nVariables like cutFair that are coded as 0/1 to numerically indicate if a categorical variable is at a particular state are known as an indicator variable. You will sometimes see these referred to as a “binary variable” or “dichotomous variable”; you may also encounter the term “dummy variable” in older statistical literature.\n\nNow, let’s calculate the group means based on the new cutFair indicator variable:\n\n\ndiamonds %&gt;% \n    group_by(cutFair) %&gt;% \n    summarize(mean(price))\n## Error in `group_by()`:\n## ! Must group by variables found in `.data`.\n## ✖ Column `cutFair` is not found."
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories",
    "text": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories\nNext, let’s model the trend in the relationship between the cutFair and price variables using a simple linear regression model:\n\n# Construct the model\ndiamond_mod0 &lt;- lm(price ~ cutFair, data = diamonds)\n## Error in eval(predvars, data, env): object 'cutFair' not found\n\n# Summarize the model\ncoef(summary(diamond_mod0))\n## Error: object 'diamond_mod0' not found\n\nCompare these results to the output of exercise 3e. What do you notice? How do you interpret the intercept and cutFair coefficient terms from this model?\n\nyour answer here"
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 5: Modeling trend using a categorical predictor with >2 categories",
    "text": "Exercise 5: Modeling trend using a categorical predictor with &gt;2 categories\nUsing a single binary predictor like the cutFair indicator variable is useful when there are two clearly delineated categories. However, the cut variable actually contains 5 categories! Because we’ve collapsed all non-Fair classifications into a single category (i.e. cutFair = 0), the model above can’t tell us anything about the difference in expected price between, say, Premium and Ideal cuts. The good news is that it is very straightforward to model categorical predictors with &gt;2 categories. We can do this by using the cut variable as our predictor:\n\n# Construct the model\ndiamond_mod &lt;- lm(price ~ cut, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod))\n##               Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept)  4358.7578   98.78795 44.122361 0.000000e+00\n## cutGood      -429.8933  113.84940 -3.775982 1.595493e-04\n## cutVery Good -376.9979  105.16422 -3.584849 3.375707e-04\n## cutPremium    225.4999  104.39521  2.160060 3.077240e-02\n## cutIdeal     -901.2158  102.41155 -8.799943 1.408406e-18\n\n\nEven though we specified a single predictor variable in the model, we are seeing 4 coefficient estimates–why do you think this is the case?\n\n\nyour answer here\n\n\nNOTE: We see 4 indicator variables (for Good, Very Good, Premium, and Ideal), but we do not see cutFair in the model output. This is because Fair is the reference level of the cut variable (it’s first alphabetically). You’ll see below that it is, indeed, still in the model. You’ll also see why the term “reference level” makes sense!\n\n\nAfter examining the summary table output from the code chunk above, complete the model formula:\n\n\n\nE[price | cut] = ___ +/- ___ cutGood +/- ___ cutVery Good +/- ___ cutPremium +/- ___ cutIdeal"
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-6-making-sense-of-the-model",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-6-making-sense-of-the-model",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 6: Making sense of the model",
    "text": "Exercise 6: Making sense of the model\nRecall our model: E[price | cut] = 4358.7578 - 429.8933 cutGood - 376.9979 cutVery Good + 225.4999 cutPremium - 901.2158 cutIdeal\n\nUse the model formula to calculate the expected/typical price for diamonds of Good cut.\nSimilarly, calculate the expected/typical price for diamonds of Fair cut.\nRe-examine these 2 calculations. Where have you seen these numbers before?!"
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-7-interpreting-coefficients",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-7-interpreting-coefficients",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 7: Interpreting coefficients",
    "text": "Exercise 7: Interpreting coefficients\nRecall that our model formula is not a formula for a line. Thus we can’t interpret the coefficients as “slopes” as we have before. Taking this into account and reflecting upon your calculations above…\n\nInterpret the intercept coefficient (4358.7578) in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\nInterpret the cutGood and cutVery Good coefficients (-429.8933 and -376.9979) in terms of the data context. Hint: where did you use these value in the prediction calculations above?"
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-8-modeling-choices-challenge",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-8-modeling-choices-challenge",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 8: Modeling choices (CHALLENGE)",
    "text": "Exercise 8: Modeling choices (CHALLENGE)\nWhy do we fit this model in this way (using 4 indicator variables cutGood, cutVery Good, cutPremium, cutIdeal)? Instead, suppose that we created a single variable cutCat that gave each category a numerical value: 0 for Fair, 1 for Good, 2 for Very Good, 3 for Premium, and 4 for Ideal.\nHow would this change things? What are the pros and cons of each approach?"
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#reflection",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#reflection",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Reflection",
    "text": "Reflection\nThrough the exercises above, you learned how to build and interpret models that incorporate a categorical predictor variable. For the benefit of your future self, summarize how one can interpret the coefficients for a categorical predictor.\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#render-your-work",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#render-your-work",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check."
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-9-diamond-color",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-9-diamond-color",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 9: Diamond color",
    "text": "Exercise 9: Diamond color\nConsider modeling price by color.\n\nBefore creating a visualization that shows the relationship between price and color, write down what you expect the plot to look like. Then construct and interpret an apporpriate plot.\nCompute the average price for each color.\nFit an appropriate linear model with lm() and display a short summary of the model.\nWrite out the model formula from the above summary.\nWhich color is the reference level? How can you tell from the model summary?\nInterpret the intercept and two other coefficients from the model in terms of the data context."
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#exercise-10-diamond-clarity",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#exercise-10-diamond-clarity",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Exercise 10: Diamond clarity",
    "text": "Exercise 10: Diamond clarity\nIf you want more practice, repeat the steps from Exercise 8 for the clarity variable."
  },
  {
    "objectID": "template_qmds/07-slr-cat-predictor-notes.html#done",
    "href": "template_qmds/07-slr-cat-predictor-notes.html#done",
    "title": "Simple linear regression: categorical predictor (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html",
    "href": "template_qmds/05-slr-model-eval-notes.html",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nUse residual plots to evaluate the correctness of a model\nExplain the rationale for the R-squared metric of model strength\nInterpret the R-squared metric\nThink about ethical implications of modeling by examining the impacts of biased data, power dynamics, the role of categorization, and the role of emotion and lived experience\n\n\n\n\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 1.7, 3.7, and 3.8 in the STAT 155 Notes\n\nNote: You do not need to focus on the “Ladder of Power” in Section 3.8. Transformations in general will be the focus of the next activity we do.\n\nVideos:\n\nModel evaluation: is the model wrong? (slides)\nModel evaluation: is the model strong? (slides)\nModel evaluation: is the model fair? (slides)\nR Code for Evaluating and Using a Linear Model\n\n\n\n\n\nOne way to think about model evaluation is to consider whether or not underlying assumptions of our regression models are being met (or not). Asking ourselves if our models are “wrong”, “strong”, and “fair” approaches this from one perspective. To the first question (whether our model is wrong), recall the following four assumptions of linear regression:\n\nLinearity\nIndependence\nNormality\nEqual Variance\n\nNote that they spell “LINE” (how convenient!).\nBy assumptions, we mean that the above four “things” are needed mathematically in order for linear regression to “work”.\nWhereas we can check some of these assumptions using a residual plot, we need to examine the context of our data collection when checking the Independence assumption. What we mean by independence, is that the residuals in our model do not depend on one another. This may seem like an unsatisfying definition, so here are some examples:\n\nSuppose I want to understand the association between a person’s high school GPA and their college GPA. I collect data from every graduating senior, at three different high schools. If I have college GPA as my outcome, and high school GPA as my predictor, are my residuals independent? Probably not! It is reasonable to believe that students from the same high school may have similar GPAs, due to resources their high school may have had available, or specific teachers grading differently at one school or another. This is an example of clustering, where we have clusters of students within schools. The independence assumption of our linear regression model would be violated. One way to address this would be to include which high school they went to as an additional covariate in our regression model (we’ll get to this with multiple linear regression), and more advanced methods are covered in a course on Correlated Data.\nSuppose I want to understand the association between a mouse’s weight and their water consumption across time. I collect data for 365 days for ten different mice, recording their weight and water consumption each day of the year. If I have weight as my predictor and water consumption as my outcome, are my residuals independent? Nope! This is an example of correlated data that is longitudinal in nature: I have multiple observations per individual (mouse) across time. A mouse’s weight one day is certainly not independent of it’s weight the following day. The independence assumption of our linear regression model would again be violated. One way to address this would be to include “Mouse ID” as a predictor in our regression model (again, we’ll get to this with multiple linear regression).\n\nAll types of data that will violate the independence assumption of linear regression will have some sort of correlation structure (within individual, across time, across space, etc.). Think about clusters. If your observations fall neatly into specific clusters, your data may violate the independence assumption of linear regression.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#learning-goals",
    "href": "template_qmds/05-slr-model-eval-notes.html#learning-goals",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nUse residual plots to evaluate the correctness of a model\nExplain the rationale for the R-squared metric of model strength\nInterpret the R-squared metric\nThink about ethical implications of modeling by examining the impacts of biased data, power dynamics, the role of categorization, and the role of emotion and lived experience"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#readings-and-videos",
    "href": "template_qmds/05-slr-model-eval-notes.html#readings-and-videos",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "",
    "text": "Choose either the reading or the videos to go through before class.\n\nReading: Sections 1.7, 3.7, and 3.8 in the STAT 155 Notes\n\nNote: You do not need to focus on the “Ladder of Power” in Section 3.8. Transformations in general will be the focus of the next activity we do.\n\nVideos:\n\nModel evaluation: is the model wrong? (slides)\nModel evaluation: is the model strong? (slides)\nModel evaluation: is the model fair? (slides)\nR Code for Evaluating and Using a Linear Model"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#model-assumptions",
    "href": "template_qmds/05-slr-model-eval-notes.html#model-assumptions",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "",
    "text": "One way to think about model evaluation is to consider whether or not underlying assumptions of our regression models are being met (or not). Asking ourselves if our models are “wrong”, “strong”, and “fair” approaches this from one perspective. To the first question (whether our model is wrong), recall the following four assumptions of linear regression:\n\nLinearity\nIndependence\nNormality\nEqual Variance\n\nNote that they spell “LINE” (how convenient!).\nBy assumptions, we mean that the above four “things” are needed mathematically in order for linear regression to “work”.\nWhereas we can check some of these assumptions using a residual plot, we need to examine the context of our data collection when checking the Independence assumption. What we mean by independence, is that the residuals in our model do not depend on one another. This may seem like an unsatisfying definition, so here are some examples:\n\nSuppose I want to understand the association between a person’s high school GPA and their college GPA. I collect data from every graduating senior, at three different high schools. If I have college GPA as my outcome, and high school GPA as my predictor, are my residuals independent? Probably not! It is reasonable to believe that students from the same high school may have similar GPAs, due to resources their high school may have had available, or specific teachers grading differently at one school or another. This is an example of clustering, where we have clusters of students within schools. The independence assumption of our linear regression model would be violated. One way to address this would be to include which high school they went to as an additional covariate in our regression model (we’ll get to this with multiple linear regression), and more advanced methods are covered in a course on Correlated Data.\nSuppose I want to understand the association between a mouse’s weight and their water consumption across time. I collect data for 365 days for ten different mice, recording their weight and water consumption each day of the year. If I have weight as my predictor and water consumption as my outcome, are my residuals independent? Nope! This is an example of correlated data that is longitudinal in nature: I have multiple observations per individual (mouse) across time. A mouse’s weight one day is certainly not independent of it’s weight the following day. The independence assumption of our linear regression model would again be violated. One way to address this would be to include “Mouse ID” as a predictor in our regression model (again, we’ll get to this with multiple linear regression).\n\nAll types of data that will violate the independence assumption of linear regression will have some sort of correlation structure (within individual, across time, across space, etc.). Think about clusters. If your observations fall neatly into specific clusters, your data may violate the independence assumption of linear regression.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-1-is-the-model-correct",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-1-is-the-model-correct",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nLet’s revisit the Capital Bikeshare data:\n\n# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")\n\nWe previously explored a model of daily ridership among registered users as a function of temperature:\n\n# Fit a linear model\nbike_model &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n\n# Check it out\nsummary(bike_model)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3607.1  -959.2  -153.8   998.2  3304.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -667.916    251.608  -2.655  0.00811 ** \n## temp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1310 on 729 degrees of freedom\n## Multiple R-squared:  0.2961, Adjusted R-squared:  0.2952 \n## F-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16\n\nPlot this relationship with both a curved and linear trend line. Based on this plot, do you think the model is correct? If not, which of the LINE assumptions does it violate?\n\n# Plot temp_feel vs riders_registered with a model trend\n___(___, aes(x = ___, y = ___)) + \n    geom___() + \n    geom___(se = FALSE, color = \"red\") +\n    geom___(method = \"lm\", se = FALSE)\n## Error in parse(text = input): &lt;text&gt;:2:2: unexpected input\n## 1: # Plot temp_feel vs riders_registered with a model trend\n## 2: __\n##     ^"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-2-residual-plots",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-2-residual-plots",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 2: Residual plots",
    "text": "Exercise 2: Residual plots\nPlotting the residuals vs the predictions (also called “fitted values”) for each case can help us assess how wrong our model is. This will be a particularly important tool when evaluating models with multiple predictors. Construct the residual plot for bike_model. As with the scatterplot, this plot indicates that bike_model violates one of the LINE assumptions. Explain which assumption that is and how you can tell that from just the residual plot.\nNotes:\n\nInformation about the residuals (.resid) and predictions (.fitted) are stored within our model, thus we start our ggplot() with the model name as opposed to the raw dataset. We will rarely start ggplot() with a model instead of the data.\nWe can fix this model by adding a quadratic “transformation term”. We’ll discuss this idea in our next class.\n\n\n# Check out the residual plot for bike_model\nggplot(bike_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-3-whats-incorrect-about-this-model",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-3-whats-incorrect-about-this-model",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 3: What’s incorrect about this model?",
    "text": "Exercise 3: What’s incorrect about this model?\nConsider another example. The mammals data includes data on the average brain weight (g) and body weight (kg) for a variety of mammals:\n\n# Import the data\nmammals &lt;- read_csv(\"https://mac-stat.github.io/data/mammals.csv\")\n\n# Check it out\nhead(mammals)\n## # A tibble: 6 × 4\n##    ...1 animal            body brain\n##   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n## 1     1 Arctic fox        3.38  44.5\n## 2     2 Owl monkey        0.48  15.5\n## 3     3 Mountain beaver   1.35   8.1\n## 4     4 Cow             465    423  \n## 5     5 Grey wolf        36.3  120. \n## 6     6 Goat             27.7  115\n\nFit a model of brain vs body weight:\n\n# Construct the model\nmammal_model &lt;- lm(brain ~ body, mammals)\n\n# Check it out\nsummary(mammal_model)\n## \n## Call:\n## lm(formula = brain ~ body, data = mammals)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -810.07  -88.52  -79.64  -13.02 2050.33 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 91.00440   43.55258    2.09   0.0409 *  \n## body         0.96650    0.04766   20.28   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 334.7 on 60 degrees of freedom\n## Multiple R-squared:  0.8727, Adjusted R-squared:  0.8705 \n## F-statistic: 411.2 on 1 and 60 DF,  p-value: &lt; 2.2e-16\n\n\nConstruct two plots that will help us evaluate mammal_model:\n\n\n# Scatterplot of brain weight (y) vs body weight (x)\n# Include a model trend line (i.e. a representation of mammal_model)\n\n\n# Residual plot for mammal_model\n\n\nThese two plots confirm that our model is wrong. What is wrong? That is, which of the LINE assumptions are violated? (NOTE: We again can fix this model by “transforming” one or both of the brain and body variables. We’ll discuss this idea in our next class.)"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-4-exploring-mammals",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-4-exploring-mammals",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 4: Exploring mammals",
    "text": "Exercise 4: Exploring mammals\nJust for fun, let’s dig into the mammals data. Discuss what you observe:\n\n# Label the points by the animal name!\n# Discuss: What 2 things are new in this code?\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    geom_smooth(method = \"lm\", se = FALSE) \n\n\n\n\n\n\n\n\n\n# Zoom in\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    lims(y = c(0, 1500), x = c(0, 600))\n\n\n\n\n\n\n\n\n\n# Zoom in more\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    lims(y = c(0, 500), x = c(0, 200))"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the variation in the predictors.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that’s explained by the model (the variance of the predictions) and the variability that’s left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\nStrong models have residuals that don’t deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe two rows of plots show a stronger and a weaker model. Just by looking at the blue trend line and the dispersion of the points about the line, which row corresponds to the stronger model? How can you tell? Which row would you expect to have a higher correlation?\nWhat is different about the variance of the residuals from the first to the second row?\n\n\nPutting this together, the R-squared compares Var(predicted) to Var(response):\n\\[R^2 = \\frac{\\text{variance of predicted values}}{\\text{variance of observed response values}} = 1 - \\frac{\\text{variance of residuals}}{\\text{variance of observed response values}}\\] ::: {.callout-note collapse=“true”} ## R-squared\n\\[\nR^2 = 1 - \\frac{SSE}{SSTO} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n\\] where \\(y_i\\) are our observed outcomes, \\(i = 1, \\dots, n\\), \\(\\hat{y}_i\\) are our fitted values/predictions, and \\(\\bar{y}\\) is our observed average outcome. :::"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-6-r-squared-interpretations",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-6-r-squared-interpretations",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 6: R-squared Interpretations",
    "text": "Exercise 6: R-squared Interpretations\nRecall bikemod1 from Exercise 3, where we predicted registered riders by what the temperature felt like on a given day. Use the summary function to look out the model output for bikemod1, and interpret the \\(R^2\\) value for this model, in the context of the problem. (NOTE: \\(R^2\\) is reported in output here as “Multiple R-squared”).\n\n# Get R-squared\nsummary(bike_model)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3607.1  -959.2  -153.8   998.2  3304.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -667.916    251.608  -2.655  0.00811 ** \n## temp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1310 on 729 degrees of freedom\n## Multiple R-squared:  0.2961, Adjusted R-squared:  0.2952 \n## F-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-7-further-exploring-r-squared",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-7-further-exploring-r-squared",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 7: Further exploring R-squared",
    "text": "Exercise 7: Further exploring R-squared\nIn this exercise, we’ll look at data from a synthetic dataset called Anscombe’s quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\n\nThe anscombe data is actually 4 datasets in one: x1 and y1 go together, and so forth. Examine the coefficient estimates (in the “Estimate” column of the “Coefficients:” part) and the “Multiple R-squared” value on the second to last line. What do you notice? How do these models compare?\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\n## \n## Call:\n## lm(formula = y1 ~ x1, data = anscombe)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.92127 -0.45577 -0.04136  0.70941  1.83882 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0001     1.1247   2.667  0.02573 * \n## x1            0.5001     0.1179   4.241  0.00217 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6665, Adjusted R-squared:  0.6295 \n## F-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\nsummary(anscombe_mod2)\n## \n## Call:\n## lm(formula = y2 ~ x2, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.9009 -0.7609  0.1291  0.9491  1.2691 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)    3.001      1.125   2.667  0.02576 * \n## x2             0.500      0.118   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6662, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\nsummary(anscombe_mod3)\n## \n## Call:\n## lm(formula = y3 ~ x3, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1586 -0.6146 -0.2303  0.1540  3.2411 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0025     1.1245   2.670  0.02562 * \n## x3            0.4997     0.1179   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6663, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\nsummary(anscombe_mod4)\n## \n## Call:\n## lm(formula = y4 ~ x4, data = anscombe)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -1.751 -0.831  0.000  0.809  1.839 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0017     1.1239   2.671  0.02559 * \n## x4            0.4999     0.1178   4.243  0.00216 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6667, Adjusted R-squared:  0.6297 \n## F-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nNow take a look at the following scatterplots of the 4 pairs of variables. What do you notice? What takeaway can we draw from this exercise?\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-8-biased-data-biased-results-example-1",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-8-biased-data-biased-results-example-1",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 8: Biased data, biased results: example 1",
    "text": "Exercise 8: Biased data, biased results: example 1\nDATA ARE NOT NEUTRAL. Data can reflect personal biases, institutional biases, power dynamics, societal biases, the limits of our knowledge, and so on. In turn, biased data can lead to biased analyses. Consider an example.\n\nDo a Google image search for “statistics professor.” What do you observe?\nThese search results are produced by a search algorithm / model. Explain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the search results produced from this biased data?"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-9-biased-data-biased-results-example-2",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-9-biased-data-biased-results-example-2",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 9: Biased data, biased results: example 2",
    "text": "Exercise 9: Biased data, biased results: example 2\nConsider the example of a large company that developed a model / algorithm to review the résumés of applicants for software developer & other tech positions. The model then gave each applicant a score indicating their hireability or potential for success at the company. You can think of this model as something like:\n\\[\\text{potential for success } = \\beta_0 + \\beta_1 (\\text{features from the résumé})\\]\nSkim this Reuter’s article about the company’s résumé model.\n\nExplain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the results produced from this biased data?"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-10-rigid-data-collection-systems",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-10-rigid-data-collection-systems",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 10: Rigid data collection systems",
    "text": "Exercise 10: Rigid data collection systems\nWhen working with categorical variables, we’ve seen that our units of observation fall into neat groups. Reality isn’t so discrete. For example, check out questions 6 and 9 on page 2 of the 2020 US Census. With your group, discuss the following:\n\nWhat are a couple of issues you see with these questions?\nWhat impact might this type of data collection have on a subsequent analysis of the census responses and the policies it might inform?\nCan you think of a better way to write these questions while still preserving the privacy of respondents?\n\nFOR A DEEPER DISCUSSION: Read Chapter 4 of Data Feminism on “What gets counted counts”."
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "href": "template_qmds/05-slr-model-eval-notes.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Exercise 11: Presenting data: “Elevating emotion and embodiment”",
    "text": "Exercise 11: Presenting data: “Elevating emotion and embodiment”\nNote: The following example highlights work done by W.E.B. Du Bois in the late 1800s / early 1900s. His work uses language common to that time period and addresses the topic of slavery.\nThe types of visualizations we’ve been learning in this course are standard practice, hence widely understood. Yet these standard visualizations can also suppress the lived experiences of people represented in the data, hence can miss the larger point. W.E.B. Du Bois (1868–1963), a “sociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer, and editor”1, was a pioneer in elevating emotion and embodiment in data visualization. For the Paris World Fair of 1900, Du Bois and his team of students from Atlanta University presented 60 data visualizations of the Black experience in America, less than 50 years after the abolishment of slavery. To this end, Du Bois noted that “I wanted to set down its aim and method in some outstanding way which would bring my work to notice by the thinking world.” That is, he wanted to increase the impact of his work by partnering technical visualizations with design that better connects to lived experiences. Check out:\n\nAn article by Allen Hillery (@AlDatavizguy).\nA complete set of the data visualizations provided by Anthony Starks (@ajstarks).\n\nDiscuss your observations. In what ways do you think the W.E.B. Du Bois visualizations might have been more effective at sharing his work than, say, plainer bar charts?\nFOR A DEEPER DISCUSSION AND MORE MODERN EXAMPLES: Read Chapter 3 of Data Feminism on the principle of elevating emotion and embodiment, i.e. the value of “multiple forms of knowledge, including the knowledge that comes from people as living, feeling bodies in the world.”"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#reflection",
    "href": "template_qmds/05-slr-model-eval-notes.html#reflection",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Reflection",
    "text": "Reflection\nWhat has stuck with you most in our exploration of model evaluation? Why\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#done",
    "href": "template_qmds/05-slr-model-eval-notes.html#done",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/05-slr-model-eval-notes.html#footnotes",
    "href": "template_qmds/05-slr-model-eval-notes.html#footnotes",
    "title": "Simple linear regression: model evaluation (Notes)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://en.wikipedia.org/wiki/W._E._B._Du_Bois↩︎"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html",
    "href": "template_qmds/03-slr-introduction-notes.html",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nVisualize and describe the relationship between two quantitative variables using a scatterplot\nWrite R code to create a scatterplot and compute the linear correlation between two quantitative variables\nDescribe/identify weak / strong, and positive / negative correlation from a point cloud\nBuild intuition for fitting lines to quantify the relationship between two quantitative variables\n\n\n\n\nChoose either the reading or the videos to go through after class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#learning-goals",
    "href": "template_qmds/03-slr-introduction-notes.html#learning-goals",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nVisualize and describe the relationship between two quantitative variables using a scatterplot\nWrite R code to create a scatterplot and compute the linear correlation between two quantitative variables\nDescribe/identify weak / strong, and positive / negative correlation from a point cloud\nBuild intuition for fitting lines to quantify the relationship between two quantitative variables"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#readings-and-videos",
    "href": "template_qmds/03-slr-introduction-notes.html#readings-and-videos",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "",
    "text": "Choose either the reading or the videos to go through after class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-1-get-to-know-the-data",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nCreate a new code chunk by clicking the green “C” button with a green + sign in the top right of the menu bar. In this code chunk, use an appropriate function to look at the first few rows of the data.\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\nWhat does a case represent?\nNavigate to the FAQ page and read the response to the “How does this site work? Do you just download results from the federations?” question. What do you learn about data quality and completeness from this response?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-2-mutating-our-data",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-2-mutating-our-data",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (lifts data is \"fed into\" the mutate() function).\n# When creating a new variable, we often reassign the data frame to itself,\n# which updates the existing columns in lifts with the additional \"new\" column(s)\n# in lifts!\nlifts &lt;- lifts %&gt;% \n    mutate(NEW_VARIABLE_NAME = Age/BestSquatKg)\n## Error in `mutate()`:\n## ℹ In argument: `NEW_VARIABLE_NAME = Age/BestSquatKg`.\n## Caused by error:\n## ! object 'BestSquatKg' not found\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet’s get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-4-data-visualization---two-quantitative-variables",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-4-data-visualization---two-quantitative-variables",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe’d like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a “point cloud”) allows us to do this! The code below creates a scatterplot of body weight vs. SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'SWR' not found\n\n\nThis is your first bivariate data visualization (visualization for two variables)! What differences do you notice in the code structure when creating a bivariate visualization, compared to univariate visualizations we’ve worked with before?\nWhat similarities do you notice in the code structure?\nDoes there appear to be some sort of pattern in the structure of the point cloud? Describe it, in no more than three sentences! Comment on the direction of the relationship between the two variables (positive? negative?) and the spread of the points (are they dispersed? close together?)."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'SWR' not found\n\n\nLook back at your answer to Exercise 4 (c). Does the smoothing line assist you in seeing a pattern, or change your answer at all? Why or why not?\nBased on the scatterplot with the smoothing line added above, does there appear to be a linear relationship between body weight and SWR (i.e. would a straight line do a decent job at summarizing the relationship between these two variables)? Why or why not?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-6-correlation",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-6-correlation",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\nWe can quantify the linear relationship between two quantitative variables using a numerical summary known as correlation (sometimes known as a “correlation coefficient” or “Pearson’s correlation”). Correlation can range from -1 to 1, where a correlation of 0 indicates that there is no linear relationship between the two quantitative variables.\nBelow is an example of a “Math Box”. You’ll see these occasionally throughout the activities. You are not required to memorize, nor will you be assessed on, anything in the math boxes. If you plan on continuing with Statistics courses at Macalester (or are interested in the math behind everything!), these math boxes are for you!\n\n\n\n\n\n\nCorrelation\n\n\n\n\n\nThe Pearson correlation coefficient, \\(r_{x, y}\\), of \\(x\\) and \\(y\\) is the (almost) average of products of the z-scores of variables \\(x\\) and \\(y\\):\n\\[\nr_{x, y} = \\frac{\\sum z_x z_y}{n - 1}\n\\]\n\n\n\nIn general, we will want to be able to describe (qualitatively) two aspects of correlation:\n\nStrength\n\n\nIs the correlation between x and y strong, or weak, i.e. how closely do the points fit around a line? This has to do with how dispersed our point clouds are.\n\n\nDirection\n\n\nIs the correlation between x and y positive or negative, i.e. does y go “up” when x goes “up” (positive), or does y go “down” when x goes “up” (negative)?\n\nStronger correlations will be further from 0 (closer to -1 or 1), and positive and negative correlations will have the appropriate respective sign (above or below zero).\n\nRather than a smooth trend line, we can force the line we add to our scatterplots to be linear using geom_smooth(method = 'lm'), as below:\n\n\n# scatterplot with linear trend line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\")\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'SWR' not found\n\n\nBased on the above scatterplot, how would you describe the correlation between body weight and SWR, in terms of strength and direction?\nMake a guess as to what numerical value the correlation between body weight and SWR will have, based on your response to part (b)."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-7-computing-correlation-in-r",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-7-computing-correlation-in-r",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\nWe can compute the correlation between body weight and SWR using summarize and cor functions:\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n## Error in `summarize()`:\n## ℹ In argument: `cor(SWR, BodyweightKg, use = \"complete.obs\")`.\n## Caused by error:\n## ! object 'SWR' not found\n\nIs the computed correlation close to what you guessed in Exercise 6 part (c)?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-8-limitations-of-correlation",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-8-limitations-of-correlation",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\nWe previously noted that correlation was a numerical summary of the linear relationship between two variables. We’ll now go through some examples of relationships between quantitative variables to demonstrate why it is incredibly important to visualize our data in addition to just computing numerical summaries!\nFor this exercise, we’ll be working with the anscombe dataset, which is built in to R. To load this dataset into our environment, we run the following code:\n\n# load anscombe data\ndata(\"anscombe\")\n\nThe anscombe dataset contains four different pairs of quantitative variables:\n\nx1, y1\nx2, y2\nx3, y3\nx4, y4\n\nAdapt the code we used in Exercise 7 to compute the correlation between each of these four pairs of variables, below:\n\n# correlation between x1, y1\n\n# correlation between x2, y2\n\n# correlation between x3, y3\n\n# correlation between x4, y4\n\n\nWhat do you notice about each of these correlations (if the answer to this isn’t obvious, double-check your code)?\nDescribe these correlations in terms of strength and direction, using only the numerical summary to assist you in your description.\nDraw an example on the white board or at your tables of what you think the point clouds for these pairs of variables might look like. There are only 11 observations, so you can draw all 11 points if you’d like!\nAdapt the code for scatterplots given previously in this activity to make four distinct scatterplots for each pair of quantitative variables in the anscombe dataset. You do not need to add a smooth trend line or a linear trend line to these plots.\n\n\n# scatterplot: x1, y1\n\n# scatterplot: x2, y2\n\n# scatterplot: x3, y3\n\n# scatterplot: x4, y4\n\n\nBased on the correlations you calculated and scatterplots you made, what is the message of this last exercise as it relates to the limits of correlation?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#reflection",
    "href": "template_qmds/03-slr-introduction-notes.html#reflection",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Reflection",
    "text": "Reflection\nMuch of statistics is about making (hopefully) reasonable assumptions in attempt to summarize observed relationships in data. Today we started considering assumptions of linear relationships between quantitative variables.\nReview the learning objectives at the top of this file and today’s activity. How do you imagine assumptions of linearity might be useful in terms of quantifying relationships between quantitative variables? How do you imagine these assumptions could sometimes fall short, or even be unethical in certain cases?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-9-lines-of-best-fit",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-9-lines-of-best-fit",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 9: Lines of best fit",
    "text": "Exercise 9: Lines of best fit\nIn this activity, we’ve learned how to fit straight lines to data, to help us visualize the relationship between two quantitative variables. So far, ggplot has chosen the line for us. How does it know which line is “best”, and what does “best” even mean?\nFor this exercise, we’ll consider the relationship between x1 and y1 in the anscombe dataset. Run the following code, which creates a scatterplot with a fitted line to our data using the function geom_abline:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1)\n\n\n\n\n\n\n\n\nDescribe the line that you see. Do you think the line is “good”? What are you using to define “good”?\nSome things to think about:\n\nHow many points are above the line?\nHow many points are below the line?\nAre the distances of the points above and below the line roughly similar, or is there meaningful difference?\n\nNow we’ll add another line to our plot. Which line do you think is better suited for this data? Why? Be specific!\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1) +\n  geom_abline(slope = 0.5, intercept = 4, col = \"orange\", size = 1)\n\n\n\n\n\n\n\n\nIt’s usually quite simple to note when a line is bad, but more difficult to quantify when a line is a good fit for our data. Consider the following line:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = -0.5, intercept = 10, col = \"red\", size = 1) \n\n\n\n\n\n\n\n\nIn the next activity, we’ll formalize the principle of least squares, which will give us one particular definition of a line of best fit that is commonly used in statistics! We’ll take advantage of the vertical distances between each point and the fitted line (residuals), which will help us define (mathematically) a line that best fits our data:\n\nlibrary(broom)\nanscombe %&gt;%\n  lm(y1 ~ x1, data = .) %&gt;%\n  augment() %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_segment(aes(xend = x1, yend = .fitted), col = \"red\") +\n  geom_point()"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#exercise-10-correlation-and-extreme-values",
    "href": "template_qmds/03-slr-introduction-notes.html#exercise-10-correlation-and-extreme-values",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Exercise 10: Correlation and extreme values",
    "text": "Exercise 10: Correlation and extreme values\nIn this exercise, we’ll explore how correlation changes with the addition of extreme values, or observations. We’ll begin by generating a toy dataset called dat with two quantitative variables, x and y. Run the code below to create the dataset.\nwhile not required, recall that you can look up function documentation in R using the ? in front of a function name to figure out what that function is doing!\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\nMake a scatterplot of x vs. y.\n\n\n# scatterplot\n\n\nBased on your scatterplot, describe the correlation between x and y in terms of strength and direction.\nGuess the correlation (the numerical value) between x and y.\nCompute the correlation between x and y. Was your guess from part (c) close?\n\n\n# correlation\n\n\nSuppose we observe an additional observation with x = 15 and y = -45. We can create a new data frame, dat_new1, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nSuppose instead of our additional observation having values x = 15 and y = -45, we instead observe x = 15 and y = -15. We can create a new data frame, dat_new2, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nWhat do you think the takeaway message is of this exercise?\n\n\nChallenge Add linear trend lines to your scatterplots from parts (f) and (h). Does this give you any additional insight into why the correlations may have changed in different ways with the addition of a new observation?"
  },
  {
    "objectID": "template_qmds/03-slr-introduction-notes.html#done",
    "href": "template_qmds/03-slr-introduction-notes.html#done",
    "title": "Simple linear regression: Visualization and Introduction (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html",
    "href": "template_qmds/01-foundations-welcome-notes.html",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "",
    "text": "Welcome to our first in-class activity! Today we will collect and summarize some data. Our goals are to get to know the people in this class and to start working with data.\nBy the end of this lesson, you should be able to:\n\nDefine cases and variables\nApply the 5 W’s + H (who, what, when, where, why, and how) to data collection\n\nLinks to related reading(s):\n\nWhat is Data?\nData Context\n\nThis activity is structured a bit differently than the activities for the remainder of the class. In this section, you’ll typically find a mini-lecture, review material, or guided / structural examples, followed by exercises.\nFor today, you’ll have some steps to follow for an interactive, tactile activity at your tables before working through the exercises below together.\n\n\nAt your table, write a one to two word answer to each of the following 7 question(s), each on a separate post-it note (do this individually). If there are two questions: write your answer to the first question on the left-hand side of the post-it note, and your answer to the second question on the bottom of the post-it note.\n\nHow many hours of sleep did you get last night? How many cups of coffee did you drink this morning?\nWhat is your declared or potential major? (If you are a double major, just pick whichever one you think of first.)\nWhat is your class year? (first year, sophomore, junior, senior)\nHow many stats courses have you taken in the past?\nOn a scale of 1 (get me out of here) to 10 (yay!), how excited are you about this course?\nIs it your birthday this semester? (yes/no)\nHow many unread emails do you have in your inbox right now?\nHave you used R/RStudio a lot, a little, or never?\n\n\n\n\nDesignate one person from your table to distribute your group’s answers to the questions to the corresponding “station” around the classroom. Each table should have a number on it, corresponding to the “station”/question.\n\n\n\nFill out an electronic version of these questions. We’ll come back to this in a future class. Wait until everyone in your group is done with this before moving on to the exercises."
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#step-1",
    "href": "template_qmds/01-foundations-welcome-notes.html#step-1",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "",
    "text": "At your table, write a one to two word answer to each of the following 7 question(s), each on a separate post-it note (do this individually). If there are two questions: write your answer to the first question on the left-hand side of the post-it note, and your answer to the second question on the bottom of the post-it note.\n\nHow many hours of sleep did you get last night? How many cups of coffee did you drink this morning?\nWhat is your declared or potential major? (If you are a double major, just pick whichever one you think of first.)\nWhat is your class year? (first year, sophomore, junior, senior)\nHow many stats courses have you taken in the past?\nOn a scale of 1 (get me out of here) to 10 (yay!), how excited are you about this course?\nIs it your birthday this semester? (yes/no)\nHow many unread emails do you have in your inbox right now?\nHave you used R/RStudio a lot, a little, or never?"
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#step-2",
    "href": "template_qmds/01-foundations-welcome-notes.html#step-2",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "",
    "text": "Designate one person from your table to distribute your group’s answers to the questions to the corresponding “station” around the classroom. Each table should have a number on it, corresponding to the “station”/question."
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#step-3",
    "href": "template_qmds/01-foundations-welcome-notes.html#step-3",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "",
    "text": "Fill out an electronic version of these questions. We’ll come back to this in a future class. Wait until everyone in your group is done with this before moving on to the exercises."
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#exercise-1",
    "href": "template_qmds/01-foundations-welcome-notes.html#exercise-1",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "Exercise 1",
    "text": "Exercise 1\nWith your group, in no more than two sentences per question, respond to the questions posed by the 5 W’s + H for the data at your group’s table. If you need a refresher on the 5 W’s + H, check out the related readings posted at the top of this activity!\nWho\n\n  Your answer:\n  \n\nWhat\n\n  Your answer:\n  \n\nWhen\n\n  Your answer:\n  \n\nWhere\n\n  Your answer:\n  \n\nWhy\n\n  Your answer:\n  \n\nHow\n\n  Your answer:"
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#exercise-2",
    "href": "template_qmds/01-foundations-welcome-notes.html#exercise-2",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "Exercise 2",
    "text": "Exercise 2\nMove the post-it notes around to construct a visualization of the responses at your station."
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#exercise-3",
    "href": "template_qmds/01-foundations-welcome-notes.html#exercise-3",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "Exercise 3",
    "text": "Exercise 3\nCalculate at least one numerical summary of the post-it note responses at your station, and record your numerical summary in the response text below. Write a complete sentence, not just the numerical summary alone! This is good practice for summarizing data in more formal writing.\n\n  Your answer:"
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#exercise-4",
    "href": "template_qmds/01-foundations-welcome-notes.html#exercise-4",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn no more than three sentences, describe what you learn about from the visual and numerical summaries. Try to write your description in a way that tells an interesting story about the people in this class.\n\n  Your answer:"
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#exercise-5",
    "href": "template_qmds/01-foundations-welcome-notes.html#exercise-5",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "Exercise 5",
    "text": "Exercise 5\nImagine that you took all the post-it notes in this room and organized them into a spreadsheet. What would each row in the underlying data set represent? What would each column of the data set represent? Check out the first related reading, linked at the top of this activity, if you need assistance!\n\n  Your answer:"
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#reflection",
    "href": "template_qmds/01-foundations-welcome-notes.html#reflection",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "Reflection",
    "text": "Reflection\nIn three to four sentences, reflect upon today’s activity. Some reflection prompts are found below:\n\nDo you think the context in which the data was collected influenced the results you found?\nWho would the numerical summaries you calculated potentially be represented of? Could you generalize the information you learned to a broader population (all students at Mac, perhaps), or would you have ethical concerns with generalizing your results?\nWhat (if anything) surprised you about the numerical summaries calculated by your group, or other groups?\nDid your data visualization help you better understand, or discover new things about the data that otherwise would have been difficult to distinguish? Why or why not?\n\n\n  Your answer:"
  },
  {
    "objectID": "template_qmds/01-foundations-welcome-notes.html#done",
    "href": "template_qmds/01-foundations-welcome-notes.html#done",
    "title": "Collecting and Summarizing Data (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "The (tentative) course schedule below will be filled in throughout the semester. For each day, there will be written on what is due ahead of class time OR whats’ the big thing (like quizzes!). The “Announcements” column is (hopefully) self-explanatory. Any urgent announcements will be made over email (moodle).\n\n\n\n\n\n\nWeek 1\n\n\n\n\n\n\n\n\nMonday\nWednesday\nFriday\nAnnouncements\n\n\n\n\nEnjoy, no class\n09/03: First day of class! Collecting and Summarizing Data  Before class:  - Read the course syllabus. I will assume that you understand all course policies beginning on Wednesday!  - Familiarize yourself with Moodle and the course website  - Complete Introductions Survey  - Walk through R Resources tab. Try downloading R and RStudio before coming to class!\n09/05: Univariate Visualization & Numerical Summaries  Before class:  - Download R and RStudio, and watch corresponding videos in the R Resources tab  - Complete the Introductions Survey (if you haven’t already!)  - Do either the readings or videos for today’s activity (Links in the Moodle checkpoint quiz)  - Complete today’s checkpoint on Moodle  During class:  - Begin Univariate Foundations Activity\nWelcome (back) to campus!\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2\n\n\n\n\n\n\n\n\nMonday\nWednesday\nFriday\nAnnouncements\n\n\n\n\n09/08: Simple Linear Regression: Discovery  Before class:  - Finish Univariate Foundations Activity outside of class  - Look through the Study Tips & Slides page on the Course Website – set a plan for yourself to be successful this semester!  - No checkpoint on Moodle for today!  During class:  - Begin SLR: Discovery Activity\n09/10: Simple Linear Regression: Formalization  Before class:  - Finish SLR: Discovery Activity outside of class  - Do either the readings or videos for today’s activity (Links in the Moodle checkpoint quiz)  - Complete today’s checkpoint on Moodle  During class:  - Begin SLR: Formalization Activity\n09/12: Simple Linear Regression: Model Evaluation  Before class:  - Finish SLR: Formalization Activity outside of class  - Do either the readings or videos for today’s activity (Links in the Moodle checkpoint quiz)  - Complete today’s checkpoint on Moodle  During class:  - Begin SLR: Model Evaluation Activity\n- PP#1 is posted on the Practice Problems tab (due Friday 09/12, 11:59pm CT)  - Last day to add/drop is Friday, 09/12\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 3\n\n\n\n\n\n\n\n\nMonday\nWednesday\nFriday\nAnnouncements\n\n\n\n\n09/15: Simple Linear Regression: Transformation  Before class:  - Finish last class activities and CP Quiz on Moodles\n09/17: Simple Linear Regression: Categorcial Variable  Before class:  - Finish last class activities and CP Quiz on Moodles\n09/19: Mulitple Linear Regression Intro  Before class:  - Finish last class activities\n- PP#2 is posted on the Practice Problems tab (due Friday 09/20, 11:59pm CT)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "",
    "text": "STAT 155: Introduction to Statistical Modeling\nMacalester College, Fall 2025\nStatistics is not just about theories & numbers — it’s about making sense of the world.\n\n\n\n\n\n\n📖 A Thought from H. G. Wells\n\n\n\n\n“Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write.”\n\n\n\nWelcome to the world of Statistics! In this course, you’ll learn how to analyze data, test research hypotheses, and make predictions in ways that matter.\nInstructor: Md Mutasim Billah  Class meeting times:\n\nSection 03: M/W/F 09:40-10:40am, THTR 002\nSection 04: M/W/F 12:00-01:00pm, THTR 202\n\nInstructor’s drop-in (office) hours:\n\nLocation: My office (OLRI 234)\nTimes: M/W: 01:30-02:30 pm.\nBy Appointment: I’m also happy to meet one-on-one! Shoot me an email and we can arrange it either in-person or over zoom, password: 123456.\nEmail Response Time: I do my best to reply to emails promptly during weekdays.\nPlease note that messages sent after 4:00 pm or on weekends may take longer to receive a response.\n\n\nSTAT 155 Preceptor Office Hours: There is a link to a Google Calendar containing all preceptor office hours available at the top of the course Moodle page!\nR/RStudio Preceptor Office Hours: Available on the MSCS Events google calendar (not to be used for questions about course content, only Data and R-related things!)\n\nThis course website will be updated throughout the semester with new activities, assignments, and announcements, so please bookmark this page if you are enrolled in the course!\nIf you find any typos, bugs, dead links, or have other questions, please email mbillah@macalester.edu"
  },
  {
    "objectID": "activities/05-slr-model-eval.html",
    "href": "activities/05-slr-model-eval.html",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you’ve settled in before class begins.",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#learning-goals",
    "href": "activities/05-slr-model-eval.html#learning-goals",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nUse residual plots to evaluate the correctness of a model\nExplain the rationale for the R-squared metric of model strength\nInterpret the R-squared metric\nThink about ethical implications of modeling by examining the impacts of biased data, power dynamics, the role of categorization, and the role of emotion and lived experience",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#readings-and-videos",
    "href": "activities/05-slr-model-eval.html#readings-and-videos",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 1.7, 3.7, and 3.8 in the STAT 155 Notes\n\nNote: You do not need to focus on the “Ladder of Power” in Section 3.8. Transformations in general will be the focus of the next activity we do.\n\nVideos:\n\nModel evaluation: is the model wrong? (slides)\nModel evaluation: is the model strong? (slides)\nModel evaluation: is the model fair? (slides)\nR Code for Evaluating and Using a Linear Model",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#model-assumptions",
    "href": "activities/05-slr-model-eval.html#model-assumptions",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Model Assumptions",
    "text": "Model Assumptions\nOne way to think about model evaluation is to consider whether or not underlying assumptions of our regression models are being met (or not). Asking ourselves if our models are “wrong”, “strong”, and “fair” approaches this from one perspective. To the first question (whether our model is wrong), recall the following four assumptions of linear regression:\n\nLinearity\nIndependence\nNormality\nEqual Variance\n\nNote that they spell “LINE” (how convenient!).\nBy assumptions, we mean that the above four “things” are needed mathematically in order for linear regression to “work”.\nWhereas we can check some of these assumptions using a residual plot, we need to examine the context of our data collection when checking the Independence assumption. What we mean by independence, is that the residuals in our model do not depend on one another. This may seem like an unsatisfying definition, so here are some examples:\n\nSuppose I want to understand the association between a person’s high school GPA and their college GPA. I collect data from every graduating senior, at three different high schools. If I have college GPA as my outcome, and high school GPA as my predictor, are my residuals independent? Probably not! It is reasonable to believe that students from the same high school may have similar GPAs, due to resources their high school may have had available, or specific teachers grading differently at one school or another. This is an example of clustering, where we have clusters of students within schools. The independence assumption of our linear regression model would be violated. One way to address this would be to include which high school they went to as an additional covariate in our regression model (we’ll get to this with multiple linear regression), and more advanced methods are covered in a course on Correlated Data.\nSuppose I want to understand the association between a mouse’s weight and their water consumption across time. I collect data for 365 days for ten different mice, recording their weight and water consumption each day of the year. If I have weight as my predictor and water consumption as my outcome, are my residuals independent? Nope! This is an example of correlated data that is longitudinal in nature: I have multiple observations per individual (mouse) across time. A mouse’s weight one day is certainly not independent of it’s weight the following day. The independence assumption of our linear regression model would again be violated. One way to address this would be to include “Mouse ID” as a predictor in our regression model (again, we’ll get to this with multiple linear regression).\n\nAll types of data that will violate the independence assumption of linear regression will have some sort of correlation structure (within individual, across time, across space, etc.). Think about clusters. If your observations fall neatly into specific clusters, your data may violate the independence assumption of linear regression.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-1-is-the-model-correct",
    "href": "activities/05-slr-model-eval.html#exercise-1-is-the-model-correct",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nLet’s revisit the Capital Bikeshare data:\n\n# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")\n\nWe previously explored a model of daily ridership among registered users as a function of temperature:\n\n# Fit a linear model\nbike_model &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n\n# Check it out\nsummary(bike_model)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3607.1  -959.2  -153.8   998.2  3304.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -667.916    251.608  -2.655  0.00811 ** \n## temp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1310 on 729 degrees of freedom\n## Multiple R-squared:  0.2961, Adjusted R-squared:  0.2952 \n## F-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16\n\nPlot this relationship with both a curved and linear trend line. Based on this plot, do you think the model is correct? If not, which of the LINE assumptions does it violate?\n\n# Plot temp_feel vs riders_registered with a model trend\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE) +\n    geom_smooth(se = FALSE, color = \"red\")",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-2-residual-plots",
    "href": "activities/05-slr-model-eval.html#exercise-2-residual-plots",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 2: Residual plots",
    "text": "Exercise 2: Residual plots\nPlotting the residuals vs the predictions (also called “fitted values”) for each case can help us assess how wrong our model is. This will be a particularly important tool when evaluating models with multiple predictors. Construct the residual plot for bike_model. As with the scatterplot, this plot indicates that bike_model violates one of the LINE assumptions. Explain which assumption that is and how you can tell that from just the residual plot.\nNotes:\n\nInformation about the residuals (.resid) and predictions (.fitted) are stored within our model, thus we start our ggplot() with the model name as opposed to the raw dataset. We will rarely start ggplot() with a model instead of the data.\nWe can fix this model by adding a quadratic “transformation term” (Next CP quiz topic!).\n\n\n# Check out the residual plot for bike_model\nggplot(bike_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) + # Check this first!\n    geom_smooth(se = FALSE)",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model",
    "href": "activities/05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 3: What’s incorrect about this model?",
    "text": "Exercise 3: What’s incorrect about this model?\nConsider another example. The mammals data includes data on the average brain weight (g) and body weight (kg) for a variety of mammals:\n\n# Import the data\nmammals &lt;- read_csv(\"https://mac-stat.github.io/data/mammals.csv\")\n\n# Check it out\nhead(mammals)\n## # A tibble: 6 × 4\n##    ...1 animal            body brain\n##   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n## 1     1 Arctic fox        3.38  44.5\n## 2     2 Owl monkey        0.48  15.5\n## 3     3 Mountain beaver   1.35   8.1\n## 4     4 Cow             465    423  \n## 5     5 Grey wolf        36.3  120. \n## 6     6 Goat             27.7  115\n\nFit a model of brain vs body weight:\n\n# Construct the model\nmammal_model &lt;- lm(brain ~ body, mammals)\n\n# Check it out\nsummary(mammal_model)\n## \n## Call:\n## lm(formula = brain ~ body, data = mammals)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -810.07  -88.52  -79.64  -13.02 2050.33 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 91.00440   43.55258    2.09   0.0409 *  \n## body         0.96650    0.04766   20.28   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 334.7 on 60 degrees of freedom\n## Multiple R-squared:  0.8727, Adjusted R-squared:  0.8705 \n## F-statistic: 411.2 on 1 and 60 DF,  p-value: &lt; 2.2e-16\n\n\nConstruct two plots that will help us evaluate mammal_model:\n\n\n# Scatterplot of brain weight (y) vs body weight (x)\n# Include a model trend line (i.e. a representation of mammal_model)\n\n\n# Residual plot for mammal_model\n\n\nThese two plots confirm that our model is wrong. What is wrong? That is, which of the LINE assumptions are violated? (NOTE: We again can fix this model by “transforming” one or both of the brain and body variables (next CP quiz topic!).",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-4-exploring-mammals",
    "href": "activities/05-slr-model-eval.html#exercise-4-exploring-mammals",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 4: Exploring mammals",
    "text": "Exercise 4: Exploring mammals\nJust for fun, let’s dig into the mammals data. Discuss what you observe:\n\n# Label the points by the animal name!\n# Discuss: What 2 things are new in this code?\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    geom_smooth(method = \"lm\", se = FALSE) \n\n\n\n\n\n\n\n\n\n# Zoom in\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    lims(y = c(0, 1500), x = c(0, 600))\n\n\n\n\n\n\n\n\n\n# Zoom in more\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    lims(y = c(0, 500), x = c(0, 200))",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "href": "activities/05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the variation in the predictors.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that’s explained by the model (the variance of the predictions) and the variability that’s left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\nStrong models have residuals that don’t deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe two rows of plots show a stronger and a weaker model. Just by looking at the blue trend line and the dispersion of the points about the line, which row corresponds to the stronger model? How can you tell? Which row would you expect to have a higher correlation?\nWhat is different about the variance of the residuals from the first to the second row?\n\n\nPutting this together, the R-squared compares Var(predicted) to Var(response):\n\\[R^2 = \\frac{\\text{variance of predicted values}}{\\text{variance of observed response values}} = 1 - \\frac{\\text{variance of residuals}}{\\text{variance of observed response values}}\\]\n\n\n\n\n\n\nR-squared\n\n\n\n\n\n\\[\nR^2 = 1 - \\frac{SSE}{SSTO} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n\\] where \\(y_i\\) are our observed outcomes, \\(i = 1, \\dots, n\\), \\(\\hat{y}_i\\) are our fitted values/predictions, and \\(\\bar{y}\\) is our observed average outcome.",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-6-r-squared-interpretations",
    "href": "activities/05-slr-model-eval.html#exercise-6-r-squared-interpretations",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 6: R-squared Interpretations",
    "text": "Exercise 6: R-squared Interpretations\nRecall bikemod1 from Exercise 1, where we predicted registered riders by what the temperature felt like on a given day. Use the summary function to look out the model output for bikemod1, and interpret the \\(R^2\\) value for this model, in the context of the problem. (NOTE: \\(R^2\\) is reported in output here as “Multiple R-squared”).\n\n# Get R-squared\nsummary(bike_model)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3607.1  -959.2  -153.8   998.2  3304.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -667.916    251.608  -2.655  0.00811 ** \n## temp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1310 on 729 degrees of freedom\n## Multiple R-squared:  0.2961, Adjusted R-squared:  0.2952 \n## F-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-7-further-exploring-r-squared",
    "href": "activities/05-slr-model-eval.html#exercise-7-further-exploring-r-squared",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 7: Further exploring R-squared",
    "text": "Exercise 7: Further exploring R-squared\nIn this exercise, we’ll look at data from a synthetic dataset called Anscombe’s quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\n\nThe anscombe data is actually 4 datasets in one: x1 and y1 go together, and so forth. Examine the coefficient estimates (in the “Estimate” column of the “Coefficients:” part) and the “Multiple R-squared” value on the second to last line. What do you notice? How do these models compare?\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\n## \n## Call:\n## lm(formula = y1 ~ x1, data = anscombe)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.92127 -0.45577 -0.04136  0.70941  1.83882 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0001     1.1247   2.667  0.02573 * \n## x1            0.5001     0.1179   4.241  0.00217 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6665, Adjusted R-squared:  0.6295 \n## F-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\nsummary(anscombe_mod2)\n## \n## Call:\n## lm(formula = y2 ~ x2, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.9009 -0.7609  0.1291  0.9491  1.2691 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)    3.001      1.125   2.667  0.02576 * \n## x2             0.500      0.118   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6662, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\nsummary(anscombe_mod3)\n## \n## Call:\n## lm(formula = y3 ~ x3, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1586 -0.6146 -0.2303  0.1540  3.2411 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0025     1.1245   2.670  0.02562 * \n## x3            0.4997     0.1179   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6663, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\nsummary(anscombe_mod4)\n## \n## Call:\n## lm(formula = y4 ~ x4, data = anscombe)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -1.751 -0.831  0.000  0.809  1.839 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0017     1.1239   2.671  0.02559 * \n## x4            0.4999     0.1178   4.243  0.00216 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6667, Adjusted R-squared:  0.6297 \n## F-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nNow take a look at the following scatterplots of the 4 pairs of variables. What do you notice? What takeaway can we draw from this exercise?\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\n\nComplete Exercise 8-11 after the class.",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-8-biased-data-biased-results-example-1",
    "href": "activities/05-slr-model-eval.html#exercise-8-biased-data-biased-results-example-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 8: Biased data, biased results: example 1",
    "text": "Exercise 8: Biased data, biased results: example 1\nDATA ARE NOT NEUTRAL. Data can reflect personal biases, institutional biases, power dynamics, societal biases, the limits of our knowledge, and so on. In turn, biased data can lead to biased analyses. Consider an example.\n\nDo a Google image search for “statistics professor.” What do you observe?\nThese search results are produced by a search algorithm / model. Explain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the search results produced from this biased data?",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-9-biased-data-biased-results-example-2",
    "href": "activities/05-slr-model-eval.html#exercise-9-biased-data-biased-results-example-2",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 9: Biased data, biased results: example 2",
    "text": "Exercise 9: Biased data, biased results: example 2\nConsider the example of a large company that developed a model / algorithm to review the résumés of applicants for software developer & other tech positions. The model then gave each applicant a score indicating their hireability or potential for success at the company. You can think of this model as something like:\n\\[\\text{potential for success } = \\beta_0 + \\beta_1 (\\text{features from the résumé})\\]\nSkim this Reuter’s article about the company’s résumé model.\n\nExplain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the results produced from this biased data?",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-10-rigid-data-collection-systems",
    "href": "activities/05-slr-model-eval.html#exercise-10-rigid-data-collection-systems",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 10: Rigid data collection systems",
    "text": "Exercise 10: Rigid data collection systems\nWhen working with categorical variables, we’ve seen that our units of observation fall into neat groups. Reality isn’t so discrete. For example, check out questions 6 and 9 on page 2 of the 2020 US Census. With your group, discuss the following:\n\nWhat are a couple of issues you see with these questions?\nWhat impact might this type of data collection have on a subsequent analysis of the census responses and the policies it might inform?\nCan you think of a better way to write these questions while still preserving the privacy of respondents?\n\nFOR A DEEPER DISCUSSION: Read Chapter 4 of Data Feminism on “What gets counted counts”.",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "href": "activities/05-slr-model-eval.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 11: Presenting data: “Elevating emotion and embodiment”",
    "text": "Exercise 11: Presenting data: “Elevating emotion and embodiment”\nNote: The following example highlights work done by W.E.B. Du Bois in the late 1800s / early 1900s. His work uses language common to that time period and addresses the topic of slavery.\nThe types of visualizations we’ve been learning in this course are standard practice, hence widely understood. Yet these standard visualizations can also suppress the lived experiences of people represented in the data, hence can miss the larger point. W.E.B. Du Bois (1868–1963), a “sociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer, and editor”1, was a pioneer in elevating emotion and embodiment in data visualization. For the Paris World Fair of 1900, Du Bois and his team of students from Atlanta University presented 60 data visualizations of the Black experience in America, less than 50 years after the abolishment of slavery. To this end, Du Bois noted that “I wanted to set down its aim and method in some outstanding way which would bring my work to notice by the thinking world.” That is, he wanted to increase the impact of his work by partnering technical visualizations with design that better connects to lived experiences. Check out:\n\nAn article by Allen Hillery (@AlDatavizguy).\nA complete set of the data visualizations provided by Anthony Starks (@ajstarks).\n\nDiscuss your observations. In what ways do you think the W.E.B. Du Bois visualizations might have been more effective at sharing his work than, say, plainer bar charts?\nFOR A DEEPER DISCUSSION AND MORE MODERN EXAMPLES: Read Chapter 3 of Data Feminism on the principle of elevating emotion and embodiment, i.e. the value of “multiple forms of knowledge, including the knowledge that comes from people as living, feeling bodies in the world.”",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-1-is-the-model-correct-1",
    "href": "activities/05-slr-model-eval.html#exercise-1-is-the-model-correct-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nThe red curved trend line shows a clear downward trend around 85 degrees, which contextually makes plenty of sense—extremely hot days would naturally see less riders. Overall the combination of the upward trend and downward trend makes for a curved relationship that is not captured well by a straight line of best fit. Specifically, a simple linear regression model would violate the Linearity assumption.\n\n# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE, color = \"red\") +\n    geom_smooth(method = \"lm\", se = FALSE)",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-2-residual-plots-1",
    "href": "activities/05-slr-model-eval.html#exercise-2-residual-plots-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 2: Residual plots",
    "text": "Exercise 2: Residual plots\nThe residual plot shows a lingering trend in the residuals—the blue curve traces the trend in the residuals, and it does not lie flat on the y = 0 line. This again suggests that the Linearity assumption is violated.\n\nbike_model &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n\n# Check out the residual plot for bike_model\nggplot(bike_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model-1",
    "href": "activities/05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 3: What’s incorrect about this model?",
    "text": "Exercise 3: What’s incorrect about this model?\n\n# Import the data\nmammals &lt;- read_csv(\"https://mac-stat.github.io/data/mammals.csv\")\n\n# Check it out\nhead(mammals)\n## # A tibble: 6 × 4\n##    ...1 animal            body brain\n##   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n## 1     1 Arctic fox        3.38  44.5\n## 2     2 Owl monkey        0.48  15.5\n## 3     3 Mountain beaver   1.35   8.1\n## 4     4 Cow             465    423  \n## 5     5 Grey wolf        36.3  120. \n## 6     6 Goat             27.7  115\n\n# Construct the model\nmammal_model &lt;- lm(brain ~ body, mammals)\n\n# Check it out\nsummary(mammal_model)\n## \n## Call:\n## lm(formula = brain ~ body, data = mammals)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -810.07  -88.52  -79.64  -13.02 2050.33 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 91.00440   43.55258    2.09   0.0409 *  \n## body         0.96650    0.04766   20.28   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 334.7 on 60 degrees of freedom\n## Multiple R-squared:  0.8727, Adjusted R-squared:  0.8705 \n## F-statistic: 411.2 on 1 and 60 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n# Scatterplot of brain weight (y) vs body weight (x)\n# Include a model trend line (i.e. a representation of mammal_model)\nggplot(mammals, aes(y = brain, x = body)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n# Residual plot for mammal_model\nggplot(mammal_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\nThe biggest issue here is that the assumption of equal variance is violated. There’s much greater variability in the residuals as the predictions increase. This is because there’s much greater variability in the brain weights (y) as body weights (x) increase.",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-4-exploring-mammals-1",
    "href": "activities/05-slr-model-eval.html#exercise-4-exploring-mammals-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 4: Exploring mammals",
    "text": "Exercise 4: Exploring mammals\nAnswers will vary.",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition-1",
    "href": "activities/05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the model.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that’s explained by the model (the variance of the predictions) and the variability that’s left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\n“Good” models have residuals that don’t deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe first row corresponds to the weaker model. We can tell because the points are much more dispersed from the trend line than in the second row. Recall that the correlation metric measures how closely clustered points are about a straight line of best fit, so we would expect the correlation to be lower for the first row than the second row.\nThe variance of the residuals is much lower for the second row—the residuals are all quite small. This indicates a stronger model.",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-6-r-squared-interpretations-1",
    "href": "activities/05-slr-model-eval.html#exercise-6-r-squared-interpretations-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 6: R-squared Interpretations",
    "text": "Exercise 6: R-squared Interpretations\n\nsummary(bike_model)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3607.1  -959.2  -153.8   998.2  3304.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -667.916    251.608  -2.655  0.00811 ** \n## temp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1310 on 729 degrees of freedom\n## Multiple R-squared:  0.2961, Adjusted R-squared:  0.2952 \n## F-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16\n\nMultiple R-squared: 0.2961\nInterpretation: 29.61% of the variation in number of registered riders on any given day can be explained by the variation in temperature (specifically, what temperature it “feels” like it is).",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercise-7-further-exploring-r-squared-1",
    "href": "activities/05-slr-model-eval.html#exercise-7-further-exploring-r-squared-1",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercise 7: Further exploring R-squared",
    "text": "Exercise 7: Further exploring R-squared\nIn this exercise, we’ll look at data from a synthetic dataset called Anscombe’s quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\nhead(anscombe)\n##   x1 x2 x3 x4   y1   y2    y3   y4\n## 1 10 10 10  8 8.04 9.14  7.46 6.58\n## 2  8  8  8  8 6.95 8.14  6.77 5.76\n## 3 13 13 13  8 7.58 8.74 12.74 7.71\n## 4  9  9  9  8 8.81 8.77  7.11 8.84\n## 5 11 11 11  8 8.33 9.26  7.81 8.47\n## 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nAll of these models have close to the same intercept, slope, and R-squared!\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\n## \n## Call:\n## lm(formula = y1 ~ x1, data = anscombe)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.92127 -0.45577 -0.04136  0.70941  1.83882 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0001     1.1247   2.667  0.02573 * \n## x1            0.5001     0.1179   4.241  0.00217 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6665, Adjusted R-squared:  0.6295 \n## F-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\nsummary(anscombe_mod2)\n## \n## Call:\n## lm(formula = y2 ~ x2, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.9009 -0.7609  0.1291  0.9491  1.2691 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)    3.001      1.125   2.667  0.02576 * \n## x2             0.500      0.118   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6662, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\nsummary(anscombe_mod3)\n## \n## Call:\n## lm(formula = y3 ~ x3, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1586 -0.6146 -0.2303  0.1540  3.2411 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0025     1.1245   2.670  0.02562 * \n## x3            0.4997     0.1179   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6663, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\nsummary(anscombe_mod4)\n## \n## Call:\n## lm(formula = y4 ~ x4, data = anscombe)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -1.751 -0.831  0.000  0.809  1.839 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0017     1.1239   2.671  0.02559 * \n## x4            0.4999     0.1178   4.243  0.00216 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6667, Adjusted R-squared:  0.6297 \n## F-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nBut when we look at the scatterplots, they all look substantially different, and we would want to approach our modeling differently for each one:\n\nx1 and y1: A linear model seems appropriate for this data.\nx2 and y2: The scatterplot is clearly curved—a “linear” regression model with squared terms, for example, would be more appropriate for this data. (We’ll talk more about ways to handle nonlinear relationships soon!)\nx3 and y3: There is a very clear outlier at about x3 = 13 that we would want to dig into to better understand the context. After that investigation, we might consider removing this outlier and refitting the model.\nx4 and y4: There is clearly something strange going on with most of the cases having an x4 value of exactly 8. We would not want to jump straight into modeling. Instead, we should dig deeper to find out more about this data.\n\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#exercises-8---11",
    "href": "activities/05-slr-model-eval.html#exercises-8---11",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Exercises 8 - 11",
    "text": "Exercises 8 - 11\nNo solutions for these exercises. These require longer discussions, not discrete answers.",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/05-slr-model-eval.html#footnotes",
    "href": "activities/05-slr-model-eval.html#footnotes",
    "title": "Simple Linear Regression - Model Evaluation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://en.wikipedia.org/wiki/W._E._B._Du_Bois↩︎",
    "crumbs": [
      "Simple Linear Regression - Model Evaluation"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html",
    "href": "activities/02-foundations-univariate.html",
    "title": "Univariate Visualization & Summaries",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you’ve settled in before class begins.",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#learning-goals",
    "href": "activities/02-foundations-univariate.html#learning-goals",
    "title": "Univariate Visualization & Summaries",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this activity, you should be able to:\n\nWhat summarizations and visualizations are appropriate for categorical or quantitative variables\nWrite R code to read in data and to summarize and visualize a single variable at a time.\nInterpret key features of barplots, boxplots, histograms, and density plots\nDescribe information about the distribution of a quantitative variable using the concepts of shape, center, spread, and outliers\nRelate summary statistics of data to the concepts of shape, center, spread, and outliers",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#readings-and-videos",
    "href": "activities/02-foundations-univariate.html#readings-and-videos",
    "title": "Univariate Visualization & Summaries",
    "section": "Readings and videos",
    "text": "Readings and videos\nYou should have gone through the followings before the class and finished checkpoint quizzes!\n\nReading: Sections 2.1-2.4, 2.6 in the STAT 155 Notes\nVideos:\n\nUnivariate summaries (slides)\n\nPart 1\nPart 2\n\nR Code for Categorical Visualization and Summarization\nR Code for Quantitative Visualization and Summarization\nQuarto docs\n\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-1-importing-and-getting-to-know-the-data",
    "href": "activities/02-foundations-univariate.html#exercise-1-importing-and-getting-to-know-the-data",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 1: Importing and getting to know the data",
    "text": "Exercise 1: Importing and getting to know the data\nFirst, in the Console pane of RStudio, run the following command to install some necessary packages (you will need to do this any time you are installing a new package):\ninstall.packages(\"tidyverse\") # We have already installed it!\nNow, in the Quarto pane, run the following code chunk to load the package and load a dataset (you can either click the green arrow in the top right of the code chunk, put your cursor in the code chunk and hit Ctrl+Alt+C [on Windows/Linux] or Command+Option+C [on Mac]).\n\n# Load package\nlibrary(tidyverse)\n\n# Read in the Dear Abby data\nabby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\n\nThroughout this activity, we’ll work only with the most recent year of data, from 2017. Run the following chunk:\n\n# Wrangle the Dear Abby data\n# Ignore this code for now!\nabby &lt;- abby %&gt;% \n  filter(year == 2017) %&gt;% \n  mutate(month = month(month, label = TRUE)) %&gt;%\n  mutate(\n    parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\"),\n    marriage = str_detect(question_only, \"marriage|marry|married\"),\n    money = str_detect(question_only, \"money|finance\")\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    themes = c(\n      if (parents) \"parents\",\n      if (marriage) \"marriage\",\n      if (money) \"money\"\n    ) %&gt;% paste(collapse = \", \"),\n    themes = ifelse(themes == \"\", \"other\", themes)\n  ) %&gt;%\n  ungroup() %&gt;% \n  select(year, month, day, question_only, bing_pos, afinn_overall, afinn_pos, afinn_neg, themes)\n\n\nClick on the Environment tab (generally in the upper right hand pane in RStudio). Then click the abby line. The abby data will pop up as a separate pane (like viewing a spreadsheet) – check it out.\nIn this tidy dataset, what is the unit of observation? That is, what is represented in each row of the dataset?\nWhat term do we use for the columns of the dataset?\nTry out each function below. Identify what each function tells you about the abby data and note this in the ???:\n\n\n# ??? [what do both numbers mean?]\ndim(abby)\n## [1] 514   9\n\n\n# ???\nnrow(abby)\n## [1] 514\n\n\n# ???\nncol(abby)\n## [1] 9\n\n\n# ???\nhead(abby)\n## # A tibble: 6 × 9\n##    year month day   question_only     bing_pos afinn_overall afinn_pos afinn_neg\n##   &lt;dbl&gt; &lt;ord&gt; &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1  2017 Aug   30    \"i moved to the …    0.75             14        16         2\n## 2  2017 Aug   30    \"under what circ…   NA                NA        NA        NA\n## 3  2017 Aug   28    \"i'm not a dog p…    0.333             5         5         0\n## 4  2017 Aug   28    \"my 62-year-old …    0.143           -11         8        19\n## 5  2017 Aug   27    \"i have a friend…    0.222             0         7         7\n## 6  2017 Aug   27    \"i have been sel…    0.333            -5         2         7\n## # ℹ 1 more variable: themes &lt;chr&gt;\n\n\n# ???\nnames(abby)\n## [1] \"year\"          \"month\"         \"day\"           \"question_only\"\n## [5] \"bing_pos\"      \"afinn_overall\" \"afinn_pos\"     \"afinn_neg\"    \n## [9] \"themes\"\n\n\n[OPTIONAL] If you’re not sure how exactly to use a function, you can pull up a built-in help page with information about the arguments a function takes (i.e., what goes inside the parentheses), and the output it produces. To do this, click inside the Console pane, and enter ?function_name. For example, to pull up a help page for the dim() function, we can type ?dim and hit Enter. Try pulling up the help page for the read_csv() function we used to load the dataset.",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-2-preparing-to-summarize-and-visualize-the-data",
    "href": "activities/02-foundations-univariate.html#exercise-2-preparing-to-summarize-and-visualize-the-data",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 2: Preparing to summarize and visualize the data",
    "text": "Exercise 2: Preparing to summarize and visualize the data\nIn the next exercises, we will be exploring themes in the Dear Abby questions and the overall “mood” or sentiment of the questions. Before continuing, read the codebook for this dataset for some context about sentiment analysis, which gives us a measure of the mood/sentiment of a text.\n\nWhat sentiment variables do we have in the dataset? Are they quantitative or categorical?\nCheck out the theme variable. Is this quantitative or categorical?\nWhat visualizations are appropriate for looking at the distribution of a single quantitative variable? What about a single categorical variable?",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-3-exploring-themes-in-the-letters",
    "href": "activities/02-foundations-univariate.html#exercise-3-exploring-themes-in-the-letters",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 3: Exploring themes in the letters",
    "text": "Exercise 3: Exploring themes in the letters\n\nThe code below makes a barplot of the themes variable using the ggplot2 visualization package. Before making the plot, make note of what you expect the plot might look like. (This might be hard–just do your best!) Then compare to what you observe when you run the code chunk to make the plot. (Clearly defining your expectations first is good scientific practice to avoid confirmation bias.)\n\n\n# Load package\n# install.packages(\"ggplot2\") # Run in R Console first time to install (copy without '#')\nlibrary(ggplot2)\n\n# barplot\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\nWe can follow up on the barplot with a simple numerical summary. Whereas the ggplot2 package is great for visualizations, dplyr is great for numerical summaries. The code below constructs a table of the number of questions with each theme. Make sure that these numerical summaries match up with what you saw in the barplot.\n\n\n# install.packages(\"dplyr\")\n# Construct a table of counts\nabby %&gt;% \n    count(themes)\n## # A tibble: 8 × 2\n##   themes                       n\n##   &lt;chr&gt;                    &lt;int&gt;\n## 1 marriage                    75\n## 2 marriage, money              5\n## 3 money                       21\n## 4 other                      234\n## 5 parents                    127\n## 6 parents, marriage           33\n## 7 parents, marriage, money     4\n## 8 parents, money              15\n\n\nBefore proceeding, let’s break down the plotting code above. Run each chunk to see how the two lines of code above build up the plot in “layers”. Add comments (on the lines starting with #) to document what you notice.\n\n\n# ???\nggplot(abby, aes(x = themes)) #sets up the \"canvas\" of the plot with axis labels\n\n\n\n\n\n\n\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() # Adds the bars- Any Problem you notice?\n\n\n\n\n\n\n\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) #Rotates the x axis labels\n\n\n\n\n\n\n\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) # Changes the visual theme of the plot with a white background and removes gridlines",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-4-exploring-sentiment",
    "href": "activities/02-foundations-univariate.html#exercise-4-exploring-sentiment",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 4: Exploring sentiment",
    "text": "Exercise 4: Exploring sentiment\nWe’ll look at the distribution of the bing_pos sentiment variable and associated summary statistics.\n\n\n\n\nThe code below creates a boxplot of this variable. In the comment, make note of how this code is similar to the code for the barplot above. As in the previous exercise, before running the code chunk to create the plot, make note of what you expect the boxplot to look like.\n\n\n# ???\nggplot(abby, aes(x = bing_pos)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nChallenge: Using the code for the barplot and boxplot as a guide, try to make a histogram and a density plot of the overall average ratings.\n\nWhat information is given by the tallest bar of the histogram?\nHow would you describe the shape of the distribution?\n\n\n\n# Histogram\n\n# Density plot\n\n\nWe can compute summary statistics (numerical summaries) for a quantitative variable using the summary() function or with the summarize() function from the dplyr package. (1st Qu. and 3rd Qu. stand for first and third quartile.) After inspecting these summaries, look back to your boxplot, histogram, and density plot. Which plots show which summaries most clearly?\n\n\n# Summary statistics\n# Using summary() - convenient for computing many summaries in one command\n# Does not show the standard deviation\nabby %&gt;% \n    select(bing_pos) %&gt;% \n    summary()\n##     bing_pos     \n##  Min.   :0.0000  \n##  1st Qu.:0.1667  \n##  Median :0.3333  \n##  Mean   :0.3650  \n##  3rd Qu.:0.5000  \n##  Max.   :1.0000  \n##  NA's   :19\n\n# Using summarize() from dplyr\n# Note that we use %&gt;% to pipe the data into the summarize() function\n# We need to use na.rm = TRUE because there are missing values (NAs)\nabby %&gt;% \n    summarize(mean(bing_pos, na.rm = TRUE), median(bing_pos, na.rm = TRUE), sd(bing_pos, na.rm = TRUE))\n## # A tibble: 1 × 3\n##   `mean(bing_pos, na.rm = TRUE)` median(bing_pos, na.rm…¹ sd(bing_pos, na.rm =…²\n##                            &lt;dbl&gt;                    &lt;dbl&gt;                  &lt;dbl&gt;\n## 1                          0.365                    0.333                  0.279\n## # ℹ abbreviated names: ¹​`median(bing_pos, na.rm = TRUE)`,\n## #   ²​`sd(bing_pos, na.rm = TRUE)`\n\n\nWrite a good paragraph describing the information in the histogram (or density plot) by discussing shape, center, spread, and outliers. Incorporate the numerical summaries from part c.",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#pause-math-box",
    "href": "activities/02-foundations-univariate.html#pause-math-box",
    "title": "Univariate Visualization & Summaries",
    "section": "Pause: Math box",
    "text": "Pause: Math box\nBelow is an example of a “math box” which summarizes the formulas for some of the numerical summaries above. You are not required to memorize, nor will you be assessed on, any formulas presented in this or any future math box. They serve 3 purposes:\n\nTo emphasize that there’s “math” / a formal structure behind what we’re doing.\nTo provide students that plan to continue studying Statistics a glimpse into the formal statistical theory they’ll explore in later courses.\nTo make happy the students that are simply interested in math!\n\n\n\n\n\n\n\n\n\n\nMATH BOX: Univariate numerical summaries\n\n\n\nLet \\((y_1, y_2, ..., y_n)\\) be a sample of \\(n\\) data points.\nmean: \\[\\overline{y} = \\frac{y_1 + y_2 + \\cdots + y_n}{n} = \\frac{\\sum_{i=1}^n y_i}{n}\\]\nvariance: \\[\\text{var}(y) = \\frac{(y_1 - \\overline{y})^2 + (y_2 - \\overline{y})^2 + \\cdots + (y_n - \\overline{y})^2}{n - 1} = \\frac{\\sum_{i=1}^n (y_i - \\overline{y})^2}{n - 1}\\]\nstandard deviation: \\[\\text{sd}(y) = \\sqrt{\\text{var}(y)}\\]",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-5-box-plots-vs.-histograms-vs.-density-plots",
    "href": "activities/02-foundations-univariate.html#exercise-5-box-plots-vs.-histograms-vs.-density-plots",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 5: Box plots vs. histograms vs. density plots",
    "text": "Exercise 5: Box plots vs. histograms vs. density plots\nWe took 3 different approaches to plotting the quantitative average course variable above. They all have pros and cons.\n\nWhat is one pro about the boxplot in comparison to the histogram and density plot?\nWhat is one con about the boxplot in comparison to the histogram and density plots?\nIn this example, which plot do you prefer and why?",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-6-returning-to-our-context-looking-ahead",
    "href": "activities/02-foundations-univariate.html#exercise-6-returning-to-our-context-looking-ahead",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 6: Returning to our context, looking ahead",
    "text": "Exercise 6: Returning to our context, looking ahead\nIn this activity, we explored data on Dear Abby question, with a focus on exploring a single variable at a time.\n\nIn big picture terms, what have we learned about Dear Abby questions?\nWhat further curiosities do you have about the data?",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-7-different-ways-to-think-about-data-visualization",
    "href": "activities/02-foundations-univariate.html#exercise-7-different-ways-to-think-about-data-visualization",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 7: Different ways to think about data visualization",
    "text": "Exercise 7: Different ways to think about data visualization\nIn working with and visualizing data, it’s important to keep in mind what a data point represents. It can reflect the experience of a real person. It might reflect the sentiment in a piece of art. It might reflect history. We’ve taken one very narrow and technical approach to data visualization. Check out the following examples, and write some notes about anything you find interesting.\n\nDear Data\nW.E.B. DuBois\nDecolonizing Data Viz",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-8-rendering-your-work",
    "href": "activities/02-foundations-univariate.html#exercise-8-rendering-your-work",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 8: Rendering your work",
    "text": "Exercise 8: Rendering your work\nSave this file, and then click the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\n\nScroll through and inspect the document to see how your work was translated into this HTML format. Neat!\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check.",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#reflection",
    "href": "activities/02-foundations-univariate.html#reflection",
    "title": "Univariate Visualization & Summaries",
    "section": "Reflection",
    "text": "Reflection\nGo to the top of this file and review the learning objectives for this lesson. Which objectives do you have a good handle on, are at least familiar with, or are struggling with? What feels challenging right now? What are some wins from the day?\n\nResponse: Put your response here.",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#advice-make-an-r-code-cheat-sheet",
    "href": "activities/02-foundations-univariate.html#advice-make-an-r-code-cheat-sheet",
    "title": "Univariate Visualization & Summaries",
    "section": "Advice: make an R code “cheat sheet”!",
    "text": "Advice: make an R code “cheat sheet”!\nYou will continue to pick up new R code and ideas. You’re highly encouraged to start tracking this in a cheat sheet (eg: in a Google doc). The cheat sheet will be a handy reference for you, and the act of making it will help deepen your understanding and retention.",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-9-read-in-and-get-to-know-the-weather-data",
    "href": "activities/02-foundations-univariate.html#exercise-9-read-in-and-get-to-know-the-weather-data",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 9: Read in and get to know the weather data",
    "text": "Exercise 9: Read in and get to know the weather data\nDaily weather data are available for 3 locations in Perth, Australia.\n\nView the codebook here.\nComplete the code below to read in the data.\n\n\n# Replace the ??? with your own name for the weather data\n# Replace the ___ with the correct function\n??? &lt;- ___(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n## Error in parse(text = input): &lt;text&gt;:3:5: unexpected assignment\n## 2: # Replace the ___ with the correct function\n## 3: ??? &lt;-\n##        ^",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-10-exploring-the-data-structure",
    "href": "activities/02-foundations-univariate.html#exercise-10-exploring-the-data-structure",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 10: Exploring the data structure",
    "text": "Exercise 10: Exploring the data structure\nCheck out the basic features of the weather data.\n\n# Examine the first six cases\n\n# Find the dimensions of the data\n\nWhat does a case represent in this data?",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-11-exploring-rainfall",
    "href": "activities/02-foundations-univariate.html#exercise-11-exploring-rainfall",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 11: Exploring rainfall",
    "text": "Exercise 11: Exploring rainfall\nThe raintoday variable contains information about rainfall.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about rainfall in Perth?\n\n\n# Visualization\n\n# Numerical summaries",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-12-exploring-temperature",
    "href": "activities/02-foundations-univariate.html#exercise-12-exploring-temperature",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 12: Exploring temperature",
    "text": "Exercise 12: Exploring temperature\nThe maxtemp variable contains information on the daily high temperature.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about high temperatures in Perth?\n\n\n# Visualization\n\n# Numerical summaries",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-13-customizing-challenge",
    "href": "activities/02-foundations-univariate.html#exercise-13-customizing-challenge",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 13: Customizing! (CHALLENGE)",
    "text": "Exercise 13: Customizing! (CHALLENGE)\nThough you will naturally absorb some RStudio code throughout the semester, being an effective statistical thinker and “programmer” does not require that we memorize all code. That would be impossible! In contrast, using the foundation you built today, do some digging online to learn how to customize your visualizations.\n\nFor the histogram below, add a title and more meaningful axis labels. Specifically, title the plot “Distribution of max temperatures in Perth”, change the x-axis label to “Maximum temperature” and y-axis label to “Number of days”. HINT: Do a Google search for something like “add axis labels ggplot”.\n\n\n# Add a title and axis labels\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram()\n## Error: object 'weather' not found\n\n\nAdjust the code below in order to color the bars green. NOTE: Color can be an effective tool, but here it is simply gratuitous.\n\n\n# Make the bars green\nggplot(weather, aes(x = raintoday)) + \n    geom_bar()\n## Error: object 'weather' not found\n\n\nCheck out the ggplot2 cheat sheet. Try making some of the other kinds of univariate plots outlined there.\nWhat else would you like to change about your plot? Try it!",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-14-optional-challenge",
    "href": "activities/02-foundations-univariate.html#exercise-14-optional-challenge",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 14: Optional challenge",
    "text": "Exercise 14: Optional challenge\nAt the top of this activity, we searched for words related to some topics of interest (parents, marriage, money) and combined them into a single theme variable. It looked something like this:\n\nabby_new &lt;- abby %&gt;% \n  mutate(\n    parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\"),\n    marriage = str_detect(question_only, \"marriage|marry|married\"),\n    money = str_detect(question_only, \"money|finance\")\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    themes = c(\n      if (parents) \"parents\",\n      if (marriage) \"marriage\",\n      if (money) \"money\"\n    ) %&gt;% paste(collapse = \", \"),\n    themes = ifelse(themes == \"\", \"other\", themes)\n  ) %&gt;%\n  ungroup()\n\nCheck it out:\n\nhead(abby_new)\n## # A tibble: 6 × 12\n##    year month day   question_only     bing_pos afinn_overall afinn_pos afinn_neg\n##   &lt;dbl&gt; &lt;ord&gt; &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1  2017 Aug   30    \"i moved to the …    0.75             14        16         2\n## 2  2017 Aug   30    \"under what circ…   NA                NA        NA        NA\n## 3  2017 Aug   28    \"i'm not a dog p…    0.333             5         5         0\n## 4  2017 Aug   28    \"my 62-year-old …    0.143           -11         8        19\n## 5  2017 Aug   27    \"i have a friend…    0.222             0         7         7\n## 6  2017 Aug   27    \"i have been sel…    0.333            -5         2         7\n## # ℹ 4 more variables: themes &lt;chr&gt;, parents &lt;lgl&gt;, marriage &lt;lgl&gt;, money &lt;lgl&gt;\n\n\nUnderstand the code!\n\nInside mutate() the line parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\") created a new variable called parents. This variable takes on TRUE or FALSE. Explain what TRUE and FALSE mean here.\nThe themes variable combines the information from the parents, marriage, and money variables. Check out the themes for the first 3 rows / data points. Convince yourself that you understand how it corresponds to the parents, marriage, and money variables.\n\nBeyond parents, marriage, and money, what are some other topics that might pop up in the Dear Abby letters (and that you’re interested in exploring)? Modify the code below to explore those topics! Update the themes variable accordingly.\n\n\nabby_new &lt;- abby %&gt;% \n  mutate(\n    parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\"),\n    marriage = str_detect(question_only, \"marriage|marry|married\"),\n    money = str_detect(question_only, \"money|finance\")\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    themes = c(\n      if (parents) \"parents\",\n      if (marriage) \"marriage\",\n      if (money) \"money\"\n    ) %&gt;% paste(collapse = \", \"),\n    themes = ifelse(themes == \"\", \"other\", themes)\n  ) %&gt;%\n  ungroup()\n\n# Check out the raw data\nhead(abby_new)\n## # A tibble: 6 × 12\n##    year month day   question_only     bing_pos afinn_overall afinn_pos afinn_neg\n##   &lt;dbl&gt; &lt;ord&gt; &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1  2017 Aug   30    \"i moved to the …    0.75             14        16         2\n## 2  2017 Aug   30    \"under what circ…   NA                NA        NA        NA\n## 3  2017 Aug   28    \"i'm not a dog p…    0.333             5         5         0\n## 4  2017 Aug   28    \"my 62-year-old …    0.143           -11         8        19\n## 5  2017 Aug   27    \"i have a friend…    0.222             0         7         7\n## 6  2017 Aug   27    \"i have been sel…    0.333            -5         2         7\n## # ℹ 4 more variables: themes &lt;chr&gt;, parents &lt;lgl&gt;, marriage &lt;lgl&gt;, money &lt;lgl&gt;\n\n# Check out the number of letters belonging to each theme\nabby_new %&gt;% \n  count(themes)\n## # A tibble: 8 × 2\n##   themes                       n\n##   &lt;chr&gt;                    &lt;int&gt;\n## 1 marriage                    75\n## 2 marriage, money              5\n## 3 money                       21\n## 4 other                      234\n## 5 parents                    127\n## 6 parents, marriage           33\n## 7 parents, marriage, money     4\n## 8 parents, money              15",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-1-importing-and-getting-to-know-the-data-1",
    "href": "activities/02-foundations-univariate.html#exercise-1-importing-and-getting-to-know-the-data-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 1: Importing and getting to know the data",
    "text": "Exercise 1: Importing and getting to know the data\n\nNote how clicking the abby data causes both a popup pane and the command View(abby) to appear in the Console. In fact, the View() function is the underlying command that opens a dataset pane. (View() should always be entered in the Console and NOT your Quarto document.)\nEach row / case corresponds to a single question.\nColumns = variables\nTry out each function below. Identify what each function tells you about the abby data and note this in the ???:\n\n\n# First number = number of rows / cases\n# Second number = number of columns / variables\ndim(abby)\n## [1] 514   6\n\n# Number of rows (cases)\nnrow(abby)\n## [1] 514\n\n# Number of columns (variables)\nncol(abby)\n## [1] 6\n\n# View first few rows of the dataset (6 rows, by default)\nhead(abby)\n## # A tibble: 6 × 6\n##    year month day   question_only                                bing_pos themes\n##   &lt;dbl&gt; &lt;ord&gt; &lt;chr&gt; &lt;chr&gt;                                           &lt;dbl&gt; &lt;chr&gt; \n## 1  2017 Aug   30    \"i moved to the philippines five years ago.…    0.75  paren…\n## 2  2017 Aug   30    \"under what circumstances do you ask your a…   NA     money \n## 3  2017 Aug   28    \"i'm not a dog person. i'm not even an anim…    0.333 other \n## 4  2017 Aug   28    \"my 62-year-old father has recently started…    0.143 paren…\n## 5  2017 Aug   27    \"i have a friend, \\\"charlene,\\\" whom i met …    0.222 other \n## 6  2017 Aug   27    \"i have been selected to attend a symposium…    0.333 other\n\n# Get all column (variable) names\nnames(abby)\n## [1] \"year\"          \"month\"         \"day\"           \"question_only\"\n## [5] \"bing_pos\"      \"themes\"\n\n\nWe can display the first 10 rows with head(abby, n = 10).",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-2-preparing-to-summarize-and-visualize-the-data-1",
    "href": "activities/02-foundations-univariate.html#exercise-2-preparing-to-summarize-and-visualize-the-data-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 2: Preparing to summarize and visualize the data",
    "text": "Exercise 2: Preparing to summarize and visualize the data\n\nThe sentiment variables are afinn_overall, afinn_pos, afinn_neg, and bing_pos, and they are quantitative. The afinn variables don’t have units but we can still get a sense of the scale by remembering that each word gets a score between -5 and 5. The bing_pos variable doesn’t have units because it’s a fraction, but we know that it ranges from 0 to 1.\ncategorical\nAppropriate visualizations:\n\nsingle quantitative variable: boxplot, histogram, density plot\nsingle categorical variable: barplot",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-3-exploring-themes-in-the-letters-1",
    "href": "activities/02-foundations-univariate.html#exercise-3-exploring-themes-in-the-letters-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 3: Exploring themes in the letters",
    "text": "Exercise 3: Exploring themes in the letters\n\nExpectations about the plot will vary\n\n\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\nCounts in the table below match the barplot\n\n\n# Construct a table of counts\nabby %&gt;% \n    count(themes)\n## # A tibble: 8 × 2\n##   themes                       n\n##   &lt;chr&gt;                    &lt;int&gt;\n## 1 marriage                    75\n## 2 marriage, money              5\n## 3 money                       21\n## 4 other                      234\n## 5 parents                    127\n## 6 parents, marriage           33\n## 7 parents, marriage, money     4\n## 8 parents, money              15\n\n\nWhat do the plot layers do?\n\n\n# Just sets up the \"canvas\" of the plot with axis labels\nggplot(abby, aes(x = themes))\n\n\n\n\n\n\n\n\n\n# Adds the bars\nggplot(abby, aes(x = themes)) +\n    geom_bar()\n\n\n\n\n\n\n\n\n\n# Rotates the x axis labels\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\n# Changes the visual theme of the plot with a white background and removes gridlines\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-4-exploring-sentiment-1",
    "href": "activities/02-foundations-univariate.html#exercise-4-exploring-sentiment-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 4: Exploring sentiment",
    "text": "Exercise 4: Exploring sentiment\n\n\n\n\nggplot(abby, aes(x = bing_pos)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nWe replace geom_boxplot() with geom_histogram() and geom_density().\n\n\n# Histogram\nggplot(abby, aes(x = bing_pos)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\n# Density plot\nggplot(abby, aes(x = bing_pos)) +\n    geom_density()\n\n\n\n\n\n\n\n\n\n\nBoxplot shows min, max, median, 1st and 3rd quartile easily. (It shows median, 1st and 3rd quartile directly as lines)\nHistogram and density plot show min and max but the mean and median aren’t shown directly–we have to roughly guess based on the peak of the distribution\n\n\n\n# Summary statistics\nabby %&gt;% \n    select(bing_pos) %&gt;% \n    summary()\n##     bing_pos     \n##  Min.   :0.0000  \n##  1st Qu.:0.1667  \n##  Median :0.3333  \n##  Mean   :0.3650  \n##  3rd Qu.:0.5000  \n##  Max.   :1.0000  \n##  NA's   :19\n\nabby %&gt;% \n    summarize(mean(bing_pos, na.rm = TRUE), median(bing_pos, na.rm = TRUE), sd(bing_pos, na.rm = TRUE))\n## # A tibble: 1 × 3\n##   `mean(bing_pos, na.rm = TRUE)` median(bing_pos, na.rm…¹ sd(bing_pos, na.rm =…²\n##                            &lt;dbl&gt;                    &lt;dbl&gt;                  &lt;dbl&gt;\n## 1                          0.365                    0.333                  0.279\n## # ℹ abbreviated names: ¹​`median(bing_pos, na.rm = TRUE)`,\n## #   ²​`sd(bing_pos, na.rm = TRUE)`\n\n\nThe distribution of sentiment scores is roughly tri-modal, ranging from 0 to 1. There’s a group of very negative letters (with roughly 0% of words being positive), a group of very positive letters (with roughly 100% of words being positive), and a group of mostly negative letters. The typical sentiment is around 0.34.",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-5-box-plots-vs.-histograms-vs.-density-plots-1",
    "href": "activities/02-foundations-univariate.html#exercise-5-box-plots-vs.-histograms-vs.-density-plots-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 5: Box plots vs. histograms vs. density plots",
    "text": "Exercise 5: Box plots vs. histograms vs. density plots\n\nBoxplots very clearly show key summary statistics like median, 1st and 3rd quartile\nBoxplots can oversimplify by not showing the shape of the distribution.",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-6-returning-to-our-context-looking-ahead-1",
    "href": "activities/02-foundations-univariate.html#exercise-6-returning-to-our-context-looking-ahead-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 6: Returning to our context, looking ahead",
    "text": "Exercise 6: Returning to our context, looking ahead\n\nAnswers will vary",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-9-read-in-and-get-to-know-the-weather-data-1",
    "href": "activities/02-foundations-univariate.html#exercise-9-read-in-and-get-to-know-the-weather-data-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 9: Read in and get to know the weather data",
    "text": "Exercise 9: Read in and get to know the weather data\n\nweather &lt;- read_csv(\"https://raw.githubusercontent.com/Mac-STAT/data/main/weather_3_locations.csv\")",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-10-exploring-the-data-structure-1",
    "href": "activities/02-foundations-univariate.html#exercise-10-exploring-the-data-structure-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 10: Exploring the data structure",
    "text": "Exercise 10: Exploring the data structure\nCheck out the basic features of the weather data.\n\n# Examine the first six cases\nhead(weather)\n## # A tibble: 6 × 24\n##   date       location  mintemp maxtemp rainfall evaporation sunshine windgustdir\n##   &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      \n## 1 2020-01-01 Wollongo…    17.1    23.1        0          NA       NA SSW        \n## 2 2020-01-02 Wollongo…    17.7    24.2        0          NA       NA SSW        \n## 3 2020-01-03 Wollongo…    19.7    26.8        0          NA       NA NE         \n## 4 2020-01-04 Wollongo…    20.4    35.5        0          NA       NA SSW        \n## 5 2020-01-05 Wollongo…    19.8    21.4        0          NA       NA SSW        \n## 6 2020-01-06 Wollongo…    18.3    22.9        0          NA       NA NE         \n## # ℹ 16 more variables: windgustspeed &lt;dbl&gt;, winddir9am &lt;chr&gt;, winddir3pm &lt;chr&gt;,\n## #   windspeed9am &lt;dbl&gt;, windspeed3pm &lt;dbl&gt;, humidity9am &lt;dbl&gt;,\n## #   humidity3pm &lt;dbl&gt;, pressure9am &lt;dbl&gt;, pressure3pm &lt;dbl&gt;, cloud9am &lt;dbl&gt;,\n## #   cloud3pm &lt;dbl&gt;, temp9am &lt;dbl&gt;, temp3pm &lt;dbl&gt;, raintoday &lt;chr&gt;,\n## #   risk_mm &lt;dbl&gt;, raintomorrow &lt;chr&gt;\n\n# Find the dimensions of the data\ndim(weather)\n## [1] 2367   24\n\nA case represents a day of the year in a particular area (Hobart, Uluru, Wollongong as seen by the location variable).",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-11-exploring-rainfall-1",
    "href": "activities/02-foundations-univariate.html#exercise-11-exploring-rainfall-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 11: Exploring rainfall",
    "text": "Exercise 11: Exploring rainfall\nThe raintoday variable contains information about rainfall.\n\nraintoday is categorical (No, Yes)\nIt is more common to have no rain.\n\n\n# Visualization\nggplot(weather, aes(x = raintoday)) +\n    geom_bar()\n\n\n\n\n\n\n\n\n# Numerical summaries\nweather %&gt;% \n    count(raintoday)\n## # A tibble: 3 × 2\n##   raintoday     n\n##   &lt;chr&gt;     &lt;int&gt;\n## 1 No         1864\n## 2 Yes         446\n## 3 &lt;NA&gt;         57",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-12-exploring-temperature-1",
    "href": "activities/02-foundations-univariate.html#exercise-12-exploring-temperature-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 12: Exploring temperature",
    "text": "Exercise 12: Exploring temperature\nThe maxtemp variable contains information on the daily high temperature.\n\nmaxtemp is quantitative\nThe typical max temperature is around 23 degrees Celsius (with an average of 23.62 and a median of 22 degrees). The max temperatures ranged from 8.6 to 45.4 degrees. Finally, on the typical day, the max temp falls about 7.8 degrees from the mean. There are multiple modes in the distribution of max temperature—this likely reflects the different cities in the dataset.\n\n\n# Visualization\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram()\n\n\n\n\n\n\n\n\n# Numerical summaries\nsummary(weather$maxtemp)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    8.60   18.10   22.00   23.62   27.40   45.40      34\n\n# There are missing values (NAs) in this variable, so we add\n# the na.rm = TRUE argument\nweather %&gt;% \n    summarize(sd(maxtemp, na.rm = TRUE))\n## # A tibble: 1 × 1\n##   `sd(maxtemp, na.rm = TRUE)`\n##                         &lt;dbl&gt;\n## 1                        7.80",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "activities/02-foundations-univariate.html#exercise-13-customizing-challenge-1",
    "href": "activities/02-foundations-univariate.html#exercise-13-customizing-challenge-1",
    "title": "Univariate Visualization & Summaries",
    "section": "Exercise 13: Customizing! (CHALLENGE)",
    "text": "Exercise 13: Customizing! (CHALLENGE)\n\n\n\n\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram() + \n    labs(x = \"Maximum temperature\", y = \"Number of days\", title = \"Distribution of max temperatures in Perth\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Make the bars green\nggplot(weather, aes(x = raintoday)) + \n    geom_bar(fill = \"green\")",
    "crumbs": [
      "Univariate Visualization & Summaries"
    ]
  },
  {
    "objectID": "R_Resources.html",
    "href": "R_Resources.html",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "Crowd-sourced R functions\nInteractive RStudio tutorials (R basics, data viz, and more)\nMarkdown (Quarto) basics, and Quarto/RStudio tutorial\nRStudio cheatsheets\nGoogle it! If you have a question about R, someone else probably asked it. Add “R tidyverse” to your search term.\nExample: scatterplot R tidyverse\nNote about ChatGPT for code: Please avoid using ChatGPT as a first resort for R code. It often suggests overly wordy or unfamiliar approaches. Our goal is for you to understand the code you write; sticking to tools and syntax we use in class will support your learning best."
  },
  {
    "objectID": "R_Resources.html#getting-help",
    "href": "R_Resources.html#getting-help",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "Crowd-sourced R functions\nInteractive RStudio tutorials (R basics, data viz, and more)\nMarkdown (Quarto) basics, and Quarto/RStudio tutorial\nRStudio cheatsheets\nGoogle it! If you have a question about R, someone else probably asked it. Add “R tidyverse” to your search term.\nExample: scatterplot R tidyverse\nNote about ChatGPT for code: Please avoid using ChatGPT as a first resort for R code. It often suggests overly wordy or unfamiliar approaches. Our goal is for you to understand the code you write; sticking to tools and syntax we use in class will support your learning best."
  },
  {
    "objectID": "R_Resources.html#getting-started",
    "href": "R_Resources.html#getting-started",
    "title": "R and RStudio Resources",
    "section": "Getting Started",
    "text": "Getting Started\nThe videos below introduce R and RStudio and show how to install them on your computer. Start with the overview, then watch the step-by-step video for your operating system.\nDownload links (mentioned in the videos): - R: http://cran.r-project.org/ - RStudio: https://www.rstudio.com/products/rstudio/download/#download\n\n\n\n\n\n\nImportant\n\n\n\nVersion numbers in the videos are out-of-date. Please download the latest versions of both R and RStudio. As of August 25, 2025, the latest versions are: R 4.5.1 and RStudio 2025.05.1+513.\n\n\n\nInstallation / Overview\n\nInstalling R and RStudio (Overview) (Length: 4:30)\n\nPick one of the following: - Mac — Installing R and RStudio Step-by-Step (Length: 3:24) - Windows — Installing R and RStudio Step-by-Step (Length: 5:43)\nIf you run into installation issues, contact me right away. If we can’t get RStudio working locally, you can use Macalester’s online RStudio server:\nQuick intro video"
  },
  {
    "objectID": "R_Resources.html#intro-videos-to-r-watch-in-order",
    "href": "R_Resources.html#intro-videos-to-r-watch-in-order",
    "title": "R and RStudio Resources",
    "section": "Intro Videos to R (watch in order)",
    "text": "Intro Videos to R (watch in order)\n\nIntro to R and RStudio (11:31)\nR Data Types (8:05)\nR Error Messages and Troubleshooting (Optional) (7:52)\nIntro to RMarkdown / Quarto (9:33)\nFile Structure & Organization (Optional)\n\nMac (5:13)\nWindows (7:44)\n\nTips on File Naming & Organization (Optional)\nR Packages (7:30)\n\n\nYou can adjust video speed and pause as needed. If anything doesn’t work, please let me know so we can fix it quickly."
  },
  {
    "objectID": "activities/01_foundations_welcome.html",
    "href": "activities/01_foundations_welcome.html",
    "title": "Collecting and Summarizing Data",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you’ve settled in before class begins.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#see-class-notes",
    "href": "activities/01_foundations_welcome.html#see-class-notes",
    "title": "Collecting and Summarizing Data",
    "section": "See class notes",
    "text": "See class notes\nGo to your class-notes to see what we covered in live-note taking!\n\n\n\nEXAMPLE 1: Tidy data (Class Activities!)\nWelcome to the first in-class activities of STAT 155! Fill out the Day 1 Activities form of the following questions (anonymous). We’ll come back to this in a future class. Wait until everyone in your group is done with this.\n\nHow many hours of sleep did you get last night?\nHow many cups of coffee did you drink this morning?\nWhat is your declared or potential major? (If you are a double major, just pick whichever one you think of first.)\nWhat is your anticipated graduation year?\nHow many stats/data science courses have you taken in the past?\nOn a scale of 1 (get me out of here) to 10 (yay!), how excited are you about this course?\nIs it your birthday this semester? (yes/no)\nHow many unread emails do you have in your inbox right now?",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#example-1-use-r-as-a-calculator",
    "href": "activities/01_foundations_welcome.html#example-1-use-r-as-a-calculator",
    "title": "Collecting and Summarizing Data",
    "section": "Example 1: Use R as a calculator",
    "text": "Example 1: Use R as a calculator\nType the following lines in the console (bottom left), one by one, hitting Return/Enter after each line. In some cases you might even get an error! This error is important to learning how R code does and doesn’t work.\n\n4 + 2\n\n\n4^2\n\n\n4*2\n\n\n4(2)",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#example-2-functions-and-arguments",
    "href": "activities/01_foundations_welcome.html#example-2-functions-and-arguments",
    "title": "Collecting and Summarizing Data",
    "section": "Example 2: Functions and arguments",
    "text": "Example 2: Functions and arguments\nWe can also use built-in functions to perform common tasks. These functions have names and require information about arguments in order to run:\nfunction(argument) Cheatcode: RiceCooker(Rice)\nTry out the following functions one by one in the RStudio console. For each function, note its…\n\nname\nthe argument or information it needs to run\nwhat output it produces (what the function does)\nhow the name connects to what the function does\n\n\nsqrt(9)\n\n\nnchar(\"macalester\")\n\n\nsqrt(nchar(\"snow\"))\n\nSome functions have more than 1 argument, separated by commas:\nfunction(argument1 = ___, argument2 = ___) Cheatcode: RiceCooker(Rice,Chicken)\nTry out the following, one by one.\n\nrep(x = 2, times = 5)\n\n\nrep(times = 5, x = 2)\n\n\nrep(2, 5)\n\n\nrep(5, 2)\n\nFinally, R is case sensitive. Try using Rep() instead of rep(). Take time to read the error message!\n\nRep(5, 2)",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#example-3-save-it-for-later",
    "href": "activities/01_foundations_welcome.html#example-3-save-it-for-later",
    "title": "Collecting and Summarizing Data",
    "section": "Example 3: Save it for later",
    "text": "Example 3: Save it for later\nWe’ll often want to store some R output for later use. In R:\nname &lt;- output\nwhere name is the name under which to store a result, output is the result we wish to store, and &lt;- is the assignment operator (I think of this as an arrow pointing the output into the name).\nIMPORTANT: Try out each line one at a time. Why doesn’t the first line produce any output?\n\ndegrees_c &lt;- -13\n\n\ndegrees_c\n\n\ndegrees_c * (9/5) + 32",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#example-4-import-data",
    "href": "activities/01_foundations_welcome.html#example-4-import-data",
    "title": "Collecting and Summarizing Data",
    "section": "Example 4: Import data",
    "text": "Example 4: Import data\nNext, let’s work with some data!! The first step is importing our data into RStudio. How we do this depends on:\n\nfile format (eg: .xls Excel spreadsheet, .csv, .txt)\nfile location (eg: online, on your desktop, built into RStudio itself).\n\nThe data from the survey you took before class is stored as a .csv file online. Import this data using the read_csv() function, and store it as survey using the code below:\nFirst, in the Console pane of RStudio, run the following command to install some necessary packages (you will need to do this any time you are installing a new package):\ninstall.packages(\"tidyverse\")\n\n# Load the \"tidyverse\" package which contains the read_csv() function\nlibrary(tidyverse)\n\n# Import the data\nsurvey &lt;- read_csv(\"https://mac-stat.github.io/data/112_fall_2024_survey.csv\")\n\n\n\nCheck out the data\nIn the Environment tab in the upper right pane of RStudio, click on survey. What happens?!\n\n\nIn the modern era, datasets often contain hundreds of variables and millions of observations. We need more effective ways to explore such data.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#example-5-get-to-know-the-data",
    "href": "activities/01_foundations_welcome.html#example-5-get-to-know-the-data",
    "title": "Collecting and Summarizing Data",
    "section": "Example 5: Get to know the data",
    "text": "Example 5: Get to know the data\nPAUSE: Make sure you’re still in sync with your group.\nBefore we can learn anything from our data, we must understand its structure. For each function below:\n\ntry it out\ndiscuss with your group what the function does\ndiscuss with your group how the function’s name connects to what it does\n\n\ndim(survey) # (Number of row (case/obs.), Number of column (variable))\n\n\nnrow(survey) # Number of case/obs.\n\n\nncol(survey) # Number of variables\n\n\nhead(survey) # View first few rows of the dataset (6 rows, by default)\n\n\nhead(survey, 3) # Controlling the view of first few rows of the dataset\n\n\ntail(survey) # View first few rows of the dataset (6 rows, by default)\n\n\nnames(survey) # Get all column (variable) names\n\n\nstr(survey) # Overall info about data",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#example-6-code-communication",
    "href": "activities/01_foundations_welcome.html#example-6-code-communication",
    "title": "Collecting and Summarizing Data",
    "section": "Example 6 : Code = communication",
    "text": "Example 6 : Code = communication\nIt’s important to recognize from day 1 that code is a form of communication, both to yourself and others!!!!! Code structure and details are important to readability and clarity, just as grammar, punctuation, spelling, paragraphs, and line spacing are important in written essays. All of the code below works, but has bad structure. With your group, discuss what is unfortunate about each line, then make it better.\n\nseq(from=1, to=9, by=2)\nseq(from = 1, to=9, by=2)\ntemp_cel &lt;- -13\nthisisthetemperaturetodayincelsius &lt;- -13\nthis_is_the_temperature_today_in_celsius &lt;- -13",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#example-7-you-will-make-so-many-mistakes",
    "href": "activities/01_foundations_welcome.html#example-7-you-will-make-so-many-mistakes",
    "title": "Collecting and Summarizing Data",
    "section": "Example 7: You will make so many mistakes!",
    "text": "Example 7: You will make so many mistakes!\nMistakes are common when, and even important to, learning any new language. You’ll get better and better at interpreting error messages, finding help, and fixing errors. In addition to finding help online, R has built-in help files. For example:\n\nIn the console, type ?rep and press Return/Enter.\nCheck out the documentation file that pops up in the Help tab (lower right).\nQuickly scroll through, noting the type of information provided.\nPause at the “Examples” section at the bottom – perhaps the most useful section! Try out a couple of the provided examples in your console.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#example-8-make-a-cheat-sheet",
    "href": "activities/01_foundations_welcome.html#example-8-make-a-cheat-sheet",
    "title": "Collecting and Summarizing Data",
    "section": "Example 8: Make a “cheat sheet”",
    "text": "Example 8: Make a “cheat sheet”\nYou will continue to pick up new R code and ideas. You’re highly encouraged to start tracking this in a cheat sheet (eg: in a Google doc). The cheat sheet will be a handy reference for you, and the act of making it will help deepen your understanding and retention.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-complete-this-after-the-class",
    "href": "activities/01_foundations_welcome.html#exercise-complete-this-after-the-class",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise: Complete this after the class",
    "text": "Exercise: Complete this after the class\nComplete this exercise after class. First, try it on your own (or with your group), and then check your work against the solution provided at the end of this .qmd file.\nUse R code to do the following:\n\nImport & name data on different Himalayan peaks from the url below:\nhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-22/peaks.csv NOTE: A codebook, i.e. a description of the data, is here.\nUse a function to show which variables are recorded on each peak.\nHow many peaks are included in the dataset? Answer this using a function, not by counting up the rows yourself.\nShow the first 6 rows of the dataset. NOTE: This gives us a quick glimpse without having to print out the entire dataset!",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-1-use-r-as-a-calculator",
    "href": "activities/01_foundations_welcome.html#exercise-1-use-r-as-a-calculator",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 1: Use R as a calculator",
    "text": "Exercise 1: Use R as a calculator\n\n4 + 2\n## [1] 6\n4^2\n## [1] 16\n4*2\n## [1] 8\n#4(2) # We need to use * for multiplication",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-2-functions-and-arguments",
    "href": "activities/01_foundations_welcome.html#exercise-2-functions-and-arguments",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 2: Functions and arguments",
    "text": "Exercise 2: Functions and arguments\n\n# Calculate the square root of 9\nsqrt(9)\n## [1] 3\n\n# Calculate the number of characters in the word \"macalester\"\nnchar(\"macalester\")\n## [1] 10\n\n# Calculate the square root of the number of characters in the word \"snow\"\nsqrt(nchar(\"snow\"))\n## [1] 2\n\n\n# Repeat the number 2, 5 times\nrep(x = 2, times = 5)\n## [1] 2 2 2 2 2\n\n# Repeat the number 2, 5 times\nrep(times = 5, x = 2)\n## [1] 2 2 2 2 2\n\n# Repeat the number 2, 5 times\nrep(2, 5)\n## [1] 2 2 2 2 2\n\n# Repeat the number 5, 2 times\nrep(5, 2)\n## [1] 5 5",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-3-save-it-for-later",
    "href": "activities/01_foundations_welcome.html#exercise-3-save-it-for-later",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 3: Save it for later",
    "text": "Exercise 3: Save it for later\n\n# Nothing shows up -- all we're doing here is storing -13 as degrees_c\ndegrees_c &lt;- -13\n\n# Print the contents of degrees_c\ndegrees_c\n## [1] -13\n\n# We can \"do math\" with the contents of degrees_c\ndegrees_c * (9/5) + 32\n## [1] 8.6",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-4-import-data",
    "href": "activities/01_foundations_welcome.html#exercise-4-import-data",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 4: Import data",
    "text": "Exercise 4: Import data\n\n# Load the tidyverse package\nlibrary(tidyverse)\n\n# Import the data\nsurvey &lt;- read_csv(\"https://mac-stat.github.io/data/112_fall_2024_survey.csv\")",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-5-get-to-know-the-data",
    "href": "activities/01_foundations_welcome.html#exercise-5-get-to-know-the-data",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 5: Get to know the data",
    "text": "Exercise 5: Get to know the data\n\n# Dimensions of the survey data set\n# First number = number of rows\n# Second number = number of columns\ndim(survey)\n## [1] 98  4\n\n\n# Number of rows in the survey data set\nnrow(survey)\n## [1] 98\n\n\n# First 6 rows (the head) of the survey data set\nhead(survey)\n## # A tibble: 6 × 4\n##   cafe_mac     minutes_to_campus fave_temp hangout      \n##   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;        \n## 1 Cheesecake                  15        18 the mountains\n## 2 Cheese pizza                10        24 a beach      \n## 3 udon noodles                 4        18 the mountains\n## 4 egg rolls                    7        10 a beach      \n## 5 Tacos                        5        18 the mountains\n## 6 pasta                       35         7 the mountains\n\n\n# First 3 rows of the survey data set\nhead(survey, 3)\n## # A tibble: 3 × 4\n##   cafe_mac     minutes_to_campus fave_temp hangout      \n##   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;        \n## 1 Cheesecake                  15        18 the mountains\n## 2 Cheese pizza                10        24 a beach      \n## 3 udon noodles                 4        18 the mountains\n\n\n# Last 6 rows (the tail) of the survey data set\ntail(survey)\n## # A tibble: 6 × 4\n##   cafe_mac        minutes_to_campus fave_temp hangout \n##   &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   \n## 1 Burger                         10        21 a forest\n## 2 Pepperoni Pizza                10        24 a beach \n## 3 Hamburger                       6        23 a beach \n## 4 Ginger Cookies                 10        26 a beach \n## 5 bbq chicken                     5        14 a city  \n## 6 Breakfast food                 15        25 a city\n\n\n# Names of the variables in the survey data set\nnames(survey)\n## [1] \"cafe_mac\"          \"minutes_to_campus\" \"fave_temp\"        \n## [4] \"hangout\"\n\n\n# Structure of all variables in the survey data set\nstr(survey)\n## spc_tbl_ [98 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##  $ cafe_mac         : chr [1:98] \"Cheesecake\" \"Cheese pizza\" \"udon noodles\" \"egg rolls\" ...\n##  $ minutes_to_campus: num [1:98] 15 10 4 7 5 35 5 15 7 20 ...\n##  $ fave_temp        : num [1:98] 18 24 18 10 18 7 75 24 13 16 ...\n##  $ hangout          : chr [1:98] \"the mountains\" \"a beach\" \"the mountains\" \"a beach\" ...\n##  - attr(*, \"spec\")=\n##   .. cols(\n##   ..   cafe_mac = col_character(),\n##   ..   minutes_to_campus = col_double(),\n##   ..   fave_temp = col_double(),\n##   ..   hangout = col_character()\n##   .. )\n##  - attr(*, \"problems\")=&lt;externalptr&gt;",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-6-code-communication",
    "href": "activities/01_foundations_welcome.html#exercise-6-code-communication",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 6: Code = communication",
    "text": "Exercise 6: Code = communication\n\n# Make it less smooshy. Add spaces!\nseq(from = 1, to = 9, by = 2)\n## [1] 1 3 5 7 9\n\n# Use consistent spacing\nseq(from = 1, to = 9, by = 2)\n## [1] 1 3 5 7 9\n\n# Use more descriptive names when storing objects\nmy_output &lt;- -13\n\n# Use a shorter and easier to read name\ncelsius_today &lt;- -13\nCelsiusToday  &lt;- -13",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-7-you-will-make-so-many-mistakes",
    "href": "activities/01_foundations_welcome.html#exercise-7-you-will-make-so-many-mistakes",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 7: You will make so many mistakes!",
    "text": "Exercise 7: You will make so many mistakes!",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-8-your-turn",
    "href": "activities/01_foundations_welcome.html#exercise-8-your-turn",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 8: Your turn",
    "text": "Exercise 8: Your turn\n\n# a\npeaks &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-22/peaks.csv\")\n\n# b\nnames(peaks)\n## [1] \"peak_id\"                    \"peak_name\"                 \n## [3] \"peak_alternative_name\"      \"height_metres\"             \n## [5] \"climbing_status\"            \"first_ascent_year\"         \n## [7] \"first_ascent_country\"       \"first_ascent_expedition_id\"\n\n# c\ndim(peaks)\n## [1] 468   8\nnrow(peaks)\n## [1] 468\n\n# d\nhead(peaks)\n## # A tibble: 6 × 8\n##   peak_id peak_name     peak_alternative_name height_metres climbing_status\n##   &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;                         &lt;dbl&gt; &lt;chr&gt;          \n## 1 AMAD    Ama Dablam    Amai Dablang                   6814 Climbed        \n## 2 AMPG    Amphu Gyabjen &lt;NA&gt;                           5630 Climbed        \n## 3 ANN1    Annapurna I   &lt;NA&gt;                           8091 Climbed        \n## 4 ANN2    Annapurna II  &lt;NA&gt;                           7937 Climbed        \n## 5 ANN3    Annapurna III &lt;NA&gt;                           7555 Climbed        \n## 6 ANN4    Annapurna IV  &lt;NA&gt;                           7525 Climbed        \n## # ℹ 3 more variables: first_ascent_year &lt;dbl&gt;, first_ascent_country &lt;chr&gt;,\n## #   first_ascent_expedition_id &lt;chr&gt;",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html",
    "href": "activities/03_04-slr-intro-formalization.html",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you’ve settled in before class begins.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#learning-goals",
    "href": "activities/03_04-slr-intro-formalization.html#learning-goals",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nVisualize and describe the relationship between two quantitative variables using a scatterplot\nWrite R code to create a scatterplot and compute the linear correlation between two quantitative variables\nDescribe/identify weak / strong, and positive / negative correlation from a point cloud\nBuild intuition for fitting lines to quantify the relationship between two quantitative variables\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula for a simple linear regression model with a quantitative predictor\nWrite R code to fit a linear regression model\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute expected / predicted / fitted values and residuals from a linear regression model formula\nInterpret predicted values and residuals in the context of the data\nExplain the connection between residuals and the least squares criterion",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#readings-and-videos",
    "href": "activities/03_04-slr-intro-formalization.html#readings-and-videos",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through after class. CP Quiz due on Wednesday at 09:00 am on these topics\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nCreate a new code chunk to look at the first few rows of the data and learn how much data (in terms of cases and variables) we have.\n\nWhat does a case represent?\nHow many and what kinds of variables do we have?\nThinking about the who, what, when, where, why, and how of this data, which of the 5W’s + H seem most relevant to our investigations? Explain your thoughts.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nLet’s get acquainted with the riders_registered variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the pclot and numerical summaries.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#a-little-bit-of-live-note-taking",
    "href": "activities/03_04-slr-intro-formalization.html#a-little-bit-of-live-note-taking",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "A little-bit of Live Note Taking!",
    "text": "A little-bit of Live Note Taking!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#before-starting-the-exercise-lets-do-the-followings-first",
    "href": "activities/03_04-slr-intro-formalization.html#before-starting-the-exercise-lets-do-the-followings-first",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Before starting the Exercise, let’s do the followings first!",
    "text": "Before starting the Exercise, let’s do the followings first!\nMost of you should have figured out the followings by now, still let’s skim through the followings!\n\nFirst, save this activity in your device as STAT 155 -&gt; activities -&gt; copy-paste 03_04.qmd\nClick on Render button! What happens? ::: {.callout-tip title=“Answers”} The html has saved in the same location (folder) where you initially saved the .qmd file! You need to submit .html file like this for the PP! :::\nNow, click on the +C at the top right side of RStudio and then choose R. What happens?\n\n\n\n\n\n\n\nAnswers\n\n\n\nIt creates code chunks",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe’d like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nWhat type of plot would be appropriate to visualize this relationship? Sketch and describe what you expect this plot to look like.\nCreate an appropriate plot using ggplot(). How does the plot compare to what you predicted?\n\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point()\n\n\n\n\n\n\n\n\nType-in the followings in the.qmd file you have been working from the last class!\n\n\n\n\n\n\nComments\n\n\n\nTrend: Linear (?); Direction/Association: Positive/Negative, Strength: spread of the points (dispersed? close together? moderately close together?); Outlier?\n\n\n\nAdd the following two lines after your plot to add a linear (blue) and curved (red) smoothing line. What do you notice? Is a simple linear regression model appropriate for this data?\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nYOUR_PLOT +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\nWhat do you think “eval = TRUE/FALSE” doing here {r eval = TRUE/FALSE}?\n\n# Add a red straight line of best fit and a blue curve of best fit\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\n\n\n\n\n\n\n\nComments: If we only displayed the red line of best fit on the plot, we might miss the slight downward trend at the highest temperatures that we can see more clearly with the blue curve of best fit. A linear model is not appropriate if fit to the whole range of the data, but there does seem to be a linear relationship between ridership and temperature below 80 degrees Fahrenheit.\n\nCompute Correlation of temp_feel and riders_registered.\n\n\nCorrelation\nWe can quantify the linear relationship between two quantitative variables using a numerical summary known as correlation (sometimes known as a “correlation coefficient” or “Pearson’s correlation”). Correlation can range from -1 to 1, where a correlation of 0 indicates that there is no linear relationship between the two quantitative variables.\nBelow is an example of a “Math Box”. You’ll see these occasionally throughout the activities. You are not required to memorize, nor will you be assessed on, anything in the math boxes. If you plan on continuing with Statistics courses at Macalester (or are interested in the math behind everything!), these math boxes are for you!\n\n\n\n\n\n\nCorrelation\n\n\n\n\n\nThe Pearson correlation coefficient, \\(r_{x, y}\\), of \\(x\\) and \\(y\\) is the (almost) average of products of the z-scores of variables \\(x\\) and \\(y\\):\n\\[\nr_{x, y} = \\frac{\\sum z_x z_y}{n - 1}\n\\]\n\n\n\nIn general, we will want to be able to describe (qualitatively) two aspects of correlation:\n\nStrength\n\n\nIs the correlation between x and y strong, or weak, i.e. how closely do the points fit around a line? This has to do with how dispersed our point clouds are.\n\n\nDirection\n\n\nIs the correlation between x and y positive or negative, i.e. does y go “up” when x goes “up” (positive), or does y go “down” when x goes “up” (negative)?\n\nStronger correlations will be further from 0 (closer to -1 or 1), and positive and negative correlations will have the appropriate respective sign (above or below zero).\nWhiteboard Time (a little-bit!)\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\nbikes %&gt;%\n    summarize(cor(temp_feel, riders_registered))\n## # A tibble: 1 × 1\n##   `cor(temp_feel, riders_registered)`\n##                                 &lt;dbl&gt;\n## 1                               0.544",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#see-class-notes-slr-formalization",
    "href": "activities/03_04-slr-intro-formalization.html#see-class-notes-slr-formalization",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "See class-notes: SLR Formalization",
    "text": "See class-notes: SLR Formalization",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-4-filtering-our-data",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-4-filtering-our-data",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\nThe relationship between registered riders and temperature looks linear below 80 degrees. We can use the filter() function from the dplyr package to subset our cases. (We’ll learn techniques soon for handling this nonlinear relationship.)\nIf we wanted to only keep cases where registered ridership was greater than 2000, we would use the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nNEW_DATASET_NAME &lt;- bikes %&gt;% \n    filter(riders_registered &gt; 2000)\n\nAdapt the example above to create a new dataset called bikes_sub that only keeps cases where the felt temperature is less than 80 degrees.\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nbikes_sub &lt;- bikes %&gt;% \n    filter(temp_feel &lt; 80)\n\nDid it work? Check the dimensions of bikes and bikes_sub!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet’s fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes_sub)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3681.8  -928.3   -98.6   904.9  3496.7 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -2486.412    421.379  -5.901 7.37e-09 ***\n## temp_feel      86.493      6.464  13.380  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1267 on 428 degrees of freedom\n## Multiple R-squared:  0.2949, Adjusted R-squared:  0.2933 \n## F-statistic:   179 on 1 and 428 DF,  p-value: &lt; 2.2e-16\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -2486.41180 421.379174 -5.900652 7.368345e-09\n## temp_feel      86.49251   6.464247 13.380135 2.349753e-34\n\n\nUsing the model summary output, complete the following model formula:\nE[riders_registered | temp_feel] = ___ + ___ * temp_feel\nIntercept interpretation: On days that feel like 0 degrees Fahrenheit, we can expect an average of -2486.41180 riders—a negative number of riders doesn’t make sense! This results because of extrapolation—0 degrees is so far below the minimum temperature in the data. We only have information on the relationship between ridership and temperature in the ~40-100 degree range and have no idea what that relationship looks like outside that range.\nSlope interpretation: Every 1 degree increase in feeling temperature is associated with an average of about 86 more riders.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-6-predictions-and-residuals",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-6-predictions-and-residuals",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don’t worry about the syntax – we haven’t learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n## # A tibble: 1 × 2\n##   riders_registered temp_feel\n##               &lt;dbl&gt;     &lt;dbl&gt;\n## 1              5665      53.8\n\n\nPeak back at the scatterplot. More riders than expected – the point is far above the trend line.\n\n\nggplot(bikes_sub, aes(x = temp_feel, y = riders_registered)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) \n\n\n\n\n\n\n\n\n\nUse your model formula from the previous exercise to predict the ridership on August 17, 2012 from the temperature on that day. (That is, where do days with this temperature fall on the model trend line? How many registered riders would we expect on a 53.816 degree day?)\n\n\n\n\n\n\n\nAnswer\n\n\n\n-2486.41180 + 86.49251 * 53.816 = 2168.269\n\n\n\nCheck your part b calculation using the predict() function. Take careful note of the syntax – there’s a lot going on!\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n##        1 \n## 2168.269\n\n\nCalculate the residual or prediction error. How far does the observed ridership fall from the model prediction?\n\n\n\n\n\n\n\nAnswer\n\n\n\nresidual = observed y - predicted y = 5665 - 2168.269 = 3496.731\n\n\n\nAre positive residuals above or below the trend line? When we have positive residuals, does the model over- or under-estimate ridership? Repeat these questions for negative residuals.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\nPositive residuals are above the trend line—we under-estimate ridership.\nNegative residuals are below the trend line—we over-estimate ridership.\n\n\n\n\nFor an 85 degree day, how many registered riders would we expect? Do you think it’s a good idea to make this prediction? (Revisit the visualization and filtering we did in Exercises 3 and 4.) [Complete after the class!]",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-7-changing-temperature-units-challenge-complete-after-the-class",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-7-changing-temperature-units-challenge-complete-after-the-class",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 7: Changing temperature units (CHALLENGE) [Complete after the class!]",
    "text": "Exercise 7: Changing temperature units (CHALLENGE) [Complete after the class!]\nSuppose we had measured temperature in degrees Celsius rather than degrees Fahrenheit. How do you think our intercept and slope estimates, and their coefficient interpretations, would change?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#render-your-work-again-this-is-a-good-practice-to-render-often--to-see-which-part-of-the-paragraph-might-cause-non-rendering-if-applicable-complete-after-the-class",
    "href": "activities/03_04-slr-intro-formalization.html#render-your-work-again-this-is-a-good-practice-to-render-often--to-see-which-part-of-the-paragraph-might-cause-non-rendering-if-applicable-complete-after-the-class",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Render your work Again (this is a good practice to render often- to see which part of the paragraph might cause non-rendering, if applicable!) [Complete after the class!]",
    "text": "Render your work Again (this is a good practice to render often- to see which part of the paragraph might cause non-rendering, if applicable!) [Complete after the class!]\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-8-ridership-and-windspeed",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-8-ridership-and-windspeed",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet’s pull together everything that you’ve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\n\n\n# Get a short summary of this model\n\n\nSummarize your observations from the visualizations.\nWrite out a formula for the model trend.\nInterpret both the intercept and the windspeed coefficient. (Note: What does a negative slope indicate?)\nUse this model to predict the ridership on August 17, 2012 and calculate the corresponding residual. (Note: You’ll first need to find the windspeed on this date!)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-9-data-drills-filter-select-summarize-complete-after-class",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-9-data-drills-filter-select-summarize-complete-after-class",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 9: Data drills (filter, select, summarize) [Complete after class]",
    "text": "Exercise 9: Data drills (filter, select, summarize) [Complete after class]\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We’ll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nThus far, in the dplyr grammar you’ve seen 3 verbs or action words: summarize(), select(), filter(). Try out the following code and then summarize the point of the summarize() function:\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n## # A tibble: 1 × 2\n##   `mean(temp_feel)` `mean(humidity)`\n##               &lt;dbl&gt;            &lt;dbl&gt;\n## 1              52.0            0.544\n\n\n\nVerb 2: select\nTry out the following code and then summarize the point of the select() function:\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n## # A tibble: 10 × 2\n##    date       temp_feel\n##    &lt;date&gt;         &lt;dbl&gt;\n##  1 2011-01-01      64.7\n##  2 2011-01-02      63.8\n##  3 2011-01-03      49.0\n##  4 2011-01-04      51.1\n##  5 2011-01-05      52.6\n##  6 2011-01-06      53.0\n##  7 2011-01-07      50.8\n##  8 2011-01-08      46.6\n##  9 2011-01-09      42.5\n## 10 2011-01-10      45.6\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n## # A tibble: 10 × 3\n##    humidity riders_registered day_of_week\n##       &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806               654 Sat        \n##  2    0.696               670 Sun        \n##  3    0.437              1229 Mon        \n##  4    0.590              1454 Tue        \n##  5    0.437              1518 Wed        \n##  6    0.518              1518 Thu        \n##  7    0.499              1362 Fri        \n##  8    0.536               891 Sat        \n##  9    0.434               768 Sun        \n## 10    0.483              1280 Mon\n\n\n\nVerb 3: filter\nTry out the following code and then summarize the point of the filter() function:\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n## # A tibble: 7 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-03      49.0    0.437              1229 Mon        \n## 2 2011-01-04      51.1    0.590              1454 Tue        \n## 3 2011-01-05      52.6    0.437              1518 Wed        \n## 4 2011-01-06      53.0    0.518              1518 Thu        \n## 5 2011-01-07      50.8    0.499              1362 Fri        \n## 6 2011-01-08      46.6    0.536               891 Sat        \n## 7 2011-01-10      45.6    0.483              1280 Mon\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n## # A tibble: 2 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-01      64.7    0.806               654 Sat        \n## 2 2011-01-08      46.6    0.536               891 Sat\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")\n## # A tibble: 1 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-08      46.6    0.536               891 Sat",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-10-your-turn-complete-after-the-class",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-10-your-turn-complete-after-the-class",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 10: Your turn [Complete after the class!]",
    "text": "Exercise 10: Your turn [Complete after the class!]\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\n\n# Keep only information about the humidity and day of week using a different approach\n\n# Keep only information for Sundays\n\n# Keep only information for Sundays with temperatures below 50\n\n# Calculate the maximum and minimum temperatures",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nCreate a new code chunk by clicking the green “C” button with a green + sign in the top right of the menu bar. In this code chunk, use an appropriate function to look at the first few rows of the data.\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\nWhat does a case represent?\nNavigate to the FAQ page and read the response to the “How does this site work? Do you just download results from the federations?” question. What do you learn about data quality and completeness from this response?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-2-mutating-our-data",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-2-mutating-our-data",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (lifts data is \"fed into\" the mutate() function).\n# When creating a new variable, we often reassign the data frame to itself,\n# which updates the existing columns in lifts with the additional \"new\" column(s)\n# in lifts!\nlifts &lt;- lifts %&gt;% \n    mutate(NEW_VARIABLE_NAME = Age/BestSquatKg)\n## Error in `mutate()`:\n## ℹ In argument: `NEW_VARIABLE_NAME = Age/BestSquatKg`.\n## Caused by error:\n## ! object 'BestSquatKg' not found\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg.\n\nlifts &lt;- lifts %&gt;% \n    mutate(SWR = TotalKg / BodyweightKg)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet’s get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-4-data-visualization---two-quantitative-variables",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-4-data-visualization---two-quantitative-variables",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe’d like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a “point cloud”) allows us to do this! The code below creates a scatterplot of body weight vs. SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nThis is your second (!) bivariate data visualization (visualization for two variables)! What differences do you notice in the code structure when creating a bivariate visualization, compared to univariate visualizations we’ve worked with before?\nWhat similarities do you notice in the code structure?\nDoes there appear to be some sort of pattern in the structure of the point cloud? Describe it, in no more than three sentences! Comment on the direction of the relationship between the two variables (positive? negative?) and the spread of the points (are they dispersed? close together?).",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\nLook back at your answer to Exercise 4 (c). Does the smoothing line assist you in seeing a pattern, or change your answer at all? Why or why not?\nBased on the scatterplot with the smoothing line added above, does there appear to be a linear relationship between body weight and SWR (i.e. would a straight line do a decent job at summarizing the relationship between these two variables)? Why or why not?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-6-correlation",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-6-correlation",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\nWe can quantify the linear relationship between two quantitative variables using a numerical summary known as correlation (sometimes known as a “correlation coefficient” or “Pearson’s correlation”). Correlation can range from -1 to 1, where a correlation of 0 indicates that there is no linear relationship between the two quantitative variables.\nBelow is an example of a “Math Box”. You’ll see these occasionally throughout the activities. You are not required to memorize, nor will you be assessed on, anything in the math boxes. If you plan on continuing with Statistics courses at Macalester (or are interested in the math behind everything!), these math boxes are for you!\n\n\n\n\n\n\nCorrelation\n\n\n\n\n\nThe Pearson correlation coefficient, \\(r_{x, y}\\), of \\(x\\) and \\(y\\) is the (almost) average of products of the z-scores of variables \\(x\\) and \\(y\\):\n\\[\nr_{x, y} = \\frac{\\sum z_x z_y}{n - 1}\n\\]\n\n\n\nIn general, we will want to be able to describe (qualitatively) two aspects of correlation:\n\nStrength\n\n\nIs the correlation between x and y strong, or weak, i.e. how closely do the points fit around a line? This has to do with how dispersed our point clouds are.\n\n\nDirection\n\n\nIs the correlation between x and y positive or negative, i.e. does y go “up” when x goes “up” (positive), or does y go “down” when x goes “up” (negative)?\n\nStronger correlations will be further from 0 (closer to -1 or 1), and positive and negative correlations will have the appropriate respective sign (above or below zero).\n\nRather than a smooth trend line, we can force the line we add to our scatterplots to be linear using geom_smooth(method = 'lm'), as below:\n\n\n# scatterplot with linear trend line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\nBased on the above scatterplot, how would you describe the correlation between body weight and SWR, in terms of strength and direction?\nMake a guess as to what numerical value the correlation between body weight and SWR will have, based on your response to part (b).",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-7-computing-correlation-in-r",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-7-computing-correlation-in-r",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\nWe can compute the correlation between body weight and SWR using summarize and cor functions:\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n## # A tibble: 1 × 1\n##   `cor(SWR, BodyweightKg, use = \"complete.obs\")`\n##                                            &lt;dbl&gt;\n## 1                                        -0.0392\n\nIs the computed correlation close to what you guessed in Exercise 6 part (c)?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-8-limitations-of-correlation",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-8-limitations-of-correlation",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\nWe previously noted that correlation was a numerical summary of the linear relationship between two variables. We’ll now go through some examples of relationships between quantitative variables to demonstrate why it is incredibly important to visualize our data in addition to just computing numerical summaries!\nFor this exercise, we’ll be working with the anscombe dataset, which is built in to R. To load this dataset into our environment, we run the following code:\n\n# load anscombe data\ndata(\"anscombe\")\n\nThe anscombe dataset contains four different pairs of quantitative variables:\n\nx1, y1\nx2, y2\nx3, y3\nx4, y4\n\nAdapt the code we used in Exercise 7 to compute the correlation between each of these four pairs of variables, below:\n\n# correlation between x1, y1\n\n# correlation between x2, y2\n\n# correlation between x3, y3\n\n# correlation between x4, y4\n\n\nWhat do you notice about each of these correlations (if the answer to this isn’t obvious, double-check your code)?\nDescribe these correlations in terms of strength and direction, using only the numerical summary to assist you in your description.\nDraw an example on the white board or at your tables of what you think the point clouds for these pairs of variables might look like. There are only 11 observations, so you can draw all 11 points if you’d like!\nAdapt the code for scatterplots given previously in this activity to make four distinct scatterplots for each pair of quantitative variables in the anscombe dataset. You do not need to add a smooth trend line or a linear trend line to these plots.\n\n\n# scatterplot: x1, y1\n\n# scatterplot: x2, y2\n\n# scatterplot: x3, y3\n\n# scatterplot: x4, y4\n\n\nBased on the correlations you calculated and scatterplots you made, what is the message of this last exercise as it relates to the limits of correlation?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#reflection",
    "href": "activities/03_04-slr-intro-formalization.html#reflection",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Reflection",
    "text": "Reflection\nMuch of statistics is about making (hopefully) reasonable assumptions in attempt to summarize observed relationships in data. Today we started considering assumptions of linear relationships between quantitative variables.\nReview the learning objectives at the top of this file and today’s activity. How do you imagine assumptions of linearity might be useful in terms of quantifying relationships between quantitative variables? How do you imagine these assumptions could sometimes fall short, or even be unethical in certain cases?\n\nResponse: Put your response here.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-9-lines-of-best-fit",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-9-lines-of-best-fit",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 9: Lines of best fit",
    "text": "Exercise 9: Lines of best fit\nIn this activity, we’ve learned how to fit straight lines to data, to help us visualize the relationship between two quantitative variables. So far, ggplot has chosen the line for us. How does it know which line is “best”, and what does “best” even mean?\nFor this exercise, we’ll consider the relationship between x1 and y1 in the anscombe dataset. Run the following code, which creates a scatterplot with a fitted line to our data using the function geom_abline:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1)\n\n\n\n\n\n\n\n\nDescribe the line that you see. Do you think the line is “good”? What are you using to define “good”?\nSome things to think about:\n\nHow many points are above the line?\nHow many points are below the line?\nAre the distances of the points above and below the line roughly similar, or is there meaningful difference?\n\nNow we’ll add another line to our plot. Which line do you think is better suited for this data? Why? Be specific!\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1) +\n  geom_abline(slope = 0.5, intercept = 4, col = \"orange\", size = 1)\n\n\n\n\n\n\n\n\nIt’s usually quite simple to note when a line is bad, but more difficult to quantify when a line is a good fit for our data. Consider the following line:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = -0.5, intercept = 10, col = \"red\", size = 1) \n\n\n\n\n\n\n\n\nIn the next activity, we’ll formalize the principle of least squares, which will give us one particular definition of a line of best fit that is commonly used in statistics! We’ll take advantage of the vertical distances between each point and the fitted line (residuals), which will help us define (mathematically) a line that best fits our data:\n\nlibrary(broom)\nanscombe %&gt;%\n  lm(y1 ~ x1, data = .) %&gt;%\n  augment() %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_segment(aes(xend = x1, yend = .fitted), col = \"red\") +\n  geom_point()",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-10-correlation-and-extreme-values",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-10-correlation-and-extreme-values",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 10: Correlation and extreme values",
    "text": "Exercise 10: Correlation and extreme values\nIn this exercise, we’ll explore how correlation changes with the addition of extreme values, or observations. We’ll begin by generating a toy dataset called dat with two quantitative variables, x and y. Run the code below to create the dataset.\nwhile not required, recall that you can look up function documentation in R using the ? in front of a function name to figure out what that function is doing!\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\nMake a scatterplot of x vs. y.\n\n\n# scatterplot\n\n\nBased on your scatterplot, describe the correlation between x and y in terms of strength and direction.\nGuess the correlation (the numerical value) between x and y.\nCompute the correlation between x and y. Was your guess from part (c) close?\n\n\n# correlation\n\n\nSuppose we observe an additional observation with x = 15 and y = -45. We can create a new data frame, dat_new1, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nSuppose instead of our additional observation having values x = 15 and y = -45, we instead observe x = 15 and y = -15. We can create a new data frame, dat_new2, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nWhat do you think the takeaway message is of this exercise?\n\n\nChallenge Add linear trend lines to your scatterplots from parts (f) and (h). Does this give you any additional insight into why the correlations may have changed in different ways with the addition of a new observation?",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-2",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-2",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\ndim(bikes)\n## [1] 731  15\n\nhead(bikes)\n## # A tibble: 6 × 15\n##   date       season  year month day_of_week weekend holiday temp_actual\n##   &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;lgl&gt;   &lt;chr&gt;         &lt;dbl&gt;\n## 1 2011-01-01 winter  2011 Jan   Sat         TRUE    no             57.4\n## 2 2011-01-02 winter  2011 Jan   Sun         TRUE    no             58.8\n## 3 2011-01-03 winter  2011 Jan   Mon         FALSE   no             46.5\n## 4 2011-01-04 winter  2011 Jan   Tue         FALSE   no             46.8\n## 5 2011-01-05 winter  2011 Jan   Wed         FALSE   no             48.7\n## 6 2011-01-06 winter  2011 Jan   Thu         FALSE   no             47.1\n## # ℹ 7 more variables: temp_feel &lt;dbl&gt;, humidity &lt;dbl&gt;, windspeed &lt;dbl&gt;,\n## #   weather_cat &lt;chr&gt;, riders_casual &lt;dbl&gt;, riders_registered &lt;dbl&gt;,\n## #   riders_total &lt;dbl&gt;\n\n\nA case represents a day of the year.\nWe have 15 variables broadly concerning weather, day of week information, whether the day is a holiday.\nLots of answers are reasonable here! When and where seem to be particularly relevant because this is for a rideshare based in Washington DC with data from 2011-2012. Ridership likely changes a lot from city to city and over time.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nThe distribution of the riders_registered variable looks fairly symmetric. On average there are about 3600 registered riders per day (mean = 3656, median = 3662). On any given day, the number of registered riders is about 1560 from the mean. There seem to be a small number of low outliers (minimum ridership was 20).\n\nggplot(bikes, aes(x = riders_registered)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\nggplot(bikes, aes(y = riders_registered)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\nsummary(bikes$riders_registered)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##      20    2497    3662    3656    4776    6946\n\nbikes %&gt;% \n    summarize(sd(riders_registered))\n## # A tibble: 1 × 1\n##   `sd(riders_registered)`\n##                     &lt;dbl&gt;\n## 1                   1560.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe’d like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nScatterplot (outcome and predictor are both quantitative)\n\n\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nIf we only displayed the red line of best fit on the plot, we might miss the slight downward trend at the highest temperatures that we can see more clearly with the blue curve of best fit. A linear model is not appropriate if fit to the whole range of the data, but there does seem to be a linear relationship between ridership and temperature below 80 degrees Fahrenheit.\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-4-filtering-our-data-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-4-filtering-our-data-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nbikes_sub &lt;- bikes %&gt;% \n    filter(temp_feel &lt; 80)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet’s fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes_sub)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3681.8  -928.3   -98.6   904.9  3496.7 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -2486.412    421.379  -5.901 7.37e-09 ***\n## temp_feel      86.493      6.464  13.380  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1267 on 428 degrees of freedom\n## Multiple R-squared:  0.2949, Adjusted R-squared:  0.2933 \n## F-statistic:   179 on 1 and 428 DF,  p-value: &lt; 2.2e-16\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -2486.41180 421.379174 -5.900652 7.368345e-09\n## temp_feel      86.49251   6.464247 13.380135 2.349753e-34\n\n\nE[riders_registered | temp_feel] = -2486.41180 + 86.49251 * temp_feel\nIntercept interpretation: On days that feel like 0 degrees Fahrenheit, we can expect an average of -2486.41180 riders—a negative number of riders doesn’t make sense! This results because of extrapolation—0 degrees is so far below the minimum temperature in the data. We only have information on the relationship between ridership and temperature in the ~40-100 degree range and have no idea what that relationship looks like outside that range.\nSlope interpretation: Every 1 degree increase in feeling temperature is associated with an average of about 86 more riders.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-6-predictions-and-residuals-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-6-predictions-and-residuals-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don’t worry about the syntax – we haven’t learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n## # A tibble: 1 × 2\n##   riders_registered temp_feel\n##               &lt;dbl&gt;     &lt;dbl&gt;\n## 1              5665      53.8\n\n\nMore riders than expected – the point is far above the trend line\n-2486.41180 + 86.49251 * 53.816 = 2168.269\nWe get the same result with predict():\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n##        1 \n## 2168.269\n\n\nresidual = 5665 - 2168.269 = 3496.731. On August 17, 2012, there were 3496.731 more riders than would be expected from our model.\n\nPositive residuals are above the trend line—we under-estimate ridership.\nNegative residuals are below the trend line—we over-estimate ridership.\n\nOn an 85 degree day, we would predict 4865.452 riders. Even though we can compute this prediction, it’s not a good idea because of extrapolation–the data that we used to fit our model was filtered to days less than 80 degrees.\n\n\n-2486.41180 + 86.49251 * 85\n## [1] 4865.452\npredict(bike_mod, newdata = data.frame(temp_feel = 85))\n##        1 \n## 4865.451",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-7-changing-temperature-units-challenge",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-7-changing-temperature-units-challenge",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 7: Changing temperature units (CHALLENGE)",
    "text": "Exercise 7: Changing temperature units (CHALLENGE)\nIf we had measured temperature in degrees Celsius rather than degrees Fahrenheit, both the intercept and slope should change. The intercept would now represent 0 degrees Celsius (32 degrees Fahrenheit) and a one unit change in temperature is now 1 degree Celsius (1.8 degrees Fahrenheit).",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-8-ridership-and-windspeed-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-8-ridership-and-windspeed-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet’s pull together everything that you’ve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\nggplot(bikes, aes(x = windspeed, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\n\n\n\n\n\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\nbike_mod2 &lt;- lm(riders_registered ~ windspeed, data = bikes)\n\n# Get a short summary of this model\ncoef(summary(bike_mod2))\n##               Estimate Std. Error   t value      Pr(&gt;|t|)\n## (Intercept) 4490.09761  149.65992 30.002005 2.023179e-129\n## windspeed    -65.34145   10.86299 -6.015053  2.844453e-09\n\n\nThere’s a weak, negative relationship – ridership tends to be smaller on windier days.\nE[riders_registered | windspeed] = 4490.09761 - 65.34145 windspeed\n\nIntercept: On days with no wind, we’d expect around 4490 riders. (0 is a little below the minimum of the observed data, but not by much! So extrapolation in interpreting the intercept isn’t a huge concern.)\nSlope: Every 1mph increase in windspeed is associated with a ridership decrease of 65 riders on average.\n\nSee the code below to predict ridership on August 17, 2012 and calculate the corresponding residual. Note that this residual is smaller than the residual from the temperature model (that residual was 3496.731). This indicates that August 17 was more of an outlier in ridership given the temperature than the windspeed.\n\n\nbikes %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, windspeed)\n## # A tibble: 1 × 2\n##   riders_registered windspeed\n##               &lt;dbl&gt;     &lt;dbl&gt;\n## 1              5665      15.5\n\n# prediction\n4490.09761 - 65.34145 * 15.50072\n## [1] 3477.258\n\n# residual \n5665 - 3477.258\n## [1] 2187.742",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-9-data-drills-filter-select-summarize",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-9-data-drills-filter-select-summarize",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 9: Data drills (filter, select, summarize)",
    "text": "Exercise 9: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We’ll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nsummarize() calculates numerical summaries of variables (columns).\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n## # A tibble: 1 × 2\n##   `mean(temp_feel)` `mean(humidity)`\n##               &lt;dbl&gt;            &lt;dbl&gt;\n## 1              52.0            0.544\n\n\n\nVerb 2: select\nselect() selects variables (columns).\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n## # A tibble: 10 × 2\n##    date       temp_feel\n##    &lt;date&gt;         &lt;dbl&gt;\n##  1 2011-01-01      64.7\n##  2 2011-01-02      63.8\n##  3 2011-01-03      49.0\n##  4 2011-01-04      51.1\n##  5 2011-01-05      52.6\n##  6 2011-01-06      53.0\n##  7 2011-01-07      50.8\n##  8 2011-01-08      46.6\n##  9 2011-01-09      42.5\n## 10 2011-01-10      45.6\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n## # A tibble: 10 × 3\n##    humidity riders_registered day_of_week\n##       &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806               654 Sat        \n##  2    0.696               670 Sun        \n##  3    0.437              1229 Mon        \n##  4    0.590              1454 Tue        \n##  5    0.437              1518 Wed        \n##  6    0.518              1518 Thu        \n##  7    0.499              1362 Fri        \n##  8    0.536               891 Sat        \n##  9    0.434               768 Sun        \n## 10    0.483              1280 Mon\n\n\n\nVerb 3: filter\nfilter() keeps only days (rows) that meet the given condition(s).\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n## # A tibble: 7 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-03      49.0    0.437              1229 Mon        \n## 2 2011-01-04      51.1    0.590              1454 Tue        \n## 3 2011-01-05      52.6    0.437              1518 Wed        \n## 4 2011-01-06      53.0    0.518              1518 Thu        \n## 5 2011-01-07      50.8    0.499              1362 Fri        \n## 6 2011-01-08      46.6    0.536               891 Sat        \n## 7 2011-01-10      45.6    0.483              1280 Mon\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n## # A tibble: 2 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-01      64.7    0.806               654 Sat        \n## 2 2011-01-08      46.6    0.536               891 Sat\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")\n## # A tibble: 1 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-08      46.6    0.536               891 Sat",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-10-your-turn",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-10-your-turn",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 10: Your turn",
    "text": "Exercise 10: Your turn\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\nnew_bikes %&gt;% \n    select(humidity, day_of_week)\n## # A tibble: 10 × 2\n##    humidity day_of_week\n##       &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806 Sat        \n##  2    0.696 Sun        \n##  3    0.437 Mon        \n##  4    0.590 Tue        \n##  5    0.437 Wed        \n##  6    0.518 Thu        \n##  7    0.499 Fri        \n##  8    0.536 Sat        \n##  9    0.434 Sun        \n## 10    0.483 Mon\n\n# Keep only information about the humidity and day of week using a different approach\nnew_bikes %&gt;% \n    select(-date, -temp_feel, -riders_registered)\n## # A tibble: 10 × 2\n##    humidity day_of_week\n##       &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806 Sat        \n##  2    0.696 Sun        \n##  3    0.437 Mon        \n##  4    0.590 Tue        \n##  5    0.437 Wed        \n##  6    0.518 Thu        \n##  7    0.499 Fri        \n##  8    0.536 Sat        \n##  9    0.434 Sun        \n## 10    0.483 Mon\n\n# Keep only information for Sundays\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sun\")\n## # A tibble: 2 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-02      63.8    0.696               670 Sun        \n## 2 2011-01-09      42.5    0.434               768 Sun\n\n# Keep only information for Sundays with temperatures below 50\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sun\", temp_feel &lt; 50)\n## # A tibble: 1 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-09      42.5    0.434               768 Sun\n\n# Calculate the maximum and minimum temperatures\nnew_bikes %&gt;% \n    summarize(min(temp_feel), max(temp_feel))\n## # A tibble: 1 × 2\n##   `min(temp_feel)` `max(temp_feel)`\n##              &lt;dbl&gt;            &lt;dbl&gt;\n## 1             42.5             64.7",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-3",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-1-get-to-know-the-data-3",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nUse an appropriate function to look at the first few rows of the data.\n\n\nhead(lifts)\n## # A tibble: 6 × 21\n##   Name        Sex   Event Equipment   Age BodyweightKg Best3SquatKg Best3BenchKg\n##   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n## 1 Natalya Po… F     D     Raw        37           58.4          NA          NA  \n## 2 Fatima Rod… F     SBD   Single-p…  NA           74.8          NA          NA  \n## 3 Josh Kelley M     SBD   Single-p…  NA           72.4         147.         97.5\n## 4 Timothy Ca… M     D     Raw        16           72.9          NA          NA  \n## 5 M Moynihan  M     B     Raw        NA           67.5          NA         100  \n## 6 Lucas Wegr… M     B     Raw        23.5        103.           NA         188. \n## # ℹ 13 more variables: Best3DeadliftKg &lt;dbl&gt;, TotalKg &lt;dbl&gt;, Place &lt;chr&gt;,\n## #   Dots &lt;dbl&gt;, Wilks &lt;dbl&gt;, Glossbrenner &lt;dbl&gt;, Goodlift &lt;dbl&gt;, Tested &lt;chr&gt;,\n## #   Country &lt;chr&gt;, State &lt;chr&gt;, Date &lt;date&gt;, MeetCountry &lt;chr&gt;, MeetState &lt;chr&gt;\n\n\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\n\n\ndim(lifts)\n## [1] 100000     21\n\n\nA case represents an individual lifter at a single weightlifting competition.\nIt looks like some meets may be missing if they weren’t detected by the web scraper used by the maintainers of the Open Powerlifting database. They don’t describe in detail the process used for transferring PDFs of results to their database, so it’s unclear what errors in transcription might have resulted. Still, it’s worth taking a moment to appreciate the labor they put into making these results available for passionate powerlifters to explore.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-2-mutating-our-data-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-2-mutating-our-data-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\nlifts &lt;- lifts %&gt;% \n    mutate(SWR = TotalKg / BodyweightKg)\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-3-get-to-know-the-outcomeresponse-variable-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-3-get-to-know-the-outcomeresponse-variable-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet’s get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\n\n\nlifts %&gt;%\n  ggplot(aes(SWR)) +\n  geom_histogram(bins = 10, col = \"black\")\n\n\n\n\n\n\n\n\nlifts %&gt;% summarize(mean(SWR, na.rm = TRUE), min(SWR, na.rm = TRUE), max(SWR, na.rm = TRUE), sd(SWR, na.rm = TRUE))\n## # A tibble: 1 × 4\n##   `mean(SWR, na.rm = TRUE)` `min(SWR, na.rm = TRUE)` `max(SWR, na.rm = TRUE)`\n##                       &lt;dbl&gt;                    &lt;dbl&gt;                    &lt;dbl&gt;\n## 1                      4.42                    0.183                     12.5\n## # ℹ 1 more variable: `sd(SWR, na.rm = TRUE)` &lt;dbl&gt;\n\n\nWrite a good paragraph interpreting the plot and numerical summaries.\n\nStrength-to-weight (SWR) ratio ranges from 0.18 to 12.46, with a mean SWR of 4.4. SWR varies about 2.08 units above and below the mean. We observe that most SWRs appear to be centered between 4 and 7, with a slight right-skew to the data. The distribution of SWRs appears to be unimodal.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-4-data-visualization---two-quantitative-variables-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-4-data-visualization---two-quantitative-variables-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe’d like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a “point cloud”) allows us to do this! The code below creates a scatterplot of body weight vs. SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\na & b. In our plot aesthetics, we now have two variables listed (an “x” and a “y”) as opposed to just a single variable. The “geom” for a scatterplot is geom_point. Otherwise, the code structure remains very similar!\n\nIn general, it seems as though higher body weights are associated with lower SWRs. Once body weight (in kg) is greater than 50, the relationship between body weight and SWR appears to be weakly negative, and roughly linear. The points are very dispersed, indicating that there is a good amount of variation in this relationship (hence the term “weak”).",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-5-scatterplots---patterns-in-point-clouds-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-5-scatterplots---patterns-in-point-clouds-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\nThis doesn’t change my answer much (but it may have changed yours, and that’s okay!). It does appear as though there is a weakly negative relationship between body weight and SWR, particularly once body weight is above a certain value.\nI would say that yes, a linear relationship here seems reasonable! Even though there is some curvature in the smoothed trend line early on, that is based on very few data points. Those data points with low body weights aren’t enough to convince me that the relationship couldn’t be roughly linear between body weight and SWR.",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-6-correlation-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-6-correlation-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\n\nI would describe the correlation between body weight and SWR as weak and negative.\nI’ll guess -0.1, since the line is negative, and the points are very dispersed around the line!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-7-computing-correlation-in-r-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-7-computing-correlation-in-r-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n## # A tibble: 1 × 1\n##   `cor(SWR, BodyweightKg, use = \"complete.obs\")`\n##                                            &lt;dbl&gt;\n## 1                                        -0.0392\n\nSo close to our guess!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-8-limitations-of-correlation-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-8-limitations-of-correlation-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\n\n# correlation between x1, y1\nanscombe %&gt;% summarize(cor(x1, y1))\n##   cor(x1, y1)\n## 1   0.8164205\n\n# correlation between x2, y2\nanscombe %&gt;% summarize(cor(x2, y2))\n##   cor(x2, y2)\n## 1   0.8162365\n\n# correlation between x3, y3\nanscombe %&gt;% summarize(cor(x3, y3))\n##   cor(x3, y3)\n## 1   0.8162867\n\n# correlation between x4, y4\nanscombe %&gt;% summarize(cor(x4, y4))\n##   cor(x4, y4)\n## 1   0.8165214\n\n\nEach of these correlations are nearly the same!\nEach of these correlations is relatively strong, and positive, since 0.8 is positive and closer to 1 than 0.\n\n\n\n# scatterplot: x1, y1\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# scatterplot: x2, y2\nanscombe %&gt;%\n  ggplot(aes(x = x2, y = y2)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# scatterplot: x3, y3\nanscombe %&gt;%\n  ggplot(aes(x = x3, y = y3)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# scatterplot: x4, y4\nanscombe %&gt;%\n  ggplot(aes(x = x4, y = y4)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe message of this exercise is that data visualization is important in addition to numerical summaries! Many different sets of points can have nearly the same correlation, but display very different patterns in point clouds upon closer inspection. Reporting correlation alone is not enough to summarize the relationship between two quantitative variables, and should be accompanied by a scatter plot!",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "activities/03_04-slr-intro-formalization.html#exercise-10-correlation-and-extreme-values-1",
    "href": "activities/03_04-slr-intro-formalization.html#exercise-10-correlation-and-extreme-values-1",
    "title": "Simple Linear Regression - Intro+Formalization",
    "section": "Exercise 10: Correlation and extreme values",
    "text": "Exercise 10: Correlation and extreme values\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\n\n\n\n# scatterplot\ndat %&gt;% \n  ggplot(aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe correlation between x and y is moderately strong and negative.\nI’ll guess -0.6, since the relationship is negative and is sort of in-between weak and strong.\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x, y))\n##    cor(x, y)\n## 1 -0.8295483\n\n\n\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\n\n\n\n# scatterplot\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x1, y1))\n##   cor(x1, y1)\n## 1  -0.8573567\n\nOur correlation stayed roughly the same with the addition of this new point!\n\n\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\n\n\n\n# scatterplot\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# correlation\ndat_new2 %&gt;% summarize(cor(x2, y2))\n##   cor(x2, y2)\n## 1  -0.2924792\n\nThe correlation changes quite a bit with the addition of this new point! Something to note is that this new point does not follow the rough linear trend that the original points had, that the first point we considered adding also had. This line seems way off base, comparatively!\n\nThe takeaway message here is that even though both of these additional points might be considered “outliers” because they have extreme x values, one changes the relationship between x and y much more than the other. In this case, the second point we considered would be influential because it changes the observed relationship between all x’s and y’s much more than the first point we considered. Not all “outliers” are considered equal!\n\n\n\n\n\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)",
    "crumbs": [
      "Simple Linear Regression - Intro+Formalization"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Practice Problems",
    "section": "",
    "text": "Please review the Practice Problems Policies document before proceeding!\n…due Fridays at 11:59 pm Central on Moodle!\n\nPractice Problems 1, due 9/12\nPractice Problems 1, due 9/20"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Coming Soon…"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "",
    "text": "Section 03: M/W/F 09:40-10:40am, THTR 002\nSection 04: M/W/F 12:00-01:00pm, THTR 202\nWelcome to STAT 155! Whether in life or research, we’re often interested in relationships between 2+ variables. For example, how is one’s commute time to class related to their distance from campus and mode of transportation? Or, how is voter participation related to a person’s age and political affiliation? Statistical modeling is the art and science of turning data into information about such relationships of interest.\nBeing able to summarize, interpret, and communicate about data are crucial for navigating today’s information landscape, and these are precisely the skills that we’ll build in this class. Throughout the semester, we’ll study the fundamental methods that statisticians use to extract knowledge from data, emphasizing statistical literacy & intuition, real data applications, and modern computing over memorizing facts and formulas."
  },
  {
    "objectID": "syllabus.html#important-technical-concepts",
    "href": "syllabus.html#important-technical-concepts",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Important technical concepts",
    "text": "Important technical concepts\nUpon completion of this course, students should be able to:\n\nBuild, use, and interpret graphical and numerical summaries of data.\nGiven a research question: identify an appropriate model, use sample data to fit the model in RStudio (free!), evaluate the model’s quality, and quantify our uncertainty in the model’s coefficients and predictions.\nUse a sample model to make predictions & inferences about a population, using prediction/confidence intervals & hypothesis tests.\nInterpret & communicate an analysis in context & using appropriate notation, argumentation, & evidence.\nDescribe potential advantages, limitations, and ethical considerations of a data set and statistical analysis.\nIdentify common pitfalls in statistical analyses (e.g., spurious correlation vs. causal relationships, extrapolation, multicollinearity, multiple testing, practical vs. statistical significance).\nAccurately describe methods and results in a way that is scientifically sound and widely accessible.\nWork productively and effectively in a group setting."
  },
  {
    "objectID": "syllabus.html#important-statistical-skills",
    "href": "syllabus.html#important-statistical-skills",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Important statistical skills",
    "text": "Important statistical skills\nThe following skills are essential both within and beyond Statistics, and demonstrably improve your own learning and the learning of those around you:\n\nMove beyond a “homework only” study approach. Develop a deeper understanding of the material through continued review, reflection, and practice.\nThink creatively, and build confidence, applying course concepts in open-ended, novel settings.\nBe comfortable working through challenges and mistakes.\nContribute to a welcoming and engaged learning environment.\nWork effectively in a group setting."
  },
  {
    "objectID": "syllabus.html#about-your-professor",
    "href": "syllabus.html#about-your-professor",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "About your professor",
    "text": "About your professor\n\nMd Mutasim Billah, PhD\nPronunciation: listen here\nOffice: Olin-Rice 234\nEmail: mbillah@macalester.edu\n\n\n\n\n\n\nNotes from “your professor”\n\n\n\nGreetings! You can call me Mutasim, Bill or Professor Billah & I use he/him pronouns. Back when I was an undergrad student, I didn’t have the best experience in Intro Stat—those courses often emphasized formulas over real understanding. That experience has shaped my teaching—I concentrate on illustrating how statistical theories connect and can be applied in the real world. I’m excited to teach STAT 155 and to create a more meaningful experience—one that helps all students feel confident applying it beyond the classroom. My methodological research lies at the intersection of statistical genetics, biostatistics, and genomics. My current research interests include developing novel statistical methods and computationally efficient bioinformatics tools, leveraging modern machine- and deep-learning approaches analyze high-dimensional next-generation sequencing and multi-omics data to identify genes and regulatory mechanisms underlying complex diseases. Outside of my academic work, I enjoy spending time outdoors with family and friends or cooking variety of foods. If you can’t find me anywhere, I might be busy playing soccer or exploring new worlds on my PS5 Pro!\n\n\nDrop-in (office) hours:\n\nLocation: My office (OLRI 234)\nTimes: M/W: 01:30-02:30 pm.\nBy Appointment: I’m also happy to meet one-on-one if my normal drop-in hours don’t work for you. Shoot me an email and we can arrange it either in-person or over zoom, password: 123456.\nEmail Response Time: I do my best to reply to emails promptly during weekdays. Please note that messages sent after 4:00 pm or on weekends may take longer to receive a response."
  },
  {
    "objectID": "syllabus.html#about-your-preceptors",
    "href": "syllabus.html#about-your-preceptors",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "About your preceptors",
    "text": "About your preceptors\nWe have several wonderful STAT 155 preceptors this semester! Their role is to help students with content questions, assist in the navigation of available resources, advise on studying approaches, and assist with concepts, tools, and skills. Students are accountable for their own learning; as such, preceptors are not allowed to share answers to assignments (unless specifically directed by the instructor), they are not expected to immediately know the right approach to an exercise, and they do not provide assistance outside of office hours.\nIn hiring preceptors, we prioritize and emphasize kindness and respect. I expect the same of students in their interactions with the preceptors. Please utilize and respect their experience and commitment to supporting you in this course. Please check out some additional guidelines and expectations on how to interact with preceptors."
  },
  {
    "objectID": "syllabus.html#textbook-online-course-manual",
    "href": "syllabus.html#textbook-online-course-manual",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Textbook & Online Course Manual",
    "text": "Textbook & Online Course Manual\nThere is no required textbook for this course. Throughout the course, readings may be assigned from these notes, or other sources.\nThe online course manual includes all in-class activities (with solutions) and a daily Schedule. All links and materials needed will be provided on the schedule tab of this website."
  },
  {
    "objectID": "syllabus.html#moodle",
    "href": "syllabus.html#moodle",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Moodle",
    "text": "Moodle\nMoodle includes general resources, a broad course calendar, submission links, feedback, and a forum for student questions."
  },
  {
    "objectID": "syllabus.html#statistical-software",
    "href": "syllabus.html#statistical-software",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Statistical software",
    "text": "Statistical software\nWe will use the (completely free and open source) R programming language extensively throughout this course. RStudio (an interface for R) will facilitate our use of R. You may use RStudio in one of two ways:\n\nDesktop version: Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nOnline: Go to https://rstudio.macalester.edu, and log in with your full Mac email address and your usual Mac password to get access. (Note that this is a shared resource across MSCS, and you may experience performance issues due to high traffic, server outages, etc.)\n\nMore detailed instructions on downloading, installing, and getting started with R, and RStudio are available on the R Resources tab."
  },
  {
    "objectID": "syllabus.html#office-hours-oh-and-r-support",
    "href": "syllabus.html#office-hours-oh-and-r-support",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Office hours (OH) and R Support",
    "text": "Office hours (OH) and R Support\nOH: Across the instructor and preceptors, there are several office hours each week. Names, times, and locations are on the Moodle course calendar. IMPORTANT: Always check the calendar before attending OH.\nData & R Support: In addition to the course preceptors, there is support on campus for working with data and R / RStudio. This is a great resource for R setup and troubleshooting throughout the semester. See https://www.macalester.edu/mscs/data-support for more information."
  },
  {
    "objectID": "syllabus.html#asking-questionscommunicating",
    "href": "syllabus.html#asking-questionscommunicating",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Asking questions/communicating",
    "text": "Asking questions/communicating\n\nOffice Hours\nOH are a great place to chat about the course, career planning, life,… Please visit us!!\n\nOH times & locations are on the Moodle course calendar.\nOH are oriented around group discussion. They are not first come, first served appointments.\nSince it’s not an effective way to deepen your learning, OH are not a place to sit and do assignments with me or preceptors. It’s an opportunity to discuss concepts & specific questions.\n\n\n\nMoodle Forum: STAT 155 Discussion Board\nThis forum is where we’ll communicate outside class. Students can post and answer comments / questions there. This is an informal way to converse, ask questions, share info, & connect. Do not rely on receiving responses outside weekdays between 9am & 5pm."
  },
  {
    "objectID": "syllabus.html#what-to-do-when-you-have-a-question-for-me",
    "href": "syllabus.html#what-to-do-when-you-have-a-question-for-me",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "What to do when you have a question for me?",
    "text": "What to do when you have a question for me?\n\nIf it’s non-private (e.g. about policies, homework (Practice Problems), class activities, etc), you must post it on STAT 155 Discussion Board in Moodle. Remember- collaboration is the KEY!\nIf it’s personal (e.g. about an absence), email me.\nIt’s good, professional practice to check whether your question is already answered in the provided resources. For example:\n\nInfo (what to do if you miss class): syllabus\nDue dates: course calendar at the top of Moodle + course schedule in the online manual\nQuiz dates: syllabus + course calendar at the top of Moodle + course schedule in the online manual\nHomework policies & grading: homework policies & grading doc\nFinals week: syllabus + course calendar at the top of Moodle + course schedule in the online manual"
  },
  {
    "objectID": "syllabus.html#thriving-in-stat-155",
    "href": "syllabus.html#thriving-in-stat-155",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Thriving in STAT 155",
    "text": "Thriving in STAT 155\n\n\n\n\n\n\n🗓️ Plan Ahead\n\n\n\nYou should plan to spend ~10-12 hours on any 4-credit course, including class time.1 Stay up-to-date on the course calendar and carve out time for studying & doing homework.\n\n\n\n\n\n\n\n\n✅ Do the Things\n\n\n\nAt minimum, thriving in this course requires the completion of some concrete tasks. Complete all assignments, regularly attend & engage in class, complete in-class activities (which might mean completing work outside of class), and check the activity solutions.\n\n\n\n\n\n\n\n\n🏗️ Build a Foundation\n\n\n\nIf your main focus is on checking off some boxes, you won’t get much out of this course (or college in general). Deeper, enduring learning requires more. Carve out time to rewrite, reflect upon, & review your notes. Summarize concepts in your own words.\n\n\n\n\n\n\n\n\n🎉 Engage, Ask Questions, Have Fun\n\n\n\nActively participate in the class & take ownership of your learning. PLEASE: Don’t be afraid to ask for help, make mistakes, and ask questions! These skills are critical to your well-being & learning. Finally, have some fun, be curious, and reflect upon what surprises you about the material and yourself"
  },
  {
    "objectID": "syllabus.html#flexibility",
    "href": "syllabus.html#flexibility",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Flexibility",
    "text": "Flexibility\nI provide transparent accommodations to all students. It helps reduce stress and the “hidden curriculum” (not everybody feels comfortable asking for flexibility).\n\nMissed Class: It’s okay to miss class in the case of an emergency. Please see the ‘Absences’ tab below for details.\nPractice Problems (PP): Limited extensions and limited mistakes without penalty. Please carefully go through all the sections from STAT 155 PP Policies & Grading doc.\nCheckpoints: Some class periods will have course videos and readings assigned ahead of time. For each class period where this is the case, a checkpoint quiz (on Moodle) must be completed by 09:00 am. Checkpoints may be attempted as many times as you’d like, but to earn completion credit for a given checkpoint you must score 100% by your final attempt. These short quizzes are designed to ensure that you stay on top of course material, since much of the content in this course builds on itself.\nQuizzes: Limited revisions. Additional flexibility will be provided in rare extenuating circumstances, upon discussion. Exceptions must be discussed with me (not assumed) early on (not after the fact).\n\n\n\n\n\n\n\n🤝 PLEASE REACH OUT WHEN YOU NEED HELP."
  },
  {
    "objectID": "syllabus.html#absences",
    "href": "syllabus.html#absences",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Absences",
    "text": "Absences\nIt’s okay to miss the occasional class. Except in rare extenuating circumstances (which must be discussed in advance): - 3 or fewer absences will not impact your grade - 4-6 absences will impact your grade (see Calculating Final Grades section) - you cannot pass the course if you accrue 7+ absences (more than 25% of class sessions)\n\n\n\n\n\n\nWhat to Do If You Miss Class\n\n\n\n\n📧 Send me a quick email. You do not need to share a reason for your absence, especially if it’s personal. It’s just a simple courtesy & keeps communication lines open.\n📅 Check the Course Schedule in the online manual for what is happening in class that day.\n📝 Complete the in-class activity on your own & check the solutions posted in the online manual.\n💬 Ask any follow-up questions on the Moodle forum or in office hours (OH)."
  },
  {
    "objectID": "syllabus.html#artificial-intelligence-ai",
    "href": "syllabus.html#artificial-intelligence-ai",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Artificial Intelligence (AI)",
    "text": "Artificial Intelligence (AI)\nUsing AI tools is an emerging skill. You may use AI (ChatGPT, Gemini, Grok, etc), with some caveats & limitations:\n\nAI is often wrong, thus is not a good resource on topics for which you don’t yet have expertise. Relatedly, though AI can be helpful with parts of a statistical analysis (eg: getting unstuck on code, checking grammar), you have to guide that process (eg: what questions are we trying to answer? what’s a reasonable approach?).\nWork on an exercise for at least 30 minutes before even thinking about AI. You will learn very little if you overly rely on AI, hence be unprepared for other interactions with the material (eg: in-class discussions, quizzes, future courses that build upon 155, etc). Learning comes from you doing the puzzling, not from you producing a correct answer.\nWhether or not you use AI, you must be able to defend/explain any code/discussion you hand in. You cannot simply use AI to bypass your own learning.\nYou may not use AI to generate entire arguments or discussions. Putting code and discussions into your own words is critical for your own deeper learning, independent thinking, and creativity. (For example, imagine how little you’d learn in a language course if you simply used AI to translate all text for you!!)\nAny use of AI must be cited, just like any other resource."
  },
  {
    "objectID": "syllabus.html#community-academic-integrity",
    "href": "syllabus.html#community-academic-integrity",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Community & Academic Integrity",
    "text": "Community & Academic Integrity\nMSCS strives to provide a learning environment that is equitable, inclusive, welcoming, mutually respectful, and free of discrimination. You’re expected to follow the MSCS Community Guidelines. You’re also required to be familiar with & follow the college’s academic integrity & other academic policies. In addition to the examples listed there, academic violations in this course include but are not limited to the following:\n\nUsing any materials from any past STAT 155 course, at Mac or elsewhere. Relatedly, you should not provide any materials to any future 155 students.\nGaining access to, using, or distributing solution sets.\nPassing off others’ work as your own. You must be able to defend / explain all work you hand in.\nUsing AI without citation, to generate entire discussions / code blocks, or without being able to defend the results. Policy violations will result in a score of 0 on the work & be reported to the Asst. Dean of Academic Programs & Advising."
  },
  {
    "objectID": "syllabus.html#engagement",
    "href": "syllabus.html#engagement",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "(1) Engagement",
    "text": "(1) Engagement\nEngagement is important to your own learning & to fostering a supportive learning community.\n\n\n\n\n\n\n📌 Expectations\n\n\n\n\nDo not miss more than 3 in-person class sessions. (4–6 absences will lower your grade. 7+ absences will result in a D/NC.)\nWhen attending class:\n\nBe on time & don’t leave early\n\nDo not use your phone (phones must be put away when you enter the course, even if class hasn’t started)\n\nDo not use your laptop for anything other than taking notes and in-class activities (e.g., no videos, no email, no messaging apps, etc.)\n\nBe actively present (e.g., don’t work alone, don’t work on other courses, etc.)\n\nOutside class:\n\nCheck your email for announcements (sent via Moodle) and stay updated on the Moodle forum\n\nWhen you have questions, or just want to chat, please stop by OH!"
  },
  {
    "objectID": "syllabus.html#collaboration",
    "href": "syllabus.html#collaboration",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "(2) Collaboration",
    "text": "(2) Collaboration\nCollaboration improves higher-level thinking, confidence, communication, community, & more. You will work in groups in and outside class. These groups may occasionally switch & may sometimes be assigned.\n\n\n\n\n\n\n🤝 Expectations\n\n\n\n\nFollow the MSCS Community Guidelines\nIn group settings, both in and outside class, you:\n\nUse your group members’ correct names and pronouns\n\nActively contribute to discussions\n\nActively include all other group members in discussion\n\nCreate a space where others feel comfortable making mistakes & sharing their ideas\n\nEffectively communicate with your group about meeting times, etc."
  },
  {
    "objectID": "syllabus.html#preparation-checkpoints",
    "href": "syllabus.html#preparation-checkpoints",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "(3) Preparation (Checkpoints)",
    "text": "(3) Preparation (Checkpoints)\nRoughly half of our class sessions will require some prep work. Before class you will watch videos which introduce new concepts, then take a low-stakes checkpoint quiz (CP). This will help us prepare for class, build a common foundation, & maximize our time together – just how readings & reading reflections might be used in another class!\n\n\n\n\n\n\n📊 Expectations\n\n\n\nComplete at least 13 (out of 17) CPs (≈80%) without affecting your final grades!\n\n\n\n\n\n\n\n\n📜 Policies\n\n\n\n\nCPs may be attempted as many times as you’d like, but to earn completion credit for a given checkpoint you must score 100% by your final attempt.\nIf you complete less than 13 (out of 17) CPs (≈80%) before the time they are due, your overall course grade will be lowered by 1/3 of a letter grade (i.e. B –&gt; B-, A- –&gt; B+, etc.).\n\nIf you complete less than 8 (out of 17) CPs (≈50%) before the time they are due, your overall course grade will be lowered by 1 of a letter grade (i.e. A –&gt; B, etc.).\n\nCPs are due 09:00am on the assigned date. There are no extensions for CPs, as they are important preparation for the relevant class session."
  },
  {
    "objectID": "syllabus.html#practice-practice-problem-sets",
    "href": "syllabus.html#practice-practice-problem-sets",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "(4) Practice (Practice Problem Sets)",
    "text": "(4) Practice (Practice Problem Sets)\nIn 8 practice problem sets (PP), you will practice and explore the course material in more depth. The following flexibility is built in to help reduce stress and to facilitate deeper learning. Detailed directions and policies are here.\n\nGrading: PP grades will be based on Exercises & Presentation. You can make some mistakes without it chipping away at your score (e.g. you will earn 5/5 points on an exercise if it’s at least 90% correct & complete).\nDropped score: IF you submit and demonstrate clear effort on all 8 PPs, your lowest PP score will be dropped from your final grade.\nExtensions: Limited extensions will be provided.\nSTAT 155 Discussion Board: Use the Moodle board as your first stop for Practice Problems (PP):\n\nAsk first: Post questions about PP on Moodle. Include the problem number, a brief summary of your approach, and where you’re stuck. For coding, share the entire code chunk for the related problem.\nHelp each other: If you know (or suspect) the answer, reply! Explaining your reasoning helps everyone learn.\nShare alternatives: Multiple correct methods are welcome—post yours with explanation.\nShow your work: To earn full collaboration credit, provide complete, well-explained solutions/steps. Partial or unexplained answers may lose points.\nBe professional: Be respectful, cite any resources you used, and write solutions in your own words.\nGoal: work together as a class so everyone can earn the PP points while learning deeply."
  },
  {
    "objectID": "syllabus.html#project-independence-application",
    "href": "syllabus.html#project-independence-application",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "(5) Project (Independence & Application)",
    "text": "(5) Project (Independence & Application)\nMore details will be provided later in the semester. Here are some basics:\n\nWe’ll start working on projects in ~week 6, with the majority of the work happening later in the semester.\nThe projects are collaborative. You will be working in groups. Though you will work in assigned groups at various points throughout the semester, you will pick your own group for the project. This is something to think about as you meet other students in class and learn about common interests.\nProject grades will be based upon a final group written report (no oral presentation), multiple group and individual checkpoints, and individual contributions to the project (thus it’s possible for different group members to earn different grades)."
  },
  {
    "objectID": "syllabus.html#quizzes-content-expertise",
    "href": "syllabus.html#quizzes-content-expertise",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "(6) Quizzes (Content Expertise)",
    "text": "(6) Quizzes (Content Expertise)\nYour course engagement, collaboration, preparation, practice, and application will support your deeper understanding of the course material. This will be assessed through three in-person quizzes. You must schedule all travel and other commitments around them — there will not be any alternative quiz times.\n\nQuiz 1: Wednesday, 09/24 in class (tentative)\nQuiz 2: Wednesday, 10/29 in class (tentative)\nQuiz 3: Finals week\n\nThe exam will be written to take ~1.25 hours, but you will have the full 2-hour period to complete it.\n\n09:40–10:40 am section 03: Monday 12/15- 08:00am-10:00am\n12:00–01:00 pm section 04: Saturday 12.13- 08:00am-10:00am\n\n\n\n\n\n\n\n\n\n📜 Quiz Policies\n\n\n\n\nAll quizzes will have the following format:\n\nTaken individually, using pen/pencil & paper\n\nYou will not need to write code or use a calculator, but you will need to read & interpret R output\n\nClosed notes, but you may use a 3x5 index card with writing on both sides. These can be handwritten or typed, but you may not include screenshots or share note cards. Making your own card is important to the review process- as you are required to submit the index card along with the answer paper.\n\nQuizzes 2 & 3 will be cumulative. This is unavoidable as the material builds upon itself.\nQuiz corrections:\nYou can earn up to 50% of missed points back on Quizzes 1 & 2 if you:\n\nWrite a reflection of how you prepared for the quiz and where you felt strongest or more uncertain in your understanding before taking the quiz; and\n\nSubmit your quiz corrections along with your reflection to the instructor, no later than one week after quizzes have been handed back.\nNote: Quiz 3 corrections are not allowed due to time constraints at the end of the semester."
  },
  {
    "objectID": "syllabus.html#grading-system",
    "href": "syllabus.html#grading-system",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Grading system",
    "text": "Grading system\nThe grading system in this course is designed to help you achieve the learning objectives while allowing space to make and learn from mistakes along the way. Your final course grade will consist of three, evenly-weighted components (Quizzes, Practice Problems, and the Project), modified by your progress toward the Engagement, Collaboration, and Preparation (Checkpoint) goals:\n\n\n\nCourse Percentage\n\\(\\tfrac{1}{3}\\) Practice Problems +\n\\(\\tfrac{1}{3}\\) Quiz total +\n\\(\\tfrac{1}{3}\\) Project\n\n\n\nGrade\nCourse percentage\n\n\n\n\nA\n&gt; 93%\n\n\nA-\n87–93%\n\n\nB+\n84–87%\n\n\nB\n81–84%\n\n\nB-\n78–81%\n\n\nC+\n75–78%\n\n\nC\n72–75%\n\n\nC-\n69–72%\n\n\nD/NC\n&lt; 69% or 7+ absences\n\n\n\n\n\n  \n\n\nGrade Modifiers\nEngagement (including attendance) +\nPreparation (checkpoints)\n\n\n\n\n\n\n\nModifier\nScenario\n\n\n\n\nnone (e.g. A → A)\nMeets expectations in all two areas (Engagement and Preparation)\n\n\n⅓ lower grade (e.g. A → A-)\nDemonstrates strong progress (e.g., 4 absences OR less than 13 (out of 17) CPs (≈80%))\n\n\n1 lower grade (e.g. A → B)\nDemonstrates moderate progress (e.g., 5–6 absences OR less than 8 (out of 17) CPs (≈50%))\n\n\n&gt;1 lower grade\nDemonstrates little progress toward expectations in two areas\n\n\nDrop to D/NC\nHas 7+ absences\n\n\n\nNOTE: The table presents general scenarios. Please reach out if you want to discuss progress in Engagement and/or Preparation.\n\n\n\n\n\n\n\n\n\n📊 Grading Caveats\n\n\n\n\nThe goal of sharing this specific information is to provide transparency around final grades, hence clear goals to work toward. That said, assigning grades is much more nuanced than any grading rubric / framework might suggest (for good reasons). What’s shared here is a worst case scenario – it represents the lowest a grade might be if you meet the corresponding goals.\nMoodle does NOT correctly weight your grades, thus should not be used alone to monitor your progress."
  },
  {
    "objectID": "syllabus.html#what-to-do-if-you-miss-class",
    "href": "syllabus.html#what-to-do-if-you-miss-class",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "What to Do If You Miss Class",
    "text": "What to Do If You Miss Class\nIf you do miss class, I expect you to complete any in-class activities on your own. Check the solutions in the online manual and come to office hours with any follow-up questions."
  },
  {
    "objectID": "syllabus.html#late-work-on-practice-problems-pps",
    "href": "syllabus.html#late-work-on-practice-problems-pps",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Late work on Practice Problems (PPs)",
    "text": "Late work on Practice Problems (PPs)\nThroughout the semester, you may use up to three, three-day extensions. These three extensions can be used on Practice Problems only, not quizzes. The purpose of deadlines (and extensions) are to keep you accountable for your own learning, to keep you on track with the pace of the course (which builds upon itself throughout the semester), and to provide preceptors and myself with the ability to provide you with timely feedback on assignments. Since the Problem Sets are due roughly every two weeks, you must begin working on them early if you want to succeed.\nExtensions can be used automatically, without letting me know in advance. The Moodle dropboxes for assignments will close exactly 3 days after the original deadline (i.e. Mondays at 11:59pm), and I will not accept work submitted after that point unless there are extenuating circumstances that you have communicated with me about ahead of the original deadline. If you email me a completed assignment after a 3-day extension is up, I may have the preceptors provide you with feedback, but you will not receive credit for the assignment (equivalent to “Needs Improvement” on every question of the relevant assignment).\nI expect you to keep track of how many extensions you’ve used. I will do my best to email you a reminder if you have used all three of your extensions and have none remaining.\nIf you have run out of extensions and/or an extenuating circumstance occurs that impacts your ability to submit assignments on time, please email me to discuss the situation. I am happy to be flexible as long as you communicate!"
  },
  {
    "objectID": "syllabus.html#religious-observance",
    "href": "syllabus.html#religious-observance",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Religious Observance",
    "text": "Religious Observance\nStudents may wish to take part in religious observances that occur during the semester. If you have a religious observance/practice that conflicts with your participation in the course, please contact me before the end of the second week of the semester to discuss appropriate accommodations.\nIn an effort to respect religious diversity, I request that students who plan to observe a religious holiday during scheduled class meetings/class requirements talk to me about reasonable consideration by the end of the second week of the course."
  },
  {
    "objectID": "syllabus.html#well-being",
    "href": "syllabus.html#well-being",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Well-being",
    "text": "Well-being\nI want you to succeed. Both here at Macalester and beyond. To help make this happen, I am committed to the following.\nRespect: Everyone comes from a different path through life, and it is our moral duty as human beings to listen to each other without judgment and to respect one another. I have no tolerance for discrimination of any kind, in and out of the classroom. If you are seeking campus resources regarding discrimination, the Department of Multicultural Life and the Center for Religious and Spiritual Life are wonderful resources. We will also respect the MSCS Community Guidelines.\nSensitive Topics: Applications in this course span issues in science, policy, and society. As such, we may sometimes address sensitive topics. I will try to announce in class if an assignment or activity involves a potentially sensitive topic. If you have reservations about a particular topic, please come talk to me to discuss possible options.\nAccommodations: If you need accommodations for any reason, please contact Disability Services to discuss your needs, and speak with me as soon as possible afterwards so that we can discuss your accommodation plan. If you already have official accommodations, please discuss these with me within the first week of class so that you get off to a great start. Contact me if you have other special circumstances. I will find resources for you.\nTitle IX: You deserve a community free from discrimination, sexual harassment, hostility, sexual assault, domestic violence, dating violence, and stalking. If you or anyone you know has experienced harassment or discrimination, know that you are not alone. Macalester provides staff and resources to help you find support. Please be aware that as a faculty member, it is my responsibility to report disclosure about sexual harassment, sexual misconduct, relationship violence, and stalking to the Title IX Office. The purpose of this report is to ensure that anyone experiencing harm receives the resources and support they need. I will keep this information private, and it will not be shared beyond this required report.\nYou may also contact Macalester’s Title IX Coordinator directly (phone: 651-696-6258; e-mail: titleixcordinator@macalester.edu); they will provide you with supportive measures, resources, and referrals. Additional information about how to file a report (including anonymously) is available on the Title IX website.\nGeneral Health and Well-being: I care that you prioritize your well-being in this semester and beyond. Investing time into taking care of yourself will have profound impacts on all aspects of your life. Remember that beyond being a student, you are a human being carrying your own experiences, thoughts, emotions, and identities. It is important to acknowledge any stressors you may be facing, which can be mental, emotional, physical, cultural, financial, etc., and how they can have an impact on you. I encourage you to remember that you have a body with needs. In the classroom, eat when you are hungry, drink water, use the restroom, and step out if you are upset and need some air. Please do what is necessary so long as it does not impede your or others’ ability to be mentally and emotionally present in the course. Outside of the classroom, sleeping well, moving your body, and connecting with others can be strategies can help nourish you. If you are having difficulties maintaining your well-being, please don’t hesitate to contact me and/or find support from physical and mental health resources here, here, and here."
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMacalester Academic Advising – High School Preparation↩︎"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html",
    "href": "template_qmds/02-foundations-univariate-notes.html",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDescribe what a case (or unit of analysis) represents in a dataset.\nDescribe what a variable represents in a dataset.\nIdentify whether a variable is categorical or quantitative and what summarizations and visualizations are appropriate for that variable\nWrite R code to read in data and to summarize and visualize a single variable at a time.\nInterpret key features of barplots, boxplots, histograms, and density plots\nDescribe information about the distribution of a quantitative variable using the concepts of shape, center, spread, and outliers\nRelate summary statistics of data to the concepts of shape, center, spread, and outliers\n\n\n\n\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 2.1-2.4, 2.6 in the STAT 155 Notes\nVideos:\n\nUnivariate summaries (slides)\n\nPart 1\nPart 2\n\nR Code for Categorical Visualization and Summarization\nR Code for Quantitative Visualization and Summarization\nQuarto docs\n\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#learning-goals",
    "href": "template_qmds/02-foundations-univariate-notes.html#learning-goals",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDescribe what a case (or unit of analysis) represents in a dataset.\nDescribe what a variable represents in a dataset.\nIdentify whether a variable is categorical or quantitative and what summarizations and visualizations are appropriate for that variable\nWrite R code to read in data and to summarize and visualize a single variable at a time.\nInterpret key features of barplots, boxplots, histograms, and density plots\nDescribe information about the distribution of a quantitative variable using the concepts of shape, center, spread, and outliers\nRelate summary statistics of data to the concepts of shape, center, spread, and outliers"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#readings-and-videos",
    "href": "template_qmds/02-foundations-univariate-notes.html#readings-and-videos",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "",
    "text": "Choose either the reading or the videos to go through before class.\n\nReading: Sections 2.1-2.4, 2.6 in the STAT 155 Notes\nVideos:\n\nUnivariate summaries (slides)\n\nPart 1\nPart 2\n\nR Code for Categorical Visualization and Summarization\nR Code for Quantitative Visualization and Summarization\nQuarto docs\n\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-1-get-curious",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-1-get-curious",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 1: Get curious",
    "text": "Exercise 1: Get curious\n\nHypothesize with each other: what themes do you think might come up often in Dear Abby letters?\nAfter brainstorming, take a quick glance at the original article from The Pudding to see what themes they explored.\nGo to the very end of the Pudding article to the section titled “Data and Method”. In thinking about the who, what, when, where, why, and how of data context, what concerns/limitations surface with regards to using this data to learn about Americans’ concerns over the decades?"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-2-importing-and-getting-to-know-the-data",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-2-importing-and-getting-to-know-the-data",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 2: Importing and getting to know the data",
    "text": "Exercise 2: Importing and getting to know the data\nFirst, in the Console pane of RStudio, run the following command to install some necessary packages (you will need to do this any time you are installing a new package):\ninstall.packages(\"tidyverse\")\nNow, in the Quarto pane, run the following code chunk to load the package and load a dataset (you can either click the green arrow in the top right of the code chunk, put your cursor in the code chunk and hit Ctrl+Alt+C [on Windows/Linux] or Command+Option+C [on Mac]).\n\n# Load package\nlibrary(tidyverse)\n\n# Read in the Dear Abby data\nabby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\n\nIf it runs successfully, you should see the following output appear in the Console pane:\n&gt; # Load package\n&gt; library(tidyverse)\n&gt; \n&gt; # Read in the course evaluation data\n&gt; abby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\nRows: 20034 Columns: 11\n── Column specification ────────────────────────────\nDelimiter: \",\"\nchr (4): day, url, title, question_only\ndbl (7): year, month, letterId, afinn_overall, a...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nThroughout this activity, we’ll work only with the most recent year of data, from 2017. Run the following chunk:\n\n# Wrangle the Dear Abby data\n# Ignore this code for now!\nabby &lt;- abby %&gt;% \n  filter(year == 2017) %&gt;% \n  mutate(month = month(month, label = TRUE)) %&gt;%\n  mutate(\n    parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\"),\n    marriage = str_detect(question_only, \"marriage|marry|married\"),\n    money = str_detect(question_only, \"money|finance\")\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    themes = c(\n      if (parents) \"parents\",\n      if (marriage) \"marriage\",\n      if (money) \"money\"\n    ) %&gt;% paste(collapse = \", \"),\n    themes = ifelse(themes == \"\", \"other\", themes)\n  ) %&gt;%\n  ungroup() %&gt;% \n  select(year, month, day, question_only, bing_pos, afinn_overall, afinn_pos, afinn_neg, themes)\n\n\nClick on the Environment tab (generally in the upper right hand pane in RStudio). Then click the abby line. The abby data will pop up as a separate pane (like viewing a spreadsheet) – check it out.\nIn this tidy dataset, what is the unit of observation? That is, what is represented in each row of the dataset?\nWhat term do we use for the columns of the dataset?\nTry out each function below. Identify what each function tells you about the abby data and note this in the ???:\n\n\n# ??? [what do both numbers mean?]\ndim(abby)\n## [1] 514   9\n\n\n# ???\nnrow(abby)\n## [1] 514\n\n\n# ???\nncol(abby)\n## [1] 9\n\n\n# ???\nhead(abby)\n## # A tibble: 6 × 9\n##    year month day   question_only     bing_pos afinn_overall afinn_pos afinn_neg\n##   &lt;dbl&gt; &lt;ord&gt; &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1  2017 Aug   30    \"i moved to the …    0.75             14        16         2\n## 2  2017 Aug   30    \"under what circ…   NA                NA        NA        NA\n## 3  2017 Aug   28    \"i'm not a dog p…    0.333             5         5         0\n## 4  2017 Aug   28    \"my 62-year-old …    0.143           -11         8        19\n## 5  2017 Aug   27    \"i have a friend…    0.222             0         7         7\n## 6  2017 Aug   27    \"i have been sel…    0.333            -5         2         7\n## # ℹ 1 more variable: themes &lt;chr&gt;\n\n\n# ???\nnames(abby)\n## [1] \"year\"          \"month\"         \"day\"           \"question_only\"\n## [5] \"bing_pos\"      \"afinn_overall\" \"afinn_pos\"     \"afinn_neg\"    \n## [9] \"themes\"\n\n\n[OPTIONAL] If you’re not sure how exactly to use a function, you can pull up a built-in help page with information about the arguments a function takes (i.e., what goes inside the parentheses), and the output it produces. To do this, click inside the Console pane, and enter ?function_name. For example, to pull up a help page for the dim() function, we can type ?dim and hit Enter. Try pulling up the help page for the read_csv() function we used to load the dataset."
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 3: Preparing to summarize and visualize the data",
    "text": "Exercise 3: Preparing to summarize and visualize the data\nIn the next exercises, we will be exploring themes in the Dear Abby questions and the overall “mood” or sentiment of the questions. Before continuing, read the codebook for this dataset for some context about sentiment analysis, which gives us a measure of the mood/sentiment of a text.\n\nWhat sentiment variables do we have in the dataset? Are they quantitative or categorical?\nCheck out the theme variable. Is this quantitative or categorical?\nWhat visualizations are appropriate for looking at the distribution of a single quantitative variable? What about a single categorical variable?"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-4-exploring-themes-in-the-letters",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-4-exploring-themes-in-the-letters",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 4: Exploring themes in the letters",
    "text": "Exercise 4: Exploring themes in the letters\n\nThe code below makes a barplot of the themes variable using the ggplot2 visualization package. Before making the plot, make note of what you expect the plot might look like. (This might be hard–just do your best!) Then compare to what you observe when you run the code chunk to make the plot. (Clearly defining your expectations first is good scientific practice to avoid confirmation bias.)\n\n\n# Load package\nlibrary(ggplot2)\n\n# barplot\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\nWe can follow up on the barplot with a simple numerical summary. Whereas the ggplot2 package is great for visualizations, dplyr is great for numerical summaries. The code below constructs a table of the number of questions with each theme. Make sure that these numerical summaries match up with what you saw in the barplot.\n\n\n# Construct a table of counts\nabby %&gt;% \n    count(themes)\n## # A tibble: 8 × 2\n##   themes                       n\n##   &lt;chr&gt;                    &lt;int&gt;\n## 1 marriage                    75\n## 2 marriage, money              5\n## 3 money                       21\n## 4 other                      234\n## 5 parents                    127\n## 6 parents, marriage           33\n## 7 parents, marriage, money     4\n## 8 parents, money              15\n\n\nBefore proceeding, let’s break down the plotting code above. Run each chunk to see how the two lines of code above build up the plot in “layers”. Add comments (on the lines starting with #) to document what you notice.\n\n\n# ???\nggplot(abby, aes(x = themes))\n\n\n\n\n\n\n\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar()\n\n\n\n\n\n\n\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-5-exploring-sentiment",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-5-exploring-sentiment",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 5: Exploring sentiment",
    "text": "Exercise 5: Exploring sentiment\nWe’ll look at the distribution of the bing_pos sentiment variable and associated summary statistics.\n\nThe code below creates a boxplot of this variable. In the comment, make note of how this code is similar to the code for the barplot above. As in the previous exercise, before running the code chunk to create the plot, make note of what you expect the boxplot to look like.\n\n\n# ???\nggplot(abby, aes(x = bing_pos)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nChallenge: Using the code for the barplot and boxplot as a guide, try to make a histogram and a density plot of the overall average ratings.\n\nWhat information is given by the tallest bar of the histogram?\nHow would you describe the shape of the distribution?\n\n\n\n# Histogram\n\n# Density plot\n\n\nWe can compute summary statistics (numerical summaries) for a quantitative variable using the summary() function or with the summarize() function from the dplyr package. (1st Qu. and 3rd Qu. stand for first and third quartile.) After inspecting these summaries, look back to your boxplot, histogram, and density plot. Which plots show which summaries most clearly?\n\n\n# Summary statistics\n# Using summary() - convenient for computing many summaries in one command\n# Does not show the standard deviation\nabby %&gt;% \n    select(bing_pos) %&gt;% \n    summary()\n##     bing_pos     \n##  Min.   :0.0000  \n##  1st Qu.:0.1667  \n##  Median :0.3333  \n##  Mean   :0.3650  \n##  3rd Qu.:0.5000  \n##  Max.   :1.0000  \n##  NA's   :19\n\n# Using summarize() from dplyr\n# Note that we use %&gt;% to pipe the data into the summarize() function\n# We need to use na.rm = TRUE because there are missing values (NAs)\nabby %&gt;% \n    summarize(mean(bing_pos, na.rm = TRUE), median(bing_pos, na.rm = TRUE), sd(bing_pos, na.rm = TRUE))\n## # A tibble: 1 × 3\n##   `mean(bing_pos, na.rm = TRUE)` median(bing_pos, na.rm…¹ sd(bing_pos, na.rm =…²\n##                            &lt;dbl&gt;                    &lt;dbl&gt;                  &lt;dbl&gt;\n## 1                          0.365                    0.333                  0.279\n## # ℹ abbreviated names: ¹​`median(bing_pos, na.rm = TRUE)`,\n## #   ²​`sd(bing_pos, na.rm = TRUE)`\n\n\nWrite a good paragraph describing the information in the histogram (or density plot) by discussing shape, center, spread, and outliers. Incorporate the numerical summaries from part c."
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#pause-math-box",
    "href": "template_qmds/02-foundations-univariate-notes.html#pause-math-box",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Pause: Math box",
    "text": "Pause: Math box\nBelow is an example of a “math box” which summarizes the formulas for some of the numerical summaries above. You are not required to memorize, nor will you be assessed on, any formulas presented in this or any future math box. They serve 3 purposes:\n\nTo emphasize that there’s “math” / a formal structure behind what we’re doing.\nTo provide students that plan to continue studying Statistics a glimpse into the formal statistical theory they’ll explore in later courses.\nTo make happy the students that are simply interested in math!\n\n\n\n\n\n\n\n\n\n\nMATH BOX: Univariate numerical summaries\n\n\n\nLet \\((y_1, y_2, ..., y_n)\\) be a sample of \\(n\\) data points.\nmean: \\[\\overline{y} = \\frac{y_1 + y_2 + \\cdots + y_n}{n} = \\frac{\\sum_{i=1}^n y_i}{n}\\]\nvariance: \\[\\text{var}(y) = \\frac{(y_1 - \\overline{y})^2 + (y_2 - \\overline{y})^2 + \\cdots + (y_n - \\overline{y})^2}{n - 1} = \\frac{\\sum_{i=1}^n (y_i - \\overline{y})^2}{n - 1}\\]\nstandard deviation: \\[\\text{sd}(y) = \\sqrt{\\text{var}(y)}\\]"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 6: Box plots vs. histograms vs. density plots",
    "text": "Exercise 6: Box plots vs. histograms vs. density plots\nWe took 3 different approaches to plotting the quantitative average course variable above. They all have pros and cons.\n\nWhat is one pro about the boxplot in comparison to the histogram and density plot?\nWhat is one con about the boxplot in comparison to the histogram and density plots?\nIn this example, which plot do you prefer and why?"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-7-returning-to-our-context-looking-ahead",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-7-returning-to-our-context-looking-ahead",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 7: Returning to our context, looking ahead",
    "text": "Exercise 7: Returning to our context, looking ahead\nIn this activity, we explored data on Dear Abby question, with a focus on exploring a single variable at a time.\n\nIn big picture terms, what have we learned about Dear Abby questions?\nWhat further curiosities do you have about the data?"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-8-different-ways-to-think-about-data-visualization",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-8-different-ways-to-think-about-data-visualization",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 8: Different ways to think about data visualization",
    "text": "Exercise 8: Different ways to think about data visualization\nIn working with and visualizing data, it’s important to keep in mind what a data point represents. It can reflect the experience of a real person. It might reflect the sentiment in a piece of art. It might reflect history. We’ve taken one very narrow and technical approach to data visualization. Check out the following examples, and write some notes about anything you find interesting.\n\nDear Data\nW.E.B. DuBois\nDecolonizing Data Viz"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-9-rendering-your-work",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-9-rendering-your-work",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 9: Rendering your work",
    "text": "Exercise 9: Rendering your work\nSave this file, and then click the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\n\nScroll through and inspect the document to see how your work was translated into this HTML format. Neat!\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check."
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#reflection",
    "href": "template_qmds/02-foundations-univariate-notes.html#reflection",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Reflection",
    "text": "Reflection\nGo to the top of this file and review the learning objectives for this lesson. Which objectives do you have a good handle on, are at least familiar with, or are struggling with? What feels challenging right now? What are some wins from the day?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#advice-make-an-r-code-cheat-sheet",
    "href": "template_qmds/02-foundations-univariate-notes.html#advice-make-an-r-code-cheat-sheet",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Advice: make an R code “cheat sheet”!",
    "text": "Advice: make an R code “cheat sheet”!\nYou will continue to pick up new R code and ideas. You’re highly encouraged to start tracking this in a cheat sheet (eg: in a Google doc). The cheat sheet will be a handy reference for you, and the act of making it will help deepen your understanding and retention."
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-10-read-in-and-get-to-know-the-weather-data",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-10-read-in-and-get-to-know-the-weather-data",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 10: Read in and get to know the weather data",
    "text": "Exercise 10: Read in and get to know the weather data\nDaily weather data are available for 3 locations in Perth, Australia.\n\nView the codebook here.\nComplete the code below to read in the data.\n\n\n# Replace the ??? with your own name for the weather data\n# Replace the ___ with the correct function\n??? &lt;- ___(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n## Error in parse(text = input): &lt;text&gt;:3:5: unexpected assignment\n## 2: # Replace the ___ with the correct function\n## 3: ??? &lt;-\n##        ^"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-11-exploring-the-data-structure",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-11-exploring-the-data-structure",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 11: Exploring the data structure",
    "text": "Exercise 11: Exploring the data structure\nCheck out the basic features of the weather data.\n\n# Examine the first six cases\n\n# Find the dimensions of the data\n\nWhat does a case represent in this data?"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-12-exploring-rainfall",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-12-exploring-rainfall",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 12: Exploring rainfall",
    "text": "Exercise 12: Exploring rainfall\nThe raintoday variable contains information about rainfall.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about rainfall in Perth?\n\n\n# Visualization\n\n# Numerical summaries"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-13-exploring-temperature",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-13-exploring-temperature",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 13: Exploring temperature",
    "text": "Exercise 13: Exploring temperature\nThe maxtemp variable contains information on the daily high temperature.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about high temperatures in Perth?\n\n\n# Visualization\n\n# Numerical summaries"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-14-customizing-challenge",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-14-customizing-challenge",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 14: Customizing! (CHALLENGE)",
    "text": "Exercise 14: Customizing! (CHALLENGE)\nThough you will naturally absorb some RStudio code throughout the semester, being an effective statistical thinker and “programmer” does not require that we memorize all code. That would be impossible! In contrast, using the foundation you built today, do some digging online to learn how to customize your visualizations.\n\nFor the histogram below, add a title and more meaningful axis labels. Specifically, title the plot “Distribution of max temperatures in Perth”, change the x-axis label to “Maximum temperature” and y-axis label to “Number of days”. HINT: Do a Google search for something like “add axis labels ggplot”.\n\n\n# Add a title and axis labels\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram()\n## Error: object 'weather' not found\n\n\nAdjust the code below in order to color the bars green. NOTE: Color can be an effective tool, but here it is simply gratuitous.\n\n\n# Make the bars green\nggplot(weather, aes(x = raintoday)) + \n    geom_bar()\n## Error: object 'weather' not found\n\n\nCheck out the ggplot2 cheat sheet. Try making some of the other kinds of univariate plots outlined there.\nWhat else would you like to change about your plot? Try it!"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#exercise-15-optional-challenge",
    "href": "template_qmds/02-foundations-univariate-notes.html#exercise-15-optional-challenge",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Exercise 15: Optional challenge",
    "text": "Exercise 15: Optional challenge\nAt the top of this activity, we searched for words related to some topics of interest (parents, marriage, money) and combined them into a single theme variable. It looked something like this:\n\nabby_new &lt;- abby %&gt;% \n  mutate(\n    parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\"),\n    marriage = str_detect(question_only, \"marriage|marry|married\"),\n    money = str_detect(question_only, \"money|finance\")\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    themes = c(\n      if (parents) \"parents\",\n      if (marriage) \"marriage\",\n      if (money) \"money\"\n    ) %&gt;% paste(collapse = \", \"),\n    themes = ifelse(themes == \"\", \"other\", themes)\n  ) %&gt;%\n  ungroup()\n\nCheck it out:\n\nhead(abby_new)\n## # A tibble: 6 × 12\n##    year month day   question_only     bing_pos afinn_overall afinn_pos afinn_neg\n##   &lt;dbl&gt; &lt;ord&gt; &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1  2017 Aug   30    \"i moved to the …    0.75             14        16         2\n## 2  2017 Aug   30    \"under what circ…   NA                NA        NA        NA\n## 3  2017 Aug   28    \"i'm not a dog p…    0.333             5         5         0\n## 4  2017 Aug   28    \"my 62-year-old …    0.143           -11         8        19\n## 5  2017 Aug   27    \"i have a friend…    0.222             0         7         7\n## 6  2017 Aug   27    \"i have been sel…    0.333            -5         2         7\n## # ℹ 4 more variables: themes &lt;chr&gt;, parents &lt;lgl&gt;, marriage &lt;lgl&gt;, money &lt;lgl&gt;\n\n\nUnderstand the code!\n\nInside mutate() the line parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\") created a new variable called parents. This variable takes on TRUE or FALSE. Explain what TRUE and FALSE mean here.\nThe themes variable combines the information from the parents, marriage, and money variables. Check out the themes for the first 3 rows / data points. Convince yourself that you understand how it corresponds to the parents, marriage, and money variables.\n\nBeyond parents, marriage, and money, what are some other topics that might pop up in the Dear Abby letters (and that you’re interested in exploring)? Modify the code below to explore those topics! Update the themes variable accordingly.\n\n\nabby_new &lt;- abby %&gt;% \n  mutate(\n    parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\"),\n    marriage = str_detect(question_only, \"marriage|marry|married\"),\n    money = str_detect(question_only, \"money|finance\")\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    themes = c(\n      if (parents) \"parents\",\n      if (marriage) \"marriage\",\n      if (money) \"money\"\n    ) %&gt;% paste(collapse = \", \"),\n    themes = ifelse(themes == \"\", \"other\", themes)\n  ) %&gt;%\n  ungroup()\n\n# Check out the raw data\nhead(abby_new)\n## # A tibble: 6 × 12\n##    year month day   question_only     bing_pos afinn_overall afinn_pos afinn_neg\n##   &lt;dbl&gt; &lt;ord&gt; &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1  2017 Aug   30    \"i moved to the …    0.75             14        16         2\n## 2  2017 Aug   30    \"under what circ…   NA                NA        NA        NA\n## 3  2017 Aug   28    \"i'm not a dog p…    0.333             5         5         0\n## 4  2017 Aug   28    \"my 62-year-old …    0.143           -11         8        19\n## 5  2017 Aug   27    \"i have a friend…    0.222             0         7         7\n## 6  2017 Aug   27    \"i have been sel…    0.333            -5         2         7\n## # ℹ 4 more variables: themes &lt;chr&gt;, parents &lt;lgl&gt;, marriage &lt;lgl&gt;, money &lt;lgl&gt;\n\n# Check out the number of letters belonging to each theme\nabby_new %&gt;% \n  count(themes)\n## # A tibble: 8 × 2\n##   themes                       n\n##   &lt;chr&gt;                    &lt;int&gt;\n## 1 marriage                    75\n## 2 marriage, money              5\n## 3 money                       21\n## 4 other                      234\n## 5 parents                    127\n## 6 parents, marriage           33\n## 7 parents, marriage, money     4\n## 8 parents, money              15"
  },
  {
    "objectID": "template_qmds/02-foundations-univariate-notes.html#done",
    "href": "template_qmds/02-foundations-univariate-notes.html#done",
    "title": "Univariate visualization and summaries (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html",
    "href": "template_qmds/04-slr-formalization-notes.html",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula for a simple linear regression model with a quantitative predictor\nWrite R code to fit a linear regression model\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute expected / predicted / fitted values and residuals from a linear regression model formula\nInterpret predicted values and residuals in the context of the data\nExplain the connection between residuals and the least squares criterion\n\n\n\n\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#learning-goals",
    "href": "template_qmds/04-slr-formalization-notes.html#learning-goals",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula for a simple linear regression model with a quantitative predictor\nWrite R code to fit a linear regression model\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute expected / predicted / fitted values and residuals from a linear regression model formula\nInterpret predicted values and residuals in the context of the data\nExplain the connection between residuals and the least squares criterion"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#readings-and-videos",
    "href": "template_qmds/04-slr-formalization-notes.html#readings-and-videos",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "",
    "text": "Choose either the reading or the videos to go through before class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-1-get-to-know-the-data",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nCreate a new code chunk to look at the first few rows of the data and learn how much data (in terms of cases and variables) we have.\n\nWhat does a case represent?\nHow many and what kinds of variables do we have?\nThinking about the who, what, when, where, why, and how of this data, which of the 5W’s + H seem most relevant to our investigations? Explain your thoughts."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nLet’s get acquainted with the riders_registered variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe’d like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nWhat type of plot would be appropriate to visualize this relationship? Sketch and describe what you expect this plot to look like.\nCreate an appropriate plot using ggplot(). How does the plot compare to what you predicted?\nAdd the following two lines after your plot to add a linear (blue) and curved (red) smoothing line. What do you notice? Is a simple linear regression model appropriate for this data?\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nYOUR_PLOT +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-4-filtering-our-data",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-4-filtering-our-data",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\nThe relationship between registered riders and temperature looks linear below 80 degrees. We can use the filter() function from the dplyr package to subset our cases. (We’ll learn techniques soon for handling this nonlinear relationship.)\nIf we wanted to only keep cases where registered ridership was greater than 2000, we would use the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nNEW_DATASET_NAME &lt;- bikes %&gt;% \n    filter(riders_registered &gt; 2000)\n\nAdapt the example above to create a new dataset called bikes_sub that only keeps cases where the felt temperature is less than 80 degrees."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet’s fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n## Error in eval(mf, parent.frame()): object 'bikes_sub' not found\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n## Error: object 'bike_mod' not found\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n## Error: object 'bike_mod' not found\n\n\nUsing the model summary output, complete the following model formula:\nE[riders_registered | temp_feel] = ___ + ___ * temp_feel\nInterpret the intercept in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Is the intercept meaningful in this situation?\nInterpret the slope in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-6-predictions-and-residuals",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-6-predictions-and-residuals",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don’t worry about the syntax – we haven’t learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n## Error: object 'bikes_sub' not found\n\n\nPeak back at the scatterplot. Identify which point corresponds to August 17, 2012. Is it close to the trend? Were there more riders than expected or fewer than expected?\nUse your model formula from the previous exercise to predict the ridership on August 17, 2012 from the temperature on that day. (That is, where do days with this temperature fall on the model trend line? How many registered riders would we expect on a 53.816 degree day?)\nCheck your part b calculation using the predict() function. Take careful note of the syntax – there’s a lot going on!\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n## Error: object 'bike_mod' not found\n\n\nCalculate the residual or prediction error. How far does the observed ridership fall from the model prediction?\nresidual = observed y - predicted y = ???\nAre positive residuals above or below the trend line? When we have positive residuals, does the model over- or under-estimate ridership? Repeat these questions for negative residuals.\nFor an 85 degree day, how many registered riders would we expect? Do you think it’s a good idea to make this prediction? (Revisit the visualization and filtering we did in Exercises 3 and 4.)"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-7-changing-temperature-units-challenge",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-7-changing-temperature-units-challenge",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 7: Changing temperature units (CHALLENGE)",
    "text": "Exercise 7: Changing temperature units (CHALLENGE)\nSuppose we had measured temperature in degrees Celsius rather than degrees Fahrenheit. How do you think our intercept and slope estimates, and their coefficient interpretations, would change?"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#reflection",
    "href": "template_qmds/04-slr-formalization-notes.html#reflection",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Reflection",
    "text": "Reflection\nStatistics is a particular kind of language and collection of tools for channeling curiosity to improve our world.\nReview the learning objectives at the top of this file and the flow of today’s activity. How do the concepts we practiced today facilitate curiosity?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#render-your-work",
    "href": "template_qmds/04-slr-formalization-notes.html#render-your-work",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check."
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-8-ridership-and-windspeed",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-8-ridership-and-windspeed",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet’s pull together everything that you’ve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\n\n\n# Get a short summary of this model\n\n\nSummarize your observations from the visualizations.\nWrite out a formula for the model trend.\nInterpret both the intercept and the windspeed coefficient. (Note: What does a negative slope indicate?)\nUse this model to predict the ridership on August 17, 2012 and calculate the corresponding residual. (Note: You’ll first need to find the windspeed on this date!)"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-9-data-drills-filter-select-summarize",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-9-data-drills-filter-select-summarize",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 9: Data drills (filter, select, summarize)",
    "text": "Exercise 9: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We’ll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nThus far, in the dplyr grammar you’ve seen 3 verbs or action words: summarize(), select(), filter(). Try out the following code and then summarize the point of the summarize() function:\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n## # A tibble: 1 × 2\n##   `mean(temp_feel)` `mean(humidity)`\n##               &lt;dbl&gt;            &lt;dbl&gt;\n## 1              52.0            0.544\n\n\n\nVerb 2: select\nTry out the following code and then summarize the point of the select() function:\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n## # A tibble: 10 × 2\n##    date       temp_feel\n##    &lt;date&gt;         &lt;dbl&gt;\n##  1 2011-01-01      64.7\n##  2 2011-01-02      63.8\n##  3 2011-01-03      49.0\n##  4 2011-01-04      51.1\n##  5 2011-01-05      52.6\n##  6 2011-01-06      53.0\n##  7 2011-01-07      50.8\n##  8 2011-01-08      46.6\n##  9 2011-01-09      42.5\n## 10 2011-01-10      45.6\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n## # A tibble: 10 × 3\n##    humidity riders_registered day_of_week\n##       &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806               654 Sat        \n##  2    0.696               670 Sun        \n##  3    0.437              1229 Mon        \n##  4    0.590              1454 Tue        \n##  5    0.437              1518 Wed        \n##  6    0.518              1518 Thu        \n##  7    0.499              1362 Fri        \n##  8    0.536               891 Sat        \n##  9    0.434               768 Sun        \n## 10    0.483              1280 Mon\n\n\n\nVerb 3: filter\nTry out the following code and then summarize the point of the filter() function:\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n## # A tibble: 7 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-03      49.0    0.437              1229 Mon        \n## 2 2011-01-04      51.1    0.590              1454 Tue        \n## 3 2011-01-05      52.6    0.437              1518 Wed        \n## 4 2011-01-06      53.0    0.518              1518 Thu        \n## 5 2011-01-07      50.8    0.499              1362 Fri        \n## 6 2011-01-08      46.6    0.536               891 Sat        \n## 7 2011-01-10      45.6    0.483              1280 Mon\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n## # A tibble: 2 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-01      64.7    0.806               654 Sat        \n## 2 2011-01-08      46.6    0.536               891 Sat\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")\n## # A tibble: 1 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-08      46.6    0.536               891 Sat"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#exercise-10-your-turn",
    "href": "template_qmds/04-slr-formalization-notes.html#exercise-10-your-turn",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Exercise 10: Your turn",
    "text": "Exercise 10: Your turn\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\n\n# Keep only information about the humidity and day of week using a different approach\n\n# Keep only information for Sundays\n\n# Keep only information for Sundays with temperatures below 50\n\n# Calculate the maximum and minimum temperatures"
  },
  {
    "objectID": "template_qmds/04-slr-formalization-notes.html#done",
    "href": "template_qmds/04-slr-formalization-notes.html#done",
    "title": "Simple linear regression: formalizing concepts (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/06-slr-transformations-notes.html",
    "href": "template_qmds/06-slr-transformations-notes.html",
    "title": "Simple linear regression: Transformations (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDistinguish between the different motivations for transformations of variables (interpretation, regression assumptions, etc.)\nDetermine when a particular transformation (center, scale, or log) may be appropriate\nInterpret regression coefficients after a transformation has taken place\n\n\n\n\nPlease watch the following video before class.\n\nVideo: Simple Linear Regression: Transformations\n\nThe following reading is optional.\n\nSection 3.8.4 in the STAT 155 Notes covers log transformations, and the “ladder of power,” which we will not cover in class.\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/06-slr-transformations-notes.html#learning-goals",
    "href": "template_qmds/06-slr-transformations-notes.html#learning-goals",
    "title": "Simple linear regression: Transformations (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDistinguish between the different motivations for transformations of variables (interpretation, regression assumptions, etc.)\nDetermine when a particular transformation (center, scale, or log) may be appropriate\nInterpret regression coefficients after a transformation has taken place"
  },
  {
    "objectID": "template_qmds/06-slr-transformations-notes.html#readings-and-videos",
    "href": "template_qmds/06-slr-transformations-notes.html#readings-and-videos",
    "title": "Simple linear regression: Transformations (Notes)",
    "section": "",
    "text": "Please watch the following video before class.\n\nVideo: Simple Linear Regression: Transformations\n\nThe following reading is optional.\n\nSection 3.8.4 in the STAT 155 Notes covers log transformations, and the “ladder of power,” which we will not cover in class.\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/06-slr-transformations-notes.html#exercise-1-location-transformations",
    "href": "template_qmds/06-slr-transformations-notes.html#exercise-1-location-transformations",
    "title": "Simple linear regression: Transformations (Notes)",
    "section": "Exercise 1: Location transformations",
    "text": "Exercise 1: Location transformations\nLocation transformations are ones that shift a predictor variable up or down by a fixed amount. Using a location transformation is sometimes also called centering a predictor.\nWe’ll use the homes data in this exercise.\n\nFit a linear regression model of Price as a function of Living.Area, and call this model home_mod.\n\n\n# Fit the model\n\n\n# Display model summary output\n\n\nInterpret the intercept and the coefficient for Living.Area. Is the interpretation of the intercept meaningful?\nWe can use a location transformation on Living.Area to “start” it at a more reasonable value. We can see from the summarize() code below that the smallest house is 616 quare feet, so let’s center this predictor at 600 square feet. There is no code to fill in here, but make note of the mutate() syntax.\n\n\nhomes %&gt;% \n    summarize(min(Living.Area))\n## # A tibble: 1 × 1\n##   `min(Living.Area)`\n##                &lt;dbl&gt;\n## 1                616\n\n# What is mutate() doing???\nhomes &lt;- homes %&gt;%\n    mutate(Living.Area.Shifted = Living.Area-600)\n\n\nWe can actually determine the coefficients of the Price ~ Living.Area.Shifted model by hand.\n\nFirst, write out in general terms (without specific numbers) how we would interpret the intercept and slope in this model.\nUse these general interpretations as well as the summary output of home_mod to determine what these new coefficients should be.\n\nNow check your answer to part d by fitting the model.\n\n\n# Fit a model of Price vs. Living.Area.Shifted\n\n\n# Display model summary output"
  },
  {
    "objectID": "template_qmds/06-slr-transformations-notes.html#exercise-2-scale-transformations",
    "href": "template_qmds/06-slr-transformations-notes.html#exercise-2-scale-transformations",
    "title": "Simple linear regression: Transformations (Notes)",
    "section": "Exercise 2: Scale transformations",
    "text": "Exercise 2: Scale transformations\nIn this exercise, we’ll explore the relationship between four-year graduation rate and admissions rate of colleges.\nIn the code chunk below, construct a visualization comparing graduation rate (our outcome variable) and admissions rate (our predictor of interest). Remember that your outcome variable should be on the y-axis, in general!\n\n# Scatterplot of graduation rate vs. admissions rate\n\n\nDescribe the relationship you observe between the two quantitative variables, in terms of correlation (weak/strong, positive/negative). Does the relationship appear to be roughly linear?\nWrite a linear regression model formula of the form E[Y | X] = … (filling in Y and X appropriately).\nFit this model in R, and report (don’t interpret yet!) the slope coefficient and intercept coefficient estimates.\n\n\n# Linear regression model with GradRate as the outcome, AdmisRate as predictor of interest\n\n\nIntercept Estimate: Your response here\n\n\nSlope Estimate: Your response here\n\n\nConsidering the units of AdmisRate, what does it mean for AdmisRate to change by one unit? What are the units for AdmisRate (and GradRate, for that matter!)?\nSuppose I want the interpretation of my slope coefficient for AdmisRate in my linear model to be in terms a “1% increase in admissions rate.” To achieve this, we could mutate our AdmisRate variable to range from 0 to 100. Let’s do that for GradRate too (just because!):\n\n\n# Mutate\ncollege &lt;- college %&gt;%\n  mutate(AdmisRate = AdmisRate * ___,\n         GradRate = ___ * ___)\n## Error in parse(text = input): &lt;text&gt;:3:35: unexpected input\n## 2: college &lt;- college %&gt;%\n## 3:   mutate(AdmisRate = AdmisRate * __\n##                                      ^\n\n\nFit a new linear regression model with the updated AdmisRate and GradRate variables as your predictor of interest and outcome, respectively. Again, report the intercept and slope estimate from your model.\n\n\n# Linear regression model with updated GradRate as the outcome, updated AdmisRate as predictor of interest\n\n\nIntercept Estimate: Your response here\n\n\nSlope Estimate: Your response here\n\nHow have your intercept and slope estimates changed from the previous model, if at all?\n\nInterpret the regression coefficient that corresponds to the estimated linear relationship between admissions and graduation rates, in the context of the problem. Make sure to use non-causal language, include units, and talk about averages rather than individual cases."
  },
  {
    "objectID": "template_qmds/06-slr-transformations-notes.html#exercise-3-log-transformations",
    "href": "template_qmds/06-slr-transformations-notes.html#exercise-3-log-transformations",
    "title": "Simple linear regression: Transformations (Notes)",
    "section": "Exercise 3: Log transformations",
    "text": "Exercise 3: Log transformations\nThe Big Mac Index has been published by The Economist since 1986 as a metric for comparing purchasing power between countries, giving rise to the phrase Burgernomics. It was developed (sort of jokingly) as a way to explain exchange rates in digestible terms.\nAs an example, suppose a Big Mac in Switzerland costs 6.70 Swiss franc, and in the U.S. a Big Mac costs 5.58 USD. Then the Big Mac Index is 6.70/5.58 = 1.20, and is the implied exchange rate between Swiss franc and USD.\nIf you’d like to read more about the Big Mac index, here’s an article in The Economist (this may be behind a pay-wall for you, you can read up to 5 free articles in the Economist per month).\nFor this exercise, we’ll explore the relationship between average teaching salary in a country and the amount of time someone needs to work to be able to afford a Big Mac. The variables we’ll consider are:\n\nbigmac_mins: average minutes to earn 1 Big Mac\ngross_annual_teacher_income: average gross teacher salary in 1 year (USD)\n\n\nCreate an appropriate visualization that displays the relationship between average minutes to earn a Big Mac and gross annual, average teaching salary, and describe what you observe.\n\n\n# Visualization: Big Mac minutes vs. gross annual teacher income\n\n\nExplain why correlation might not be an appropriate numerical summary for the relationship between the two variables you plotted above.\nFit a linear regression model with bigmac_mins as the outcome and gross_annual_teacher_income as the predictor of interest, and interpret the coefficient for gross_annual_teacher_income, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\n\n\n# Linear regression code\n\n\nPlot residuals vs. fitted values for the model you fit, and describe what you observe. Are there any noticeable patterns in the residuals? Describe them!\n\n\n# Residuals vs. fitted values plot\n\n\nFor which observations do the residuals from the linear regression model appear to be relatively large (i.e. for which observations would predictions fall farthest from observed outcomes)? What possible consequences would this have for people using this model to predict the amount of time it takes for them to earn enough money to afford a Big Mac?\n\nWe’ll now consider a log transformation of teaching salary. In the code chunk below, create a new variable called log_sal that contains the logged values of gross_annual_teacher_income.\n\n# Creating new variable log_sal\nbigmac &lt;- bigmac %&gt;%\n  mutate(log_sal = log(___))\n## Error in parse(text = input): &lt;text&gt;:3:25: unexpected input\n## 2: bigmac &lt;- bigmac %&gt;%\n## 3:   mutate(log_sal = log(__\n##                            ^\n\n\nCreate an appropriate visualization that displays the relationship between average minutes to earn a Big Mac and logged gross annual, average teaching salary, and describe what you observe. Does correlation seem like it may be an appropriate numerical summary for the relationship between these two variables? Explain why or why not.\nFit a linear regression model with bigmac_mins as the outcome and log_sal as the predictor of interest, and interpret the coefficient for log_sal, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\nPlot residuals vs. fitted values for the model you fit, and describe what you observe. Are there any noticeable patterns in the residuals? Describe them!\n\n\n# Residuals vs. fitted values plot"
  },
  {
    "objectID": "template_qmds/06-slr-transformations-notes.html#reflection",
    "href": "template_qmds/06-slr-transformations-notes.html#reflection",
    "title": "Simple linear regression: Transformations (Notes)",
    "section": "Reflection",
    "text": "Reflection\nTwo of the main motivations for transforming variables in our regression models is to (1) intentionally change the interpretation of regression coefficients, and (2) to better satisfy linear regression assumptions (e.g. remove “patterns” from our residual plots). The first is nearly always justified by the scientific context of the research questions you are trying to answer, while the second is a bit more muddy.\nThink about the pros and cons of transforming your variables to satisfy linear regression assumptions. Is there a limit to how much you would be willing to transform your variables? Would transforming too much leave you with un-interpretable regression coefficients?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/06-slr-transformations-notes.html#done",
    "href": "template_qmds/06-slr-transformations-notes.html#done",
    "title": "Simple linear regression: Transformations (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html",
    "href": "template_qmds/08-mlr-intro-notes.html",
    "title": "Introduction to multiple regression (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be familiar with:\n\nsome limitations of simple linear regression\nthe general goals behind multiple linear regression\nstrategies for visualizing and interpreting multiple linear regression models of \\(Y\\) vs 2 predictors, 1 quantitative and 1 categorical\n\n\n\n\nToday is a day to discover ideas, so no readings or videos to go through before class.\n\n\n\nEXAMPLE 1\nLet’s explore some data on penguins. First, enter install.packages(\"palmerpenguins\") in the console (not Rmd). Then load the penguins data. You can find a codebook for these data by typing ?penguins in your console (not Rmd).\n\n# Load packages\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load data\nlibrary(palmerpenguins)\n## Error in library(palmerpenguins): there is no package called 'palmerpenguins'\ndata(penguins)\npenguins &lt;- penguins %&gt;% \n  filter(species != \"Adelie\", bill_length_mm &lt; 57)\n## Error in `filter()`:\n## ℹ In argument: `bill_length_mm &lt; 57`.\n## Caused by error:\n## ! object 'bill_length_mm' not found\n\n# Check it out\nhead(penguins)\n##   species    island bill_len bill_dep flipper_len body_mass    sex year\n## 1  Adelie Torgersen     39.1     18.7         181      3750   male 2007\n## 2  Adelie Torgersen     39.5     17.4         186      3800 female 2007\n## 3  Adelie Torgersen     40.3     18.0         195      3250 female 2007\n## 4  Adelie Torgersen       NA       NA          NA        NA   &lt;NA&gt; 2007\n## 5  Adelie Torgersen     36.7     19.3         193      3450 female 2007\n## 6  Adelie Torgersen     39.3     20.6         190      3650   male 2007\n\nOur goal is to build a model that we can use to get good predictions of penguins’ flipper (“arm”) lengths. Consider 2 simple linear regression models of flipper_length_mm by penguin sex and species:\n\nsummary(lm(flipper_length_mm ~ sex, penguins))$r.squared\n## Error in eval(predvars, data, env): object 'flipper_length_mm' not found\nsummary(lm(flipper_length_mm ~ species, penguins))$r.squared\n## Error in eval(predvars, data, env): object 'flipper_length_mm' not found\n\nHow might we improve our predictions of flipper_length_mm using only these 2 predictors? What do you think is a reasonable range of possible values for the new R-squqared?\nEXAMPLE 2\nConsider a simple linear regression model of flipper_length_mm by bill_length_mm:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'bill_length_mm' not found\n\nThoughts? What’s going on here? How does this highlight the limitations of a simple linear regression model?\nEXAMPLE 3\nThe cps dataset contains employment information collected by the U.S. Current Population Survey (CPS) in 2018. We can use these data to explore wages among 18-34 year olds. The original codebook is here.\n\n# Import data\ncps &lt;- read_csv(\"https://mac-stat.github.io/data/cps_2018.csv\") %&gt;% \n  select(-education, -hours) %&gt;% \n  filter(age &gt;= 18, age &lt;= 34) %&gt;% \n  filter(wage &lt; 250000)\n\n\n# Check it out\nhead(cps)\n## # A tibble: 6 × 6\n##    wage   age marital industry   health    education_level\n##   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;          \n## 1 75000    33 single  management fair      bachelors      \n## 2 33000    19 single  management very_good bachelors      \n## 3 43000    33 married management good      bachelors      \n## 4 50000    32 single  management excellent HS             \n## 5 14400    28 single  service    excellent HS             \n## 6 33000    31 married management very_good bachelors\n\nWe can use a simple linear regression model to summarize the relationship of wage with marital status:\n\n# Build the model\nwage_mod &lt;- lm(wage ~ marital, data = cps)\n\n# Summarize the model\ncoef(summary(wage_mod))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept)    46145.23    921.062  50.10002 0.000000e+00\n## maritalsingle -17052.37   1127.177 -15.12839 5.636068e-50\n\nWhat do you / don’t you conclude from this model? How does it highlight the limitations of a simple linear regression model?\nReflection: Why are multiple regression models so useful?\nWe can put more than 1 predictor into a regression model! Adding predictors to models…\n\nPredictive viewpoint: Helps us better predict the response\nDescriptive viewpoint: Helps us better understand the isolated (causal) effect of a variable by holding constant confounders\n\nMultiple linear regression model formula\nIn general, a multiple linear regression model of \\(Y\\) with multiple predictors \\((X_1, X_2, ..., X_p)\\) is represented by the following formula:\n\\[E[Y \\mid X_1, X_2, ..., X_p] = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\]"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#learning-goals",
    "href": "template_qmds/08-mlr-intro-notes.html#learning-goals",
    "title": "Introduction to multiple regression (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be familiar with:\n\nsome limitations of simple linear regression\nthe general goals behind multiple linear regression\nstrategies for visualizing and interpreting multiple linear regression models of \\(Y\\) vs 2 predictors, 1 quantitative and 1 categorical"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#readings-and-videos",
    "href": "template_qmds/08-mlr-intro-notes.html#readings-and-videos",
    "title": "Introduction to multiple regression (Notes)",
    "section": "",
    "text": "Today is a day to discover ideas, so no readings or videos to go through before class."
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#motivation",
    "href": "template_qmds/08-mlr-intro-notes.html#motivation",
    "title": "Introduction to multiple regression (Notes)",
    "section": "",
    "text": "EXAMPLE 1\nLet’s explore some data on penguins. First, enter install.packages(\"palmerpenguins\") in the console (not Rmd). Then load the penguins data. You can find a codebook for these data by typing ?penguins in your console (not Rmd).\n\n# Load packages\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load data\nlibrary(palmerpenguins)\n## Error in library(palmerpenguins): there is no package called 'palmerpenguins'\ndata(penguins)\npenguins &lt;- penguins %&gt;% \n  filter(species != \"Adelie\", bill_length_mm &lt; 57)\n## Error in `filter()`:\n## ℹ In argument: `bill_length_mm &lt; 57`.\n## Caused by error:\n## ! object 'bill_length_mm' not found\n\n# Check it out\nhead(penguins)\n##   species    island bill_len bill_dep flipper_len body_mass    sex year\n## 1  Adelie Torgersen     39.1     18.7         181      3750   male 2007\n## 2  Adelie Torgersen     39.5     17.4         186      3800 female 2007\n## 3  Adelie Torgersen     40.3     18.0         195      3250 female 2007\n## 4  Adelie Torgersen       NA       NA          NA        NA   &lt;NA&gt; 2007\n## 5  Adelie Torgersen     36.7     19.3         193      3450 female 2007\n## 6  Adelie Torgersen     39.3     20.6         190      3650   male 2007\n\nOur goal is to build a model that we can use to get good predictions of penguins’ flipper (“arm”) lengths. Consider 2 simple linear regression models of flipper_length_mm by penguin sex and species:\n\nsummary(lm(flipper_length_mm ~ sex, penguins))$r.squared\n## Error in eval(predvars, data, env): object 'flipper_length_mm' not found\nsummary(lm(flipper_length_mm ~ species, penguins))$r.squared\n## Error in eval(predvars, data, env): object 'flipper_length_mm' not found\n\nHow might we improve our predictions of flipper_length_mm using only these 2 predictors? What do you think is a reasonable range of possible values for the new R-squqared?\nEXAMPLE 2\nConsider a simple linear regression model of flipper_length_mm by bill_length_mm:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'bill_length_mm' not found\n\nThoughts? What’s going on here? How does this highlight the limitations of a simple linear regression model?\nEXAMPLE 3\nThe cps dataset contains employment information collected by the U.S. Current Population Survey (CPS) in 2018. We can use these data to explore wages among 18-34 year olds. The original codebook is here.\n\n# Import data\ncps &lt;- read_csv(\"https://mac-stat.github.io/data/cps_2018.csv\") %&gt;% \n  select(-education, -hours) %&gt;% \n  filter(age &gt;= 18, age &lt;= 34) %&gt;% \n  filter(wage &lt; 250000)\n\n\n# Check it out\nhead(cps)\n## # A tibble: 6 × 6\n##    wage   age marital industry   health    education_level\n##   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;          \n## 1 75000    33 single  management fair      bachelors      \n## 2 33000    19 single  management very_good bachelors      \n## 3 43000    33 married management good      bachelors      \n## 4 50000    32 single  management excellent HS             \n## 5 14400    28 single  service    excellent HS             \n## 6 33000    31 married management very_good bachelors\n\nWe can use a simple linear regression model to summarize the relationship of wage with marital status:\n\n# Build the model\nwage_mod &lt;- lm(wage ~ marital, data = cps)\n\n# Summarize the model\ncoef(summary(wage_mod))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept)    46145.23    921.062  50.10002 0.000000e+00\n## maritalsingle -17052.37   1127.177 -15.12839 5.636068e-50\n\nWhat do you / don’t you conclude from this model? How does it highlight the limitations of a simple linear regression model?\nReflection: Why are multiple regression models so useful?\nWe can put more than 1 predictor into a regression model! Adding predictors to models…\n\nPredictive viewpoint: Helps us better predict the response\nDescriptive viewpoint: Helps us better understand the isolated (causal) effect of a variable by holding constant confounders\n\nMultiple linear regression model formula\nIn general, a multiple linear regression model of \\(Y\\) with multiple predictors \\((X_1, X_2, ..., X_p)\\) is represented by the following formula:\n\\[E[Y \\mid X_1, X_2, ..., X_p] = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\]"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#exercise-1-visualizing-the-relationship",
    "href": "template_qmds/08-mlr-intro-notes.html#exercise-1-visualizing-the-relationship",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Exercise 1: Visualizing the relationship",
    "text": "Exercise 1: Visualizing the relationship\nWe’ve learned how to visualize the relationship of flipper_length_mm by bill_length_mm alone:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point()\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'bill_length_mm' not found\n\n\nTHINK: How might we change the scatterplot points to also indicate information about penguin species? (There’s more than 1 approach!)\nTry out your idea by modifying the code below. If you get stuck, talk with the tables around you!\n\n\npenguins %&gt;%\n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, ___ = ___)) +\n  geom_point()\n## Error in parse(text = input): &lt;text&gt;:2:58: unexpected input\n## 1: penguins %&gt;%\n## 2:   ggplot(aes(y = flipper_length_mm, x = bill_length_mm, __\n##                                                             ^"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#exercise-2-visualizing-the-model",
    "href": "template_qmds/08-mlr-intro-notes.html#exercise-2-visualizing-the-model",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Exercise 2: Visualizing the model",
    "text": "Exercise 2: Visualizing the model\nWe’ve also learned that a simple linear regression model of flipper_length_mm by bill_length_mm alone can be represented by a line:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'bill_length_mm' not found\n\n\nTHINK: Reflecting on your plot of flipper_length_mm by bill_length_mm and species in Exercise 1, how do you think a multiple regression model of flipper_length_mm using both of these predictors would be represented?\nCheck your intuition below by modifying the code below to include species in this plot, as you did in Exercise 1.\n\n\npenguins %&gt;%\n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, ___ = ___)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n## Error in parse(text = input): &lt;text&gt;:2:58: unexpected input\n## 1: penguins %&gt;%\n## 2:   ggplot(aes(y = flipper_length_mm, x = bill_length_mm, __\n##                                                             ^"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#exercise-3-intuition",
    "href": "template_qmds/08-mlr-intro-notes.html#exercise-3-intuition",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Exercise 3: Intuition",
    "text": "Exercise 3: Intuition\nYour plot in Exercise 2 demonstrated that the multiple linear regression model of flipper_length_mm by bill_length_mm and species is represented by 2 lines. Let’s interpret the punchlines!\nFor each question, provide an answer along with evidence from the model lines that supports your answer.\n\nWhat’s the relationship between flipper_length_mm and species, no matter a penguin’s bill_length_mm?\nWhat’s the relationship between flipper_length_mm and bill_length_mm, no matter a penguin’s species?\nDoes the rate of increase in flipper_length_mm with bill_length_mm differ between the two species?"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#exercise-4-model-formula",
    "href": "template_qmds/08-mlr-intro-notes.html#exercise-4-model-formula",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Exercise 4: Model formula",
    "text": "Exercise 4: Model formula\nOf course, there’s a formula behind the multiple regression model. We can obtain this using the usual lm() function.\n\n# Build the model\npenguin_mod &lt;- lm(flipper_length_mm ~ bill_length_mm + species, data = penguins)\n## Error in eval(predvars, data, env): object 'flipper_length_mm' not found\n\n# Summarize the model\ncoef(summary(penguin_mod))\n## Error: object 'penguin_mod' not found\n\n\nIn the lm() function, how did we communicate that we wanted to model flipper_length_mm by both bill_length_mm and species?\nComplete the following model formula:\nE[flipper_length_mm | bill_length_mm, speciesGentoo] = ___ + ___ * bill_length_mm + ___ * speciesGentoo"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#exercise-5-sub-model-formulas",
    "href": "template_qmds/08-mlr-intro-notes.html#exercise-5-sub-model-formulas",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Exercise 5: Sub-model formulas",
    "text": "Exercise 5: Sub-model formulas\nOk. We now have a single formula for the model.\nAnd we observed earlier that this formula is represented by two lines: one describing the relationship between flipper_length_mm and bill_length_mm for Chinstrap penguins and the other for Gentoo penguins.\nLet’s bring these ideas together.\nUtilize the model formula to obtain the equations of these two lines, i.e. to obtain the sub-model formulas for the 2 species. Hint: Plug speciesGentoo = 0 and speciesGentoo = 1.\nChinstrap: flipper_length_mm = ___ + ___ bill_length_mm\nGentoo: flipper_length_mm = ___ + ___ bill_length_mm"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#exercise-6-coefficients-physical-interpretation",
    "href": "template_qmds/08-mlr-intro-notes.html#exercise-6-coefficients-physical-interpretation",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Exercise 6: coefficients – physical interpretation",
    "text": "Exercise 6: coefficients – physical interpretation\nReflecting on Exercise 5, let’s interpret what the model coefficients tell us about the physical properties of the two 2 sub-model lines. Choose the correct option given in parentheses:\n\nThe intercept coefficient, 127.75, is the intercept of the line for (Chinstrap / Gentoo) penguins.\nThe bill_length_mm coefficient, 1.40, is the (intercept / slope) of both lines.\nThe speciesGentoo coefficient, 22.85, indicates that the (intercept / slope) of the line for Gentoo is 22.85mm higher than the (intercept / slope) of the line for Chinstrap. Similarly, since the lines are parallel, the line for Gentoo is 22.85mm higher than the line for Chinstrap at any bill_length_mm."
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#exercise-7-coefficients-contextual-interpretation",
    "href": "template_qmds/08-mlr-intro-notes.html#exercise-7-coefficients-contextual-interpretation",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Exercise 7: coefficients – contextual interpretation",
    "text": "Exercise 7: coefficients – contextual interpretation\nNext, interpret each coefficient in a contextually meaningful way. What do they tell us about penguin flipper lengths?!\n\nInterpret 127.75 (intercept of the Chinstrap line).\nInterpret 1.40 (slope of both lines). For both Chinstrap and Gentoo penguins, we expect…\nInterpret 22.85. At any bill_length_mm, we expect…"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#exercise-8-prediction",
    "href": "template_qmds/08-mlr-intro-notes.html#exercise-8-prediction",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Exercise 8: Prediction",
    "text": "Exercise 8: Prediction\nNow that we better understand the model, let’s use it to predict flipper lengths! Recall the model summary and visualization:\n\ncoef(summary(penguin_mod))\n## Error: object 'penguin_mod' not found\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, color = species)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'bill_length_mm' not found\n\n\nPredict the flipper length of a Chinstrap penguin with a 50mm long bill. Make sure your calculation is consistent with the plot.\n\n\n127.75 + 1.40*___ + 22.85*___\n## Error in parse(text = input): &lt;text&gt;:1:16: unexpected input\n## 1: 127.75 + 1.40*__\n##                    ^\n\n\nPredict the flipper length of a Gentoo penguin with a 50mm long bill. Make sure your calculation is consistent with the plot.\n\n\n127.75 + 1.40*___ + 22.85*___\n## Error in parse(text = input): &lt;text&gt;:1:16: unexpected input\n## 1: 127.75 + 1.40*__\n##                    ^\n\n\nUse the predict() function to confirm your predictions in parts a and b.\n\n\n# Confirm the calculation in part a\npredict(penguin_mod,\n        newdata = data.frame(bill_length_mm = ___, species = \"___\"))\n\n# Confirm the calculation in part b\npredict(penguin_mod,\n        newdata = data.frame(bill_length_mm = ___, species = \"___\"))\n## Error in parse(text = input): &lt;text&gt;:3:48: unexpected input\n## 2: predict(penguin_mod,\n## 3:         newdata = data.frame(bill_length_mm = __\n##                                                   ^"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#exercise-9-r-squared",
    "href": "template_qmds/08-mlr-intro-notes.html#exercise-9-r-squared",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Exercise 9: R-squared",
    "text": "Exercise 9: R-squared\nFinally, recall that improving our predictions was one motivation for multiple linear regression (using 2 predictors instead of 1). To this end, consider the R-squared values of the simple linear regression models that use just one predictor at a time:\n\nmod_bill &lt;- lm(flipper_length_mm ~ bill_length_mm, data = penguins)\n## Error in eval(predvars, data, env): object 'flipper_length_mm' not found\nsummary(mod_bill)\n## Error: object 'mod_bill' not found\n\nmod_species &lt;- lm(flipper_length_mm ~ species, data = penguins)\n## Error in eval(predvars, data, env): object 'flipper_length_mm' not found\nsummary(mod_species)\n## Error: object 'mod_species' not found\n\n\nIf you had to use only 1 of our 2 predictors, which would give the better predictions of flipper_length_mm?\nWhat do you guess is the R-squared of our multiple regression model that uses both of these predictors? Why?\nCheck your intuition. How does the R-squared of our multiple regression model compare to that of the 2 separate simple linear regression models?\n\n\nsummary(penguin_mod)\n## Error: object 'penguin_mod' not found"
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#reflection",
    "href": "template_qmds/08-mlr-intro-notes.html#reflection",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Reflection",
    "text": "Reflection\nYou’ve now explored your first multiple regression model! Thus you likely have a lot of questions about what’s to come. What are they?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/08-mlr-intro-notes.html#done",
    "href": "template_qmds/08-mlr-intro-notes.html#done",
    "title": "Introduction to multiple regression (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html",
    "href": "template_qmds/10-mlr-confounding-notes.html",
    "title": "Confounding variables (Notes)",
    "section": "",
    "text": "Slides with comments on Quiz 1\nYou can download a template file to work with here.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.\n\n\n\nBy the end of this lesson, you should be familiar with:\n\nconfounding variables\nhow to control for confounding variables in our models\nhow to represent the role of confounding variables using causal diagrams\n\n\n\n\nBefore class you should have read and watched:\n\nSections 3.9.2 in the STAT 155 Notes\nConfounding (and other causal diagrams)\n\nWatch from 0:00 - 6:54"
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#learning-goals",
    "href": "template_qmds/10-mlr-confounding-notes.html#learning-goals",
    "title": "Confounding variables (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be familiar with:\n\nconfounding variables\nhow to control for confounding variables in our models\nhow to represent the role of confounding variables using causal diagrams"
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#readings-and-videos",
    "href": "template_qmds/10-mlr-confounding-notes.html#readings-and-videos",
    "title": "Confounding variables (Notes)",
    "section": "",
    "text": "Before class you should have read and watched:\n\nSections 3.9.2 in the STAT 155 Notes\nConfounding (and other causal diagrams)\n\nWatch from 0:00 - 6:54"
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-1-review",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-1-review",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 1: Review",
    "text": "Exercise 1: Review\nThe peaks data includes information on hiking trails in the 46 “high peaks” in the Adirondack mountains of northern New York state:\n\n# Load useful packages and data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\npeaks &lt;- read_csv(\"https://mac-stat.github.io/data/high_peaks.csv\") %&gt;%\n    mutate(ascent = ascent / 1000)\n\n# Check it out \nhead(peaks)\n## # A tibble: 6 × 7\n##   peak           elevation difficulty ascent length  time rating   \n##   &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    \n## 1 Mt. Marcy           5344          5   3.17   14.8  10   moderate \n## 2 Algonquin Peak      5114          5   2.94    9.6   9   moderate \n## 3 Mt. Haystack        4960          7   3.57   17.8  12   difficult\n## 4 Mt. Skylight        4926          7   4.26   17.9  15   difficult\n## 5 Whiteface Mtn.      4867          4   2.54   10.4   8.5 easy     \n## 6 Dix Mtn.            4857          5   2.8    13.2  10   moderate\n\nBelow is a model of the time (in hours) that it takes to complete a hike by the hike’s length (in miles), vertical ascent(in 1000s of feet), and rating (easy, moderate, or difficult):\n\npeaks_model &lt;- lm(time ~ length + ascent + rating, data = peaks)\ncoef(summary(peaks_model))\n\nInterpret the length and ratingeasy coefficients in the model formula below by using our strategy:\n\nStrategy: When interpreting a coefficient for a variable x, compare two units whose values of x differ by 1 but who are identical for all other variables.\n\nE[time | length, ascent, rating] = 6.511 + 0.459 length + 0.187 ascent - 3.169 ratingeasy - 2.477 ratingmoderate\n\nSynthesis:\n\nInterpreting the coefficient \\(\\beta_Q\\) for a quantitative variable Q:\n\nHolding all other variables constant, each unit increase in Q is associated with \\(\\beta_Q\\) change (note if it’s an increase or decrease) in Y on average.\n\nInterpreting the coefficient \\(\\beta_C\\) for an indicator variable:\n\nHolding all other variables constant, the average outcome for the group referenced by this indicator (group for whom indicator = 1), is \\(\\beta_C\\) higher/lower than that of the reference group."
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-2-confounders",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-2-confounders",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 2: Confounders",
    "text": "Exercise 2: Confounders\n\nResearch question: Is there a wage gap, hence possibly discrimination, by marital status among 18-34 year olds?\n\nTo explore, we can revisit the cps data with employment information collected by the U.S. Current Population Survey (CPS) in 2018. View the codebook here.\n\n# Import data\ncps &lt;- read_csv(\"https://mac-stat.github.io/data/cps_2018.csv\") %&gt;% \n    filter(age &gt;= 18, age &lt;= 34) %&gt;% \n    filter(wage &lt; 250000)\n\n# Check it out\nhead(cps)\n## # A tibble: 6 × 8\n##    wage   age education marital industry   health    hours education_level\n##   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;          \n## 1 75000    33        16 single  management fair         40 bachelors      \n## 2 33000    19        16 single  management very_good    40 bachelors      \n## 3 43000    33        16 married management good         40 bachelors      \n## 4 50000    32        12 single  management excellent    40 HS             \n## 5 14400    28        12 single  service    excellent    40 HS             \n## 6 33000    31        16 married management very_good    45 bachelors\n\nRecall that a simple linear regression model of wage by marital suggests that single workers make $17,052 less than married workers:\n\nwage_model_1 &lt;- lm(wage ~ marital, data = cps)\ncoef(summary(wage_model_1))\n\nThat’s a big gap!!\nBUT this model ignores important confounding variables that might help explain this gap.\nA confounding variable is a cause of both the predictor of interest (marital) and of the response variable (wage).\nWe can represent this idea with a causal diagram:\n\n\n\n\n\n\n\n\n\nAnother definition of a confounding variable is one that\n\nis a cause of the outcome (wage)\nis associated with the main variable of interest (marital status)\nNOT caused by the variable of interest\n\nWe can represent this on the causal diagram with a line from the confounder to the variable of interest (instead of an arrow):\n\n\n\n\n\n\n\n\n\nName at least 2 potential confounders."
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-2b-how-why-do-confounders-bias-results",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-2b-how-why-do-confounders-bias-results",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 2b: How & why do confounders bias results?",
    "text": "Exercise 2b: How & why do confounders bias results?\nUnaccounted-for confounders are often a source of bias in our models, meaning that when we ignore them, we often over- or under-estimate the true underlying relationship between a predictor and response variable. To explore why this is important, let’s first look at how our focal predictor marital is associated with our response variable, wage:\n\ncps %&gt;%\n  ggplot(aes(x=marital, y=wage))+\n  geom_boxplot()+\n  theme_classic()\n\n\n\n\n\n\n\n\nNow, let’s consider age as a potential confounder. The following plot shows how age is associated with marital status:\n\ncps %&gt;%\n  ggplot(aes(x=age, y=marital))+\n  geom_boxplot()+\n  theme_classic()\n\n\n\n\n\n\n\n\n…this should make sense, because the older a person is, the more likely they are to be married. Similarly, we can show how age is associated with wage:\n\ncps %&gt;%\n  ggplot(aes(x=age, y=wage))+\n  geom_point()+\n  geom_smooth(method=\"lm\", se=F)+\n  theme_classic()\n\n\n\n\n\n\n\n\nHere we see that there is a positive correlation between age and wages (which again makes sense, because people who have been in the workforce longer typically earn more).\nLet’s revisit our initial plot showing the relationship between marital status and wages:\n\ncps %&gt;%\n  ggplot(aes(x=marital, y=wage))+\n  geom_boxplot()+\n  theme_classic()\n\n\n\n\n\n\n\n\nSince we now know that age is associated with both being married and higher wages, this plot doesn’t tell the full story–people who are married could simply be earning higher wages because they tend to be older, not necessarily because they are married! Age is therefore a confounder in the relationship between marital status and wages."
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-3-controlling-for-confounders",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-3-controlling-for-confounders",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 3: Controlling for confounders",
    "text": "Exercise 3: Controlling for confounders\nThe exercise above illustrates that it is important to control or adjust for confounding variables when trying to understand the actual causal relationship between a predictor (e.g. marital) and response (e.g. wage).\n\nSometimes, we can control (adjust) for confounding variables through a carefully designed experiment. For example, in comparing the effectiveness (y) of 2 different cold remedies (x), we might want to control for the age, general health, and severity of symptoms among the participants. How might we do that?\nBUT we’re often working with observational, not experimental, data. Why? Well, explain what an experiment might look like if we wanted to explore the relationship between wage (y) and marital status (x) while controlling for age."
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-4-age",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-4-age",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 4: Age",
    "text": "Exercise 4: Age\nWe’re in luck.\nWe can control (adjust) for confounding variables by including them in our model!\nThat’s one of the superpowers of multiple linear regression.\nLet’s start simple, by controlling for age in our model of wages by marital status:\n\n# Construct the model\nwage_model_2 &lt;- lm(wage ~ marital + age, cps)\ncoef(summary(wage_model_2))\n\n\nVisualize this model by modifying the code below.\n\n(Note: The last line where we add a geom_line layer adds in trendlines similar to what we might obtain using geom_smooth, but it uses the exact fitted values from our model. geom_smooth, on the other hand, adds in trendlines based on fitting two separate models to the married and single subsets of the data. Tray adding geom_smooth(method=\"lm\", se=F, linetype=\"dashed\") to the plot to see how they compare).\n\nggplot(cps, aes(y = ___, x = ___, color = ___)) +\n    geom____(size = 0.1, alpha = 0.5) +\n    geom_line(aes(y = wage_model_2$fitted.values), linewidth = 0.5)\n\n\nSuppose 2 workers are the same age, but one is married and one is single. By how much do we expect the single worker’s wage to differ from the married worker’s wage? (How does this compare to the $17,052 marital gap among all workers?)\nHow can we interpret the maritalsingle coefficient?"
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-5-more-confounders",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-5-more-confounders",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 5: More confounders",
    "text": "Exercise 5: More confounders\nLet’s control for even more potential confounders!\nModel wages by marital status while controlling for age and years of education:\n\nwage_model_3 &lt;- lm(wage ~ marital + age + education, cps)\ncoef(summary(wage_model_3))\n\n\nWith so many variables, this is a tough model to visualize. If you had to draw it, how would the model trend appear: 1 point, 2 points, 2 lines, 1 plane, or 2 planes? Explain your rationale. Hint: pay attention to whether your predictors are quantitative or categorical.\nGiven our research question, which coefficient is of primary interest? Interpret this coefficient.\nInterpret the two other coefficients in this model."
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-6-even-more",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-6-even-more",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 6: Even more",
    "text": "Exercise 6: Even more\nLet’s control for another potential confounder, the job industry in which one works (categorical):\n\nwage_model_4 &lt;- lm(wage ~ marital + age + education + industry, cps)\ncoef(summary(wage_model_4))\n\nIf we had to draw it, this model would appear as 12 planes.\nThe original plane explains the relationship between wage and the 2 quantitative predictors, age and education.\nThen this plane is split into 12 (2*6) individual planes, 1 for each possible combination of marital status (2 possibilities) and industry (6 possibilities).\n\nInterpret the main coefficient of interest for our research question.\nWhen controlling for a worker’s age, marital status, and education level, which industry tends to have the highest wages? The lowest? Note: the following table shows the 6 industries:\n\n\ncps %&gt;% count(industry)"
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-7-biggest-model-yet",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-7-biggest-model-yet",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 7: Biggest model yet",
    "text": "Exercise 7: Biggest model yet\nBuild a model that helps us explore wage by marital status while controlling for: age, education, job industry, typical number of work hours, and health status.\nStore this model as wage_model_5."
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-8-reflection",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-8-reflection",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 8: Reflection",
    "text": "Exercise 8: Reflection\nTake two workers – one is married and the other is single.\nThe models above provided the following insights into the typical difference in wages for these two groups:\n\n\n\nModel\nAssume the two people have the same…\nWage difference\n\n\n\n\nwage_model_1\nNA\n-$17,052\n\n\nwage_model_2\nage\n-$7,500\n\n\nwage_model_3\nage, education\n-$6,478\n\n\nwage_model_4\nage, education, industry\n-$5,893\n\n\nwage_model_5\nage, education, industry, hours, health\n-$4,993\n\n\n\n\nThough not the case in every analysis, the marital coefficient got closer and closer to 0 as we controlled for more confounders. Explain the significance of this phenomenon, in context - what does it mean?\nDo you still find the wage gap for single vs married people to be meaningfully “large”? Can you think of any remaining factors that might explain part of this remaining gap? Or do you think we’ve found evidence of inequitable wage practices for single vs married workers?"
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-9-a-new-extreme-example",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-9-a-new-extreme-example",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 9: A new (extreme) example",
    "text": "Exercise 9: A new (extreme) example\nFor a more extreme example of why it’s important to control for confounding variables, let’s return to the diamonds data:\n\n# Import and wrangle the data\ndata(diamonds)\ndiamonds &lt;- diamonds %&gt;% \n    mutate(\n        cut = factor(cut, ordered = FALSE),\n        color = factor(color, ordered = FALSE),\n        clarity = factor(clarity, ordered = FALSE)\n    ) %&gt;% \n    select(price, clarity, cut, color, carat)\n\nOur goal is to explore how the price of a diamond depends upon its clarity (a measure of quality).\nClarity is classified as follows, in order from best to worst:\n\n\n\nclarity\ndescription\n\n\n\n\nIF\nflawless (no internal imperfections)\n\n\nVVS1\nvery very slightly imperfect\n\n\nVVS2\n” ”\n\n\nVS1\nvery slightly imperfect\n\n\nVS2\n” ”\n\n\nSI1\nslightly imperfect\n\n\nSI2\n” ”\n\n\nI1\nimperfect\n\n\n\n\nCheck out a model of price by clarity. What clarity has the highest average price? The lowest? (This is surprising!)\n\n\ndiamond_model_1 &lt;- lm(price ~ clarity, data = diamonds)\n\n# Get a model summary\ncoef(summary(diamond_model_1))\n\n\nWhat confounding variable might explain these results? What’s your rationale?"
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-10-size",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-10-size",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 10: Size",
    "text": "Exercise 10: Size\nIt turns out that carat, the size of a diamond, is an important confounding variable.\nLet’s explore what happens when we control for this in our model:\n\ndiamond_model_2 &lt;- lm(price ~ clarity + carat, data = diamonds)\n\n# Get a model summary\ncoef(summary(diamond_model_2))\n\n# Plot the model\ndiamonds %&gt;% \n    ggplot(aes(y = price, x = carat, color = clarity)) + \n    geom_line(aes(y = diamond_model_2$fitted.values))\n\nWhat do you think now?\nWhich clarity has the highest expected price?\nThe lowest?\nProvide numerical evidence from the model."
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-11-simpsons-paradox",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-11-simpsons-paradox",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 11: Simpson’s Paradox",
    "text": "Exercise 11: Simpson’s Paradox\nControlling for carat didn’t just change the clarity coefficients, hence our understanding of the relationship between price and clarity… It flipped the signs of many of these coefficients.\nThis extreme scenario has a name: Simpson’s paradox.\nCHALLENGE: Explain why this happened and support your argument with graphical evidence.\nHINTS: Think about the causal diagram below. How do you think carat influences clarity? How do you think carat influences price? Make 2 ggplot() that support your answers."
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#exercise-12-final-conclusion",
    "href": "template_qmds/10-mlr-confounding-notes.html#exercise-12-final-conclusion",
    "title": "Confounding variables (Notes)",
    "section": "Exercise 12: Final conclusion",
    "text": "Exercise 12: Final conclusion\nWhat’s your final conclusion about diamond prices?\nWhich diamonds are more expensive: flawed ones or flawless ones?"
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#reflection",
    "href": "template_qmds/10-mlr-confounding-notes.html#reflection",
    "title": "Confounding variables (Notes)",
    "section": "Reflection",
    "text": "Reflection\nWrite a one-sentence warning label for what might happen if we do not control for confounding variables in our model.\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/10-mlr-confounding-notes.html#done",
    "href": "template_qmds/10-mlr-confounding-notes.html#done",
    "title": "Confounding variables (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nVisualize interactions between categorical and quantitative predictors using scatterplots and side-by-side or boxplots\nCritically think through whether an interaction term makes sense, or should be included in a multiple linear regression model\nWrite a model formula for a multiple linear regression model with an interaction term between two quantitative predictors, two categorical predictors, or one quantitative and one categorical predictor\nInterpret the intercept and slope coefficients in a multiple linear regression model with an interaction term\n\n\n\n\nChoose either the reading or the videos to go through before class.\n\nReading: Section 3.9.3 in the STAT 155 Notes\nVideo:\n\nInteraction variables\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html#learning-goals",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html#learning-goals",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nVisualize interactions between categorical and quantitative predictors using scatterplots and side-by-side or boxplots\nCritically think through whether an interaction term makes sense, or should be included in a multiple linear regression model\nWrite a model formula for a multiple linear regression model with an interaction term between two quantitative predictors, two categorical predictors, or one quantitative and one categorical predictor\nInterpret the intercept and slope coefficients in a multiple linear regression model with an interaction term"
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html#readings-and-videos",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html#readings-and-videos",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "",
    "text": "Choose either the reading or the videos to go through before class.\n\nReading: Section 3.9.3 in the STAT 155 Notes\nVideo:\n\nInteraction variables\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-1-translating-scientific-questions-into-statistical-questions",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-1-translating-scientific-questions-into-statistical-questions",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "Exercise 1: Translating scientific questions into statistical questions",
    "text": "Exercise 1: Translating scientific questions into statistical questions\n\nLook at the variables we have access to in the cleaned version of the data we read into R, and consider our first research question. How might we translate this question into a statistical one, that we could answer using the data we have available?\n\nThere is no one right answer to this! Brainstorm with your group.\n\nhead(campaigns)\n## # A tibble: 6 × 5\n##   wholename         district             votes incumbent spending\n##   &lt;chr&gt;             &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n## 1 Aengus O Snodaigh Dublin South Central  5591 No          28.9  \n## 2 Aidan McMahon     Louth                  294 No           0.557\n## 3 Aidan Ryan        Limerick East           19 No           2.24 \n## 4 Aine Ni Chonaill  Dublin South Central   926 No           4.08 \n## 5 Alan Dukes        Kildare South         4967 Yes         12.1  \n## 6 Alan Shatter      Dublin South          5363 Yes         11.9\n\n\nQuestion 2 (a) is a bit more specific than Question 1. Translate this question into a statistical one that can be answered using a simple linear regression model. Write out the model statement in \\(E[Y | X] = ...\\) notation that would answer this question, and note which regression coefficient you would interpret to provide you with an answer.\n\n\\[\nE[___ | ___] = ...\n\\]\n\nQuestion 2 (b) is also specific, and builds on Question 2 (a). Translate this question into a statistical one that can be answered using a multiple linear regression model. Write out the model statement in \\(E[Y | X] = ...\\) notation that would answer this question, and note which regression coefficient you would interpret to provide you with an answer.\n\n\\[\nE[___ | ___] = ...\n\\]"
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-2-visualizing-interaction",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-2-visualizing-interaction",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "Exercise 2: Visualizing Interaction",
    "text": "Exercise 2: Visualizing Interaction\n\nWrite R code to visualize the relationship between campaign spending and number of votes a candidate received. Include an aesthetic to distinguish this relationship between incumbents and challengers. Do not include lines of best fit from any statistical model on your plot at this point!\n\n\n# Visualization\n\n\nBased on your visualization from part (a), what are your answers to research questions 2 (a) and 2 (b)? Write your answer in 2-3 sentences, describing general trends you notice, suitable for a general audience.\nAdd lines of best fit from a statistical model that includes an interaction term between incumbent status and spending to your plot from part (a), using geom_smooth. Based on your updated plot, do you think including an interaction between incumbent status and spending in a multiple linear regression model would be meaningful in this context? Why or why not?\n\n\n# Visualization with lines of best fit"
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-3-fitting-and-interpreting-models-with-interaction-terms",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-3-fitting-and-interpreting-models-with-interaction-terms",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "Exercise 3: Fitting and interpreting models with interaction terms",
    "text": "Exercise 3: Fitting and interpreting models with interaction terms\n\nFit the regression model you wrote out in Exercise 1 (c). Report (do not interpret yet!) the regression coefficients below.\n\n\n# Model with interaction term\n\n\n(Intercept):\n\n\nincumbentYes:\n\n\nspending:\n\n\nincumbentYes:spending:\n\n\nUsing the coefficient estimates from part (a), write out two separate model statements, one for incumbents and one for challengers. Combine terms (using algebra) when you can! Hint: remember the indicator variables video!\n\n\nFor incumbents:\n\n\\[\nE[votes | spending] =\n\\]\n\nFor challengers:\n\n\\[\nE[votes | spending] =\n\\]\n\nInterpret the coefficient for incumbent in your interaction model, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Is this coefficient scientifically meaningful?\nWhen interpreting an interaction coefficient where one of the variables interacting is quantitative and one is categorical, it is often convenient to do so in separate sentences: interpret the slope for each category separately!\n\nInterpret the coefficient for the interaction term in your model, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\n\nBased on your interpretation in part (d), and the visualization you made including lines of best fit, do you think that including an interaction term for incumbent status and spending is meaningful, when predicting number of votes? Explain why or why not."
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-4-interactions-between-two-categorical-variables",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-4-interactions-between-two-categorical-variables",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "Exercise 4: Interactions between two categorical variables",
    "text": "Exercise 4: Interactions between two categorical variables\nLet’s return to our data on bike ridership. Suppose we are interested in the relationship between daily ridership (our response variable) and whether a user is a casual or registered rider and whether the day falls on a weekend. First, we need to create a binary variable indicating whether a user is a casual or registered rider.\n\n# Creating user variable, don't worry about syntax!\nnew_bikes &lt;- bikes %&gt;%\n  dplyr::select(riders_casual, riders_registered, weekend, temp_actual) %&gt;%\n  pivot_longer(cols = riders_casual:riders_registered, names_to = \"user\",\n               names_prefix = \"riders_\", values_to = \"rides\") %&gt;%\n  mutate(weekend = factor(weekend))\n\n\nFor each of our three relevant variables, weekend, user, and rides, classify them as quantitative or categorical.\n\n\nweekend:\n\n\nuser:\n\n\nrides:\n\n\nMake an appropriate visualization to explore the relationship between these three variables.\n\n\n# Visualization\n\n\nIs the relationship between ridership and weekend status the same for both registered and casual users? Explain why or why not, referencing the visualization you made in part (b).\nTo reflect what you observed in your visualization, fit a multiple linear regression model with an interaction term between weekend and user in our model of ridership.\n\n\n# Multiple linear regression model\n\n\nInterpret the interaction term from your model, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Just as in Exercise 3, you may find it useful to first write out multiple model statements for different categories defined by one of your categorical variables, and proceed from there!"
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-5-interactions-between-two-quantitative-variables",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html#exercise-5-interactions-between-two-quantitative-variables",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "Exercise 5: Interactions between two quantitative variables",
    "text": "Exercise 5: Interactions between two quantitative variables\nHere we’ll explore the relationship between price, milage, and age of a used car. Below is a scatterplot of mileage vs. price, colored by age:\n\ncars %&gt;% \n  ggplot(aes(x = milage, y = price, col = age)) +\n  geom_point(alpha = 0.5) + # make the points less opaque\n  scale_color_viridis_c(option = \"H\") + # a fun, colorblind-friendly palette!\n  theme_classic() # removes the gray background and grid\n\n\n\n\n\n\n\n\nIt’s a little difficult to tell what exactly is going on here. In particular, does the relationship between mileage and price vary with age of a used car? Let’s try adding some fitted lines for cars of different ages.\n\n# Ignore where the numbers in geom_abline() came from for now... we'll get there\ncars %&gt;% \n  ggplot(aes(x = milage, y = price, col = age)) +\n  geom_point(alpha = 0.5) + \n  scale_color_viridis_c(option = \"H\") + \n  theme_classic() +\n  geom_abline(slope = -6.558e-01 + 2.431e-02, intercept = 9.096e+04 -2.665e+03, col = \"black\") +\n  geom_abline(slope = -6.558e-01 + 10 * 2.431e-02, intercept = 9.096e+04 - 10 * 2.665e+03, col = \"blue\") +\n  geom_abline(slope = -6.558e-01 + 30 * 2.431e-02, intercept = 9.096e+04 - 30 * 2.665e+03, col = \"green\") +\n  ggtitle(\"Black: Age = 1yr, Blue: Age = 10yr, Green: Age = 30yr\")\n\n\n\n\n\n\n\n\n\nChallenge question: Based on the fitted lines in the plot above, anticipate what the signs (positive or negative) of the coefficients in the following interaction model will be:\n\n\\[\nE[price | age, milage] = \\beta_0 + \\beta_1 milage + \\beta_2 age + \\beta_3 milage:age\n\\] * \\(\\beta_0\\): Put your response here…\n\n\\(\\beta_1\\): Put your response here…\n\\(\\beta_2\\): Put your response here…\n\\(\\beta_3\\): Put your response here…\n\n\nFit a multiple linear regression model with an interaction term between milage and age in our model of used car price.\n\n\n# Multiple linear regression model\n\n\n\n# ... now do you see where the numbers in geom_abline() came from?\n\nAs before, we could choose distinct ages, and interpret the relationship between mileage and price for each of those groups separately. However, since age is quantitative and not categorical, this doesn’t quite give us the whole picture. Instead, we want to know how the relationship between mileage and price changes for each additional year old a car is. This is what the interaction coefficient estimates, when the interaction term is between two quantitative variables!\n\nInterpret the interaction term, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases."
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html#reflection",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html#reflection",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "Reflection",
    "text": "Reflection\nThrough the exercises above, you practiced visualizing, fitting, and interpreting multiple linear regression models with interaction terms between combinations of categorical and quantitative variables. Think about how the fitted lines looked in situations where you think there was a meaningful interaction taking place. How do you think the fitted lines would look if there was no meaningful interaction present? Explain your reasoning.\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/12-mlr-interaction-practice-notes.html#done",
    "href": "template_qmds/12-mlr-interaction-practice-notes.html#done",
    "title": "Multiple linear regression: interaction terms practice (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html",
    "href": "template_qmds/14-mlr-model-building-2-notes.html",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nExplain when variables are redundant or multicollinear.\nRelate redundancy and multicollinearity to coefficient estimates and \\(R^2\\).\nExplain why adjusted \\(R^2\\) is preferable to multiple \\(R^2\\) when comparing models with different numbers of predictors.\n\n\n\n\nToday is a day to discover ideas, so no readings or videos to go through before class, but if you want to see today’s ideas presented in a different way, you can take a look at the following after class:\n\nReading: Section 3.9.5 in the STAT 155 Notes\nVideo: Redundancy and Multicollinearity\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#learning-goals",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#learning-goals",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nExplain when variables are redundant or multicollinear.\nRelate redundancy and multicollinearity to coefficient estimates and \\(R^2\\).\nExplain why adjusted \\(R^2\\) is preferable to multiple \\(R^2\\) when comparing models with different numbers of predictors."
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#readings-and-videos",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#readings-and-videos",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "",
    "text": "Today is a day to discover ideas, so no readings or videos to go through before class, but if you want to see today’s ideas presented in a different way, you can take a look at the following after class:\n\nReading: Section 3.9.5 in the STAT 155 Notes\nVideo: Redundancy and Multicollinearity\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#exercise-1-modeling-bill-length-by-flipper-length",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#exercise-1-modeling-bill-length-by-flipper-length",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Exercise 1: Modeling bill length by flipper length",
    "text": "Exercise 1: Modeling bill length by flipper length\nWhat can a penguin’s flipper (arm) length tell us about their bill length? To answer this question, we’ll consider 3 of our models:\n\n\n\nmodel\npredictors\n\n\n\n\npenguin_model_1\nflipper_length_mm\n\n\npenguin_model_2\nflipper_length_cm\n\n\npenguin_model_3\nflipper_length_mm + flipper_length_cm\n\n\n\nPlots of the first two models are below:\n\nggplot(penguins, aes(y = bill_length_mm, x = flipper_length_mm)) + \n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE)\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'flipper_length_mm' not found\n\nggplot(penguins, aes(y = bill_length_mm, x = flipper_length_cm)) + \n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE)\n## Error in `geom_point()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'flipper_length_cm' not found\n\n\nBefore examining the model summaries, check your intuition. Do you think the penguin_model_2 R-squared will be less than, equal to, or more than that of penguin_model_1? Similarly, how do you think the penguin_model_3 R-squared will compare to that of penguin_model_1?\nCheck your intuition: Examine the R-squared values for the three penguin models and summarize how these compare.\n\n\nsummary(penguin_model_1)$r.squared\n## Error: object 'penguin_model_1' not found\nsummary(penguin_model_2)$r.squared\n## Error: object 'penguin_model_2' not found\nsummary(penguin_model_3)$r.squared\n## Error: object 'penguin_model_3' not found\n\n\nExplain why your observation in part b makes sense. Support your reasoning with a plot of just the 2 predictors: flipper_length_mm vs flipper_length_cm.\n\n\nOPTIONAL challenge: In summary(penguin_model_3), the flipper_length_cm coefficient is NA. Explain why this makes sense. HINT: Thinking about what you learned about controlling for covariates, why wouldn’t it make sense to interpret this coefficient? BONUS: For those of you that have taken MATH 236, this has to do with matrices that are not of full rank!"
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#exercise-2-incorporating-body_mass_g",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#exercise-2-incorporating-body_mass_g",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Exercise 2: Incorporating body_mass_g",
    "text": "Exercise 2: Incorporating body_mass_g\nIn this exercise you’ll consider 3 models of bill_length_mm:\n\n\n\nmodel\npredictors\n\n\n\n\npenguin_model_1\nflipper_length_mm\n\n\npenguin_model_4\nbody_mass_g\n\n\npenguin_model_5\nflipper_length_mm + body_mass_g\n\n\n\n\nWhich is the better predictor of bill_length_mm: flipper_length_mm or body_mass_g? Provide some numerical evidence.\npenguin_model_5 incorporates both flipper_length_mm and body_mass_g as predictors. Before examining a model summary, ask your gut: Will the penguin_model_5 R-squared be close to 0.35, close to 0.43, or greater than 0.6?\nCheck your intuition. Report the penguin_model_5 R-squared and summarize how this compares to that of penguin_model_1 and penguin_model_4.\nExplain why your observation in part c makes sense. Support your reasoning with a plot of the 2 predictors: flipper_length_mm vs body_mass_g."
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#exercise-3-redundancy-and-multicollinearity",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#exercise-3-redundancy-and-multicollinearity",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Exercise 3: Redundancy and Multicollinearity",
    "text": "Exercise 3: Redundancy and Multicollinearity\nThe exercises above have illustrated special phenomena in multivariate modeling:\n\ntwo predictors are redundant if they contain the same exact information\ntwo predictors are multicollinear if they are strongly associated (they contain very similar information) but are not completely redundant.\n\nRecall that we examined 5 models:\n\n\n\nmodel\npredictors\n\n\n\n\npenguin_model_1\nflipper_length_mm\n\n\npenguin_model_2\nflipper_length_cm\n\n\npenguin_model_3\nflipper_length_mm + flipper_length_cm\n\n\npenguin_model_4\nbody_mass_g\n\n\npenguin_model_5\nflipper_length_mm + body_mass_g\n\n\n\n\nWhich model had redundant predictors and which predictors were these?\nWhich model had multicollinear predictors and which predictors were these?\nIn general, what happens to the R-squared value if we add a redundant predictor to a model: will it decrease, stay the same, increase by a small amount, or increase by a significant amount?\nSimilarly, what happens to the R-squared value if we add a multicollinear predictor to a model: will it decrease, stay the same, increase by a small amount, or increase by a significant amount?"
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#exercise-4-considerations-for-strong-models",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#exercise-4-considerations-for-strong-models",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Exercise 4: Considerations for strong models",
    "text": "Exercise 4: Considerations for strong models\nLet’s dive deeper into important considerations when building a strong model. We’ll use a subset of the penguins data for exploring these ideas.\n\n# For illustration purposes only, take a sample of 10 penguins.\n# We'll discuss this code later in the course!\nset.seed(155)\npenguins_small &lt;- sample_n(penguins, size = 10) %&gt;%\n  mutate(flipper_length_mm = jitter(flipper_length_mm))\n## Error in `mutate()`:\n## ℹ In argument: `flipper_length_mm = jitter(flipper_length_mm)`.\n## Caused by error:\n## ! object 'flipper_length_mm' not found\n\nConsider 3 models of bill length:\n\n# A model with one predictor (flipper_length_mm)\npoly_mod_1 &lt;- lm(bill_length_mm ~ flipper_length_mm, penguins_small)\n## Error in eval(mf, parent.frame()): object 'penguins_small' not found\n\n# A model with two predictors (flipper_length_mm and flipper_length_mm^2)\npoly_mod_2 &lt;- lm(bill_length_mm ~ poly(flipper_length_mm, 2), penguins_small)\n## Error in eval(mf, parent.frame()): object 'penguins_small' not found\n\n# A model with nine predictors (flipper_length_mm, flipper_length_mm^2, ... on up to flipper_length_mm^9)\npoly_mod_9 &lt;- lm(bill_length_mm ~ poly(flipper_length_mm, 9), penguins_small)\n## Error in eval(mf, parent.frame()): object 'penguins_small' not found\n\n\nBefore doing any analysis, which of the three models do you think will be best?\nCalculate the R-squared values of these 3 models. Which model do you think is best?\n\n\nsummary(poly_mod_1)$r.squared\n## Error: object 'poly_mod_1' not found\nsummary(poly_mod_2)$r.squared\n## Error: object 'poly_mod_2' not found\nsummary(poly_mod_9)$r.squared\n## Error: object 'poly_mod_9' not found\n\n\nCheck out plots depicting the relationship estimated by these 3 models. Which model do you think is best?\n\n\n# A plot of model 1\nggplot(penguins_small, aes(y = bill_length_mm, x = flipper_length_mm)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE)\n## Error: object 'penguins_small' not found\n\n\n# A plot of model 2\nggplot(penguins_small, aes(y = bill_length_mm, x = flipper_length_mm)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), se = FALSE)\n## Error: object 'penguins_small' not found\n\n\n# A plot of model 9\nggplot(penguins_small, aes(y = bill_length_mm, x = flipper_length_mm)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", formula = y ~ poly(x, 9), se = FALSE)\n## Error: object 'penguins_small' not found"
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#exercise-5-reflecting-on-these-investigations",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#exercise-5-reflecting-on-these-investigations",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Exercise 5: Reflecting on these investigations",
    "text": "Exercise 5: Reflecting on these investigations\n\nList 3 of your favorite foods. Now imagine making a dish that combines all of these foods. Do you think it would taste good?\nToo many good things doesn’t make necessarily make a better thing. Model 9 demonstrates that it’s always possible to get a perfect R-squared of 1, but there are drawbacks to putting more and more predictors into our model. Answer the following about model 9:\n\nHow easy would it be to interpret this model?\nWould you say that this model captures the general trend of the relationship between bill_length_mm and flipper_length_mm?\nHow well do you think this model would generalize to penguins that were not included in the penguins_small sample? For example, would you expect these new penguins to fall on the wiggly model 9 curve?"
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#exercise-6-overfitting",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#exercise-6-overfitting",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Exercise 6: Overfitting",
    "text": "Exercise 6: Overfitting\nModel 9 provides an example of a model that is overfit to our sample data. That is, it picks up the tiny details of our data at the cost of losing the more general trends of the relationship of interest. Check out the following xkcd comic. Which plot pokes fun at overfitting?\n\nSome other goodies:"
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#exercise-7-questioning-r-squared",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#exercise-7-questioning-r-squared",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Exercise 7: Questioning R-squared",
    "text": "Exercise 7: Questioning R-squared\nZooming out, explain some limitations of relying on R-squared to measure the strength / usefulness of a model."
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#exercise-8-adjusted-r-squared",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#exercise-8-adjusted-r-squared",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Exercise 8: Adjusted R-squared",
    "text": "Exercise 8: Adjusted R-squared\nWe’ve seen that, unless a predictor is redundant with another, R-squared will increase. Even if that predictor is strongly multicollinear with another. Even if that predictor isn’t a good predictor! Thus if we only look at R-squared we might get overly greedy. We can check our greedy impulses a few ways. We take a more in depth approach in STAT 253, but one quick alternative is reported right in our model summary() tables. Adjusted R-squared includes a penalty for incorporating more and more predictors. Mathematically (where \\(n\\) is the sample size and \\(p\\) is the number of non-intercept coefficients):\n\\[\n\\text{Adjusted } R^2 = 1 - (1 - R^2) \\left( \\frac{n-1}{n-p-1} \\right)\n\\]\nThus unlike R-squared, Adjusted R-squared can decrease when the information that a predictor contributes to a model isn’t enough to offset the complexity it adds to that model. Consider two models:\n\nexample_1 &lt;- lm(bill_length_mm ~ species, penguins)\n## Error in eval(predvars, data, env): object 'bill_length_mm' not found\nexample_2 &lt;- lm(bill_length_mm ~ species + island, penguins)\n## Error in eval(predvars, data, env): object 'bill_length_mm' not found\n\n\nCheck out the summaries for the 2 example models. In general, how does a model’s Adjusted R-squared compare to the R-squared? Is it greater, less than, or equal to the R-squared?\nHow did the R-squared change from example model 1 to model 2? How did the Adjusted R-squared change?\nExplain what it is about island that resulted in a decreased Adjusted R-squared. Note: it’s not necessarily the case that island is a bad predictor on its own!"
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#reflection",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#reflection",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Reflection",
    "text": "Reflection\nToday we looked at some cautions surrounding indiscriminately adding variables to a model. Summarize key takeaways.\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/14-mlr-model-building-2-notes.html#done",
    "href": "template_qmds/14-mlr-model-building-2-notes.html#done",
    "title": "Multiple linear regression: model building (part 2) (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html",
    "href": "template_qmds/16-logistic-univariate-notes.html",
    "title": "Simple logistic regression (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nExplain the differences between linear regression and logistic regression for modeling binary outcomes\nConstruct simple logistic regression models in R\nInterpret coefficients in simple logistic regression models\nUse simple logistic regression models to make predictions\nDescribe the form (shape) of relationships on the log odds, odds, and probability scales\n\n\n\n\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 4.1-4.3 in the STAT 155 Notes\nVideo: Logistic regression (slides)\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#learning-goals",
    "href": "template_qmds/16-logistic-univariate-notes.html#learning-goals",
    "title": "Simple logistic regression (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nExplain the differences between linear regression and logistic regression for modeling binary outcomes\nConstruct simple logistic regression models in R\nInterpret coefficients in simple logistic regression models\nUse simple logistic regression models to make predictions\nDescribe the form (shape) of relationships on the log odds, odds, and probability scales"
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#readings-and-videos",
    "href": "template_qmds/16-logistic-univariate-notes.html#readings-and-videos",
    "title": "Simple logistic regression (Notes)",
    "section": "",
    "text": "Choose either the reading or the videos to go through before class.\n\nReading: Sections 4.1-4.3 in the STAT 155 Notes\nVideo: Logistic regression (slides)\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#exercise-1-exploring-age",
    "href": "template_qmds/16-logistic-univariate-notes.html#exercise-1-exploring-age",
    "title": "Simple logistic regression (Notes)",
    "section": "Exercise 1: Exploring age",
    "text": "Exercise 1: Exploring age\nDid younger passengers tend to have higher survival rates than older passengers?\nVisualizing the relationship between a binary response and a quantitative predictor can be tricky. We will take a few approaches here.\n\nCreate a boxplot where one box corresponds to the age distribution of survivors and the second to that of non-survivors.\nCreate density plots with separate colors for the survivors and non-survivors.\nThe remainder of the code below creates a plot of the fraction who survived at each age. (Since we have a large data set and multiple (though sometimes not many) observations at most ages, we can manually calculate the survival fraction.\n\nAfter inspecting the plots, summarize what you learn.\n\n# Create a boxplot\n# Note that you'll need to force R to view Survived as a binary categorical variable by using x = factor(Survived) instead of just x = Survived in the aes() part of your plot\n\n\n# Create a density plot (you'll need to use factor(Survived) again)\n\n\n# Use the code below to create a plot of the fraction who survived at each age\ntitanic_summ &lt;- titanic %&gt;% \n    group_by(Age) %&gt;%\n    summarize(frac_survived = mean(Survived))\n\nggplot(titanic_summ, aes(x = Age, y = frac_survived)) +\n    geom_point() +\n    geom_smooth(se = FALSE)"
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#exercise-2-exploring-sex-and-ticket-class",
    "href": "template_qmds/16-logistic-univariate-notes.html#exercise-2-exploring-sex-and-ticket-class",
    "title": "Simple logistic regression (Notes)",
    "section": "Exercise 2: Exploring sex and ticket class",
    "text": "Exercise 2: Exploring sex and ticket class\nWere males or females more likely to survive? Did 1st class passengers tend to survive more than 2nd and 3rd class passengers?\nThe code below creates plots that allow us to explore how Sex and PClass relate to survival. The first two plots are standard bar plots that use color to indicate what fraction of each group survived. The last two plots are mosaic plots that are much like the standard bar plots, but the width of the bars reflects the distribution of the x-axis variable. (The widest bar is the most prevalent category.)\nSummarize what you learn about the relationship between sex, ticket class, and survival.\n\n# Standard bar plots\nggplot(titanic, aes(x = Sex, fill = factor(Survived))) +\n    geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nggplot(titanic, aes(x = PClass, fill = factor(Survived))) +\n    geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n# Mosaic plots\nggplot(data = titanic %&gt;% mutate(Survived = as.factor(Survived))) +\n    geom_mosaic(aes(x = product(Sex), fill = Survived))\n## Error in geom_mosaic(aes(x = product(Sex), fill = Survived)): could not find function \"geom_mosaic\"\n\nggplot(data = titanic %&gt;% mutate(Survived = as.factor(Survived))) +\n    geom_mosaic(aes(x = product(PClass), fill = Survived))\n## Error in geom_mosaic(aes(x = product(PClass), fill = Survived)): could not find function \"geom_mosaic\""
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#exercise-3-linear-regression-model",
    "href": "template_qmds/16-logistic-univariate-notes.html#exercise-3-linear-regression-model",
    "title": "Simple logistic regression (Notes)",
    "section": "Exercise 3: Linear regression model",
    "text": "Exercise 3: Linear regression model\nFor now we will focus on exploring the relationship between (ticket) class and survival.\nLet’s tabulate survival across classes. We can tabulate across two variables by providing both variables to count():\n\ntitanic %&gt;% \n    count(PClass, Survived)\n## # A tibble: 7 × 3\n##   PClass Survived     n\n##   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n## 1 1st           0   129\n## 2 1st           1   193\n## 3 2nd           0   160\n## 4 2nd           1   119\n## 5 3rd           0   573\n## 6 3rd           1   138\n## 7 &lt;NA&gt;          0     1\n\n\nUse the count() output to fill in the following contingency table:\n\n\n\n\nClass\nDied\nSurvived\nTotal\n\n\n\n\n1st Class\n___\n___\n___\n\n\n2nd Class\n___\n___\n___\n\n\n3rd Class\n___\n___\n___\n\n\nTotal\n___\n___\n___\n\n\n\n\nUsing your table, estimate the following:\n\nthe probability of surviving among 1st class passengers\nthe probability of surviving among 2nd class passengers\nthe probability of surviving among 3rd class passengers\nthe difference in the probability of surviving, comparing 2nd class passengers to 1st class passengers (i.e., how much lower is the probability of 2nd class passengers as compared to 1st class passengers?)\nthe difference in the probability of surviving, comparing 3rd class passengers to 1st class passengers (i.e., how much lower is the probability of 3rd class passengers as compared to 1st class passengers?)\n\nAfter fitting the linear regression model below, write out the model formula using correct notation. Explain carefully what it means to talk about the expected/average value of a binary variable.\n\n\nlin_mod &lt;- lm(Survived ~ PClass, data = titanic)\nsummary(lin_mod)\n## \n## Call:\n## lm(formula = Survived ~ PClass, data = titanic)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -0.5994 -0.1941 -0.1941  0.4006  0.8059 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.59938    0.02468  24.284  &lt; 2e-16 ***\n## PClass2nd   -0.17286    0.03623  -4.772 2.03e-06 ***\n## PClass3rd   -0.40529    0.02975 -13.623  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4429 on 1309 degrees of freedom\n##   (1 observation deleted due to missingness)\n## Multiple R-squared:  0.1315, Adjusted R-squared:  0.1302 \n## F-statistic: 99.09 on 2 and 1309 DF,  p-value: &lt; 2.2e-16\n\n\nWrite an interpretation of each of the coefficients in your linear regression model. How do your coefficient estimates compare to your answers in part b?"
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#exercise-4-logistic-regression-model-categorical-predictor",
    "href": "template_qmds/16-logistic-univariate-notes.html#exercise-4-logistic-regression-model-categorical-predictor",
    "title": "Simple logistic regression (Notes)",
    "section": "Exercise 4: Logistic regression model (categorical predictor)",
    "text": "Exercise 4: Logistic regression model (categorical predictor)\n\nRefer back to your contingency table from Exercise 3a. Using your table, estimate the following:\n\nthe odds of surviving among 1st class passengers\nthe odds of surviving among 2nd class passengers\nthe odds of surviving among 3rd class passengers\nthe ratio of the odds of surviving, comparing 2nd class passengers to 1st class passengers (i.e., how many times higher/lower is the odds of survival among 2nd class passengers as compared to 1st class passengers?)\nthe ratio of the odds of surviving, comparing 3rd class passengers to 1st class passengers\n\nAfter fitting the logistic regression model below, write out the model formula using correct notation.\n\n\nlog_mod &lt;- glm(Survived ~ PClass, data = titanic, family = \"binomial\")\ncoef(summary(log_mod))\n##               Estimate Std. Error    z value     Pr(&gt;|z|)\n## (Intercept)  0.4028778  0.1137246   3.542574 3.962427e-04\n## PClass2nd   -0.6989281  0.1660923  -4.208071 2.575600e-05\n## PClass3rd   -1.8265098  0.1480705 -12.335410 5.839072e-35\n\n\nWrite an interpretation of each of the exponentiated coefficients in your logistic regression model. Think carefully about what we are modeling when we fit a logistic regression model. How do these exponentiated coefficient estimates compare to your answers in part a?"
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#exercise-5-logistic-regression-model-quantitative-predictor",
    "href": "template_qmds/16-logistic-univariate-notes.html#exercise-5-logistic-regression-model-quantitative-predictor",
    "title": "Simple logistic regression (Notes)",
    "section": "Exercise 5: Logistic regression model (quantitative predictor)",
    "text": "Exercise 5: Logistic regression model (quantitative predictor)\nNow we will explore how to interpret a quantitative predictor in a logistic regression model.\n\nAfter fitting the logistic regression model below, write out the model formula using correct notation.\n\n\nlog_mod &lt;- glm(Survived ~ Age, data = titanic, family = \"binomial\")\ncoef(summary(log_mod))\n##                Estimate Std. Error    z value   Pr(&gt;|z|)\n## (Intercept) -0.08142783 0.17386170 -0.4683483 0.63953556\n## Age         -0.00879462 0.00523158 -1.6810637 0.09275054\n\n\nWrite an interpretation of each of the exponentiated coefficients in this logistic regression model."
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#exercise-6-linear-vs.-logistic-modeling",
    "href": "template_qmds/16-logistic-univariate-notes.html#exercise-6-linear-vs.-logistic-modeling",
    "title": "Simple logistic regression (Notes)",
    "section": "Exercise 6: Linear vs. logistic modeling",
    "text": "Exercise 6: Linear vs. logistic modeling\nTo highlight a key difference between linear vs. logistic modeling, consider the following linear and logistic regression models of survival with sex and age as predictors in addition to ticket class.\n\nlin_mod2 &lt;- lm(Survived ~ PClass + Sex + Age, data = titanic)\ncoef(summary(lin_mod2))\n##                 Estimate  Std. Error    t value     Pr(&gt;|t|)\n## (Intercept)  1.130522829 0.051940872  21.765573 8.158449e-82\n## PClass2nd   -0.207433817 0.039239825  -5.286308 1.637737e-07\n## PClass3rd   -0.393344488 0.037709874 -10.430809 7.001373e-24\n## Sexmale     -0.501325667 0.029419802 -17.040416 2.697807e-55\n## Age         -0.006004789 0.001105949  -5.429536 7.633977e-08\n\nlog_mod2 &lt;- glm(Survived ~ PClass + Sex + Age, data = titanic, family = \"binomial\")\ncoef(summary(log_mod2))\n##                Estimate  Std. Error    z value     Pr(&gt;|z|)\n## (Intercept)  3.75966210 0.397567324   9.456668 3.179129e-21\n## PClass2nd   -1.29196240 0.260075781  -4.967638 6.777324e-07\n## PClass3rd   -2.52141915 0.276656805  -9.113888 7.948131e-20\n## Sexmale     -2.63135683 0.201505379 -13.058494 5.684093e-39\n## Age         -0.03917681 0.007616218  -5.143868 2.691392e-07\n\n\nUse the linear regression model to predict the probability of survival for Rose (a 17 year old female in 1st class) and Jack (a 20 year old male in 3rd class). Show your work.\nNow use the logistic regression model to predict the survival probability for Rose and Jack. Show your work. (Hint: use the logistic regression model to obtain the predicted log odds, exponentiate to get the odds, and then convert to probability.)\nComment on differences that you notice in the predictions from parts a and b."
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#reflection",
    "href": "template_qmds/16-logistic-univariate-notes.html#reflection",
    "title": "Simple logistic regression (Notes)",
    "section": "Reflection",
    "text": "Reflection\nWhat binary outcomes might be relevant in your project? What predictor(s) could be relevant in a logistic regression model for that outcome?\n\nResponse: Put your response here."
  },
  {
    "objectID": "template_qmds/16-logistic-univariate-notes.html#done",
    "href": "template_qmds/16-logistic-univariate-notes.html#done",
    "title": "Simple logistic regression (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html",
    "href": "template_qmds/18-sampling-normal-notes.html",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "",
    "text": "Recognize the difference between a population parameter and a sample estimate.\nReview the Normal probability model, a tool we’ll need to turn information in our sample data into inferences about the broader population.\nExplore the ideas of randomness, sampling distributions, and standard error through a class experiment. (We’ll define these more formally in the next class.)\n\n\n\n\nPlease do the following videos and reading before class.\n\nReading: Section 6 Introduction, and Section 6.6 in the STAT 155 Notes\nVideo 1: exploration vs inference\nVideo 2: Normal probability model"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#learning-goals",
    "href": "template_qmds/18-sampling-normal-notes.html#learning-goals",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "",
    "text": "Recognize the difference between a population parameter and a sample estimate.\nReview the Normal probability model, a tool we’ll need to turn information in our sample data into inferences about the broader population.\nExplore the ideas of randomness, sampling distributions, and standard error through a class experiment. (We’ll define these more formally in the next class.)"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#readings-and-videos",
    "href": "template_qmds/18-sampling-normal-notes.html#readings-and-videos",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "",
    "text": "Please do the following videos and reading before class.\n\nReading: Section 6 Introduction, and Section 6.6 in the STAT 155 Notes\nVideo 1: exploration vs inference\nVideo 2: Normal probability model"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#exercise-1-using-the-normal-model",
    "href": "template_qmds/18-sampling-normal-notes.html#exercise-1-using-the-normal-model",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Exercise 1: Using the Normal model",
    "text": "Exercise 1: Using the Normal model\nSuppose that the speeds of cars on a highway, in miles per hour, can be reasonably represented by the Normal model with a mean of 55mph and a standard deviation of 5mph from car to car:\n\\[\nX \\sim N(55, 5^2)\n\\]\n\nshaded_normal(mean = 55, sd = 5)\n\n\n\n\n\n\n\n\n\nProvide the (approximate) range of the middle 68% of speeds, and shade in the corresponding region on your Normal curve. NOTE: a is the lower end of the range and b is the upper end.\n\n\nshaded_normal(mean = 55, sd = 5, a = ___, b = ___)\n## Error in parse(text = input): &lt;text&gt;:1:39: unexpected input\n## 1: shaded_normal(mean = 55, sd = 5, a = __\n##                                           ^\n\n\nUse the 68-95-99.7 rule to estimate the probability that a car’s speed exceeds 60mph.\n\n\nYour response here\n\n\n# Visualize\nshaded_normal(mean = 55, sd = 5, a = 60)\n\n\n\n\n\n\n\n\n\nWhich of the following is the correct range for the probability that a car’s speed exceeds 67mph? Explain your reasoning.\n\n\nless than 0.0015\nbetween 0.0015 and 0.025\nbetween 0.025 and 0.16\ngreater than 0.16\n\n\nExplain your reasoning here\n\n\n# Visualize\nshaded_normal(mean = 55, sd = 5, a = 67)"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#exercise-2-z-scores",
    "href": "template_qmds/18-sampling-normal-notes.html#exercise-2-z-scores",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Exercise 2: Z-scores",
    "text": "Exercise 2: Z-scores\nInherently important to all of our calculations above is how many standard deviations a value “X” is from the mean.\nThis distance is called a Z-score and can be calculated as follows:\n\\[\n\\text{Z-score} = \\frac{X - \\text{mean}}{\\text{sd}}\n\\]\nFor example (from Exercise 1), if I’m traveling 40 miles an hour, my Z-score is -3. That is, my speed is 3 standard deviations below the average speed:\n\n(40 - 55) / 5\n## [1] -3\n\n\nConsider 2 other drivers. Both drivers are speeding. Who do you think is speeding more, relative to the distributions of speed in their area?\n\nDriver A is traveling at 60mph on the highway where speeds are N(55, 5^2) and the speed limit is 55mph.\nDriver B is traveling at 36mph on a residential road where speeds are N(30, 3^2) and the speed limit is 30mph.\n\n\n\nPut your best guess (hypothesis) here\n\n\nCalculate the Z-scores for Drivers A and B.\n\n\n# Driver A\n\n\n# Driver B\n\n\nNow, based on the Z-scores, who is speeding more? NOTE: The below plots might provide some insights.\n\n\n# Driver A\nshaded_normal(mean = 55, sd = 5) + \n  geom_vline(xintercept = 60)\n\n\n\n\n\n\n\n\n# Driver B\nshaded_normal(mean = 30, sd = 3) + \n  geom_vline(xintercept = 36)  \n\n\n\n\n\n\n\n\n\nYour response here"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#exercise-3-parameter-vs-estimate",
    "href": "template_qmds/18-sampling-normal-notes.html#exercise-3-parameter-vs-estimate",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Exercise 3: Parameter vs estimate",
    "text": "Exercise 3: Parameter vs estimate\nIt’s important to note that this dataset is by no means a comprehensive collection of films and their review scores–it does not contain every film that was released from 2014-2015, nor films released outside of that date range. The review scores are also frozen in time–all of these films have almost certainly accumulated additional reviews since the data were first collected.\nHowever, our stated goal is to make inferences about the overarching relationship between critic reviews and user reviews for all films (relatedly, we may want to use our model to make predictions about how user reviews are affected by critic reviews for films that may not even exist yet!). Can we actually make these inferences/predictions about a potentially infinite collection of films when all we have is a fairly limited subset of these?\n\nPopulations and Samples\nThis question points to two of the most important concepts in the field of statistical inference: populations and samples. Statisticians have many different ways of defining a population (depending on the questions they are asking), but for the purposes of this exercise, we can think of the population as the set of all possible films and all possible review scores that have been or could be catalogued on RottenTomatoes.\nOur dataset of 146 films is considered a sample of this population. A sample is simply a subset of observations taken from that population.\n\n\n\n\n\n\nSampling Criteria\n\n\n\n\n\nWhen we take a sample of data from a population, there is always some set of criteria used to determine how a sample is taken. This could be as simple as “we randomly selected 1% of all films catalogued on RottenTomatoes as of 4/1/2025”, or a more complex set of specific criteria (for this dataset, the sample was taken by selecting all films that had tickets for sale on Fandango on 8/24/2015, then further filtering to include films that have a Rotten Tomatoes rating, a RT User rating, a Metacritic score, a Metacritic User score, an IMDb score, and at least 30 fan reviews on Fandango.)\n\n\n\n\n\n“True” parameters versus estimates\nIn order to conduct statistical inference using linear regression, we must assume that there is some true, underlying, fixed intercept and slope \\(\\beta_0\\) and \\(\\beta_1\\), that describe the true linear relationship in the overall population that we’re interested in.\nIf we are modeling the relationship between UserScore and CriticScore on RottenTomatoes, The “true” underlying model we assume is thus:\n\\[\nUserScore_i = \\beta_0 + \\beta_1 CriticScore_i + e_i\n\\]\nHowever, the “true” values of \\(\\beta_0\\) and \\(\\beta_1\\) are typically impossible to know, because knowing them requires access to our entire population of interest (in this case, the review scores for every film that has been or will be released). When we fit a regression model using the sample that we do have, we are actually obtaining estimates of those true population parameters (note the notation change of putting a \\(\\hat{ }\\) on top of the Betas, to indicate that this is an estimate):\n\\[\nE[UserScore \\mid CriticScore] = \\hat{\\beta}_0 + \\hat{\\beta}_1 CriticScore\n\\]\nwhere our estimates are given by our model as \\(\\hat{\\beta}_0 = 32.3%\\), \\(\\hat{\\beta}_1 = 0.52%\\)\nFor the sake of this activity, let’s assume that these estimates are identical to the true population parameters.\n🚩🚩🚩 HOWEVER, be very careful not to make this assumption in other models you encounter.For this dataset, recall the specific sampling criteria that were used, which means these 146 films likely aren’t representative of the full population of films we’re interested in. This means that the estimates we obtained probably don’t match the true population parameters–they may or may not be close, but we don’t know for certain! 🚩🚩🚩\nBelow, we’ll simulate how parameter estimates are impacted by taking different samples. You’ll each take a random sample of 10 films in the dataset, and we’ll see if we can recover the presumed population parameters (i.e., the coefficient estimates we obtained from our model using all 146 films that were initially sampled).\nFirst, fill in your intuition below:\n\nDo you think every student will get the same set of 10 films?\n\n\nYour response here\n\n\nDo you think that your coefficient estimates will be the same as your neighbors’?\n\n\nYour responses here"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#exercise-4-random-sampling",
    "href": "template_qmds/18-sampling-normal-notes.html#exercise-4-random-sampling",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Exercise 4: Random sampling",
    "text": "Exercise 4: Random sampling\n\nUse the sample_n() function to take a random sample of 2 films\n\n\n# Try running the following chunk A FEW TIMES\nsample_n(fandango, size = 2, replace = FALSE)\n## Error in sample_n(fandango, size = 2, replace = FALSE): could not find function \"sample_n\"\n\nReflect:\n\nHow do your results compare to your neighbors’?\n\n\nYour response here\n\n\nWhat is the role of size = 2? HINT: Remember you can look at function documentation by running ?sample_n in the console!\n\n\nYour response here\n\n\nWhat is the role of replace = FALSE? HINT: Remember you can look at function documentation by running ?sample_n in the console!\n\n\nYour response here\n\n\nNow, “set the seed” to 155 and re-try your sampling.\n\n\n# Try running the following FULL chunk A FEW TIMES\nset.seed(155)\nsample_n(fandango, size = 2, replace = FALSE)\n## Error in sample_n(fandango, size = 2, replace = FALSE): could not find function \"sample_n\"\n\nWhat changed?\n\nYour response here"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#exercise-5-take-your-own-sample",
    "href": "template_qmds/18-sampling-normal-notes.html#exercise-5-take-your-own-sample",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Exercise 5: Take your own sample",
    "text": "Exercise 5: Take your own sample\nThe underlying random number generator plays a role in the random sample we happen to get. If we set.seed(some positive integer) before taking a random sample, we’ll get the same results.\nThis reproducibility is important:\n\nwe get the same results every time we render our qmd\nwe can share our work with others & ensure they get our same answers\nit wouldn’t be great if you submitted your work to, say, a journal and weren’t able to back up / confirm / reproduce your results!\n\nFollow the chunks below to obtain and use your own unique sample.\n\n# DON'T SKIP THIS STEP! \n# Set the random number seed to the digits of your own phone number (just the numbers)\nset.seed()\n## Error in set.seed(): argument \"seed\" is missing, with no default\n\n# Take a sample of 10 films\nmy_sample &lt;- sample_n(fandango, size = 10, replace = FALSE)\n## Error in sample_n(fandango, size = 10, replace = FALSE): could not find function \"sample_n\"\nmy_sample                       \n## Error: object 'my_sample' not found\n\n\n# Plot the relationship of UserScore with CriticScore among your sample\nmy_sample %&gt;% \n  ggplot(aes(y = userscore_rt, x = criticscore_rt)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n## Error in my_sample %&gt;% ggplot(aes(y = userscore_rt, x = criticscore_rt)): could not find function \"%&gt;%\"\n\n\n# Model the relationship among your sample\nmy_model &lt;- lm(userscore_rt ~ criticscore_rt, data = my_sample)\n## Error in eval(mf, parent.frame()): object 'my_sample' not found\ncoef(summary(my_model))[,1]\n## Error: object 'my_model' not found\n\nREPORT YOUR WORK\nLog your intercept and slope sample estimates in this survey."
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#exercise-6-sampling-variation",
    "href": "template_qmds/18-sampling-normal-notes.html#exercise-6-sampling-variation",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Exercise 6: Sampling variation",
    "text": "Exercise 6: Sampling variation\nRecall that we are assuming the population parameters are equal to the estimates we obtained from the model we fit using the initial sample of 146 films:\n\\[\nE[UserScore \\mid CriticScore] = 32.3 + 0.52 CriticScore\n\\]\nLet’s explore how our sample estimates of these parameters varied from student to student:\n\n# Import the experiment results\nlibrary(gsheet)\n## Error in library(gsheet): there is no package called 'gsheet'\nresults &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/11OT1VnLTTJasp5BHSKulgJiCbSLiutv8mKDOfvvXZSo/edit?usp=sharing')\n## Error in gsheet2tbl(\"https://docs.google.com/spreadsheets/d/11OT1VnLTTJasp5BHSKulgJiCbSLiutv8mKDOfvvXZSo/edit?usp=sharing\"): could not find function \"gsheet2tbl\"\n\nPlot each student’s sample estimate of the model line (gray). How do these compare to the assumed population model (red)?\n\nfandango %&gt;% \n  ggplot(aes(y = userscore_rt, x = criticscore_rt)) +\n  geom_abline(data = results, aes(intercept = sample_intercept, slope = sample_slope, linetype=section), color = \"gray\") + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n## Error in fandango %&gt;% ggplot(aes(y = userscore_rt, x = criticscore_rt)): could not find function \"%&gt;%\""
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#exercise-7-sample-intercepts",
    "href": "template_qmds/18-sampling-normal-notes.html#exercise-7-sample-intercepts",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Exercise 7: Sample intercepts",
    "text": "Exercise 7: Sample intercepts\nLet’s focus on just the sample estimates of the intercept parameter:\n\nresults %&gt;% \n  ggplot(aes(x = sample_intercept)) + \n  geom_density() + \n  geom_vline(xintercept = 32.3, color = \"red\")\n## Error in results %&gt;% ggplot(aes(x = sample_intercept)): could not find function \"%&gt;%\"\n\nComment on the shape, center, and spread of these sample estimates and how they relate to the (assumed) population intercept (red line).\n\nYour response here"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#exercise-8-slopes",
    "href": "template_qmds/18-sampling-normal-notes.html#exercise-8-slopes",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Exercise 8: Slopes",
    "text": "Exercise 8: Slopes\nSuppose we were to construct a density plot of the sample estimates of the criticscore_rt coefficient (i.e. the slopes).\n\nIntuitively, what shape do you think this plot will have?\n\n\nYour response here\n\n\nIntuitively, around what value do you think this plot will be centered?\n\n\nYour response here\n\n\nCheck your intuition:\n\n\nresults %&gt;% \n  ggplot(aes(x = sample_slope)) + \n  geom_density() + \n  geom_vline(xintercept = 0.52, color = \"red\")\n## Error in results %&gt;% ggplot(aes(x = sample_slope)): could not find function \"%&gt;%\"\n\n\nThinking back to the 68-95-99.7 rule, visually approximate the standard deviation among the sample slopes.\n\n\nYour response here"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#exercise-9-standard-error",
    "href": "template_qmds/18-sampling-normal-notes.html#exercise-9-standard-error",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Exercise 9: Standard error",
    "text": "Exercise 9: Standard error\nYou’ve likely observed that the typical or mean slope estimate is roughly equal to the (assumed) population slope parameter of 0.52:\n\nresults %&gt;% \n  summarize(mean(sample_slope))\n## Error in results %&gt;% summarize(mean(sample_slope)): could not find function \"%&gt;%\"\n\nThus the standard deviation of the slope estimates measures how far we might expect an estimate to fall from the (assumed) population slope parameter.\nThat is, it measures the typical or standard error in our sample estimates:\n\nresults %&gt;% \n  summarize(sd(sample_slope))\n## Error in results %&gt;% summarize(sd(sample_slope)): could not find function \"%&gt;%\"\n\n\nRecall your sample estimate of the slope. How far is it from the population slope, 0.52?\n\n\nHow many standard errors does your estimate fall from the population slope? That is, what’s your Z-score?\n\n\nReflecting upon your Z-score, do you think your sample estimate was one of the “lucky” ones, or one of the “unlucky” ones?\n\n\nYour response here"
  },
  {
    "objectID": "template_qmds/18-sampling-normal-notes.html#done",
    "href": "template_qmds/18-sampling-normal-notes.html#done",
    "title": "The Normal model & sampling variation (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html",
    "href": "template_qmds/19-sampling-dist-clt-notes.html",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "",
    "text": "Let \\(\\beta\\) be some population parameter and \\(\\hat{\\beta}\\) be a sample estimate of \\(\\beta\\). Our goals for the day are to:\n\nuse simulation to solidify our understanding of sampling distributions and standard errors\nexplore the appropriateness of the Central Limit Theorem in approximating a sampling distribution\nexplore the impact of sample size on sampling distributions and standard errors\n\n\n\n\nPlease watch the following videos and readings before class:\n\nReading: Section 6.7 in the STAT 155 Notes\nVideo 1: sampling distributions\nVideo 2: Central Limit Theorem"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#learning-goals",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#learning-goals",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "",
    "text": "Let \\(\\beta\\) be some population parameter and \\(\\hat{\\beta}\\) be a sample estimate of \\(\\beta\\). Our goals for the day are to:\n\nuse simulation to solidify our understanding of sampling distributions and standard errors\nexplore the appropriateness of the Central Limit Theorem in approximating a sampling distribution\nexplore the impact of sample size on sampling distributions and standard errors"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#readings-and-videos",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#readings-and-videos",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "",
    "text": "Please watch the following videos and readings before class:\n\nReading: Section 6.7 in the STAT 155 Notes\nVideo 1: sampling distributions\nVideo 2: Central Limit Theorem"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-1-500-samples-of-size-10",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-1-500-samples-of-size-10",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 1: 500 samples of size 10",
    "text": "Exercise 1: 500 samples of size 10\nRecall that we can sample 10 counties using sample_n():\n\n# Run this chunk a few times to explore the different samples you get\ncounty_clean %&gt;% \n  sample_n(size = 10, replace = FALSE)\n## Error: object 'county_clean' not found\n\nWe can also take a sample and then use the data to estimate the model:\n\n# Run this chunk a few times to explore the different sample models you get\ncounty_clean %&gt;% \n  sample_n(size = 10, replace = FALSE) %&gt;% \n  with(lm(pci_2019 ~ pci_2017))\n## Error: object 'county_clean' not found\n\nWe can also take multiple unique samples and build a sample model from each.\nThe code below obtains 500 separate samples of 10 counties, and stores the model estimates from each:\n\n# Set the seed so that we all get the same results\nset.seed(155)\n\n# Store the sample models\nsample_models_10 &lt;- mosaic::do(500)*(\n  county_clean %&gt;% \n    sample_n(size = 10, replace = FALSE) %&gt;% \n    with(lm(pci_2019 ~ pci_2017))\n)\n## Error: object 'county_clean' not found\n\n# Check it out\nhead(sample_models_10)\n## Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'head': object 'sample_models_10' not found\ndim(sample_models_10)\n## Error: object 'sample_models_10' not found\n\nReflect\n\nWhat’s the point of the do() function?!? If you’ve taken any COMP classes, what process do you think do() is a shortcut for?\nWhat is stored in the Intercept, pci_2017, and r.squared columns of the results?"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-2-sampling-distribution",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-2-sampling-distribution",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 2: Sampling distribution",
    "text": "Exercise 2: Sampling distribution\nCheck out the resulting 500 sample models:\n\ncounty_clean %&gt;% \n  ggplot(aes(x = pci_2017, y = pci_2019)) + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_abline(data = sample_models_10, \n              aes(intercept = Intercept, slope = pci_2017), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n## Error: object 'county_clean' not found\n\nLet’s focus on the slopes of these 500 sample models. A plot of the 500 slopes approximates the sampling distribution of the sample slopes.\n\nsample_models_10 %&gt;% \n  ggplot(aes(x = pci_2017)) + \n  geom_density() + \n  geom_vline(xintercept = 1.027, color = \"red\") + \n  xlim(0.3, 1.7)\n## Error: object 'sample_models_10' not found\n\nReflect: Describe the sampling distribution. What’s its general shape? Where is it centered? Roughly what’s its spread / i.e. what’s the range of estimates you observed?"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-3-standard-error",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-3-standard-error",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 3: Standard error",
    "text": "Exercise 3: Standard error\nFor a more rigorous assessment of the spread among the sample slopes, let’s calculate their standard deviation:\n\nsample_models_10 %&gt;% \n  summarize(sd(pci_2017))\n## Error: object 'sample_models_10' not found\n\nRecall: The standard deviation of sample estimates is called a “standard error”.\nIt measures the typical distance of a sample estimate from the actual population value."
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-4-central-limit-theorem-clt",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-4-central-limit-theorem-clt",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 4: Central Limit Theorem (CLT)",
    "text": "Exercise 4: Central Limit Theorem (CLT)\nRecall that the CLT assumes that, so long as our sample size is “big enough”, the sampling distribution of the sample slope will be Normal.\nSpecifically, all possible sample slopes will vary Normally around the population slope.\n\nDo your simulation results support this assumption?\nWant more intuition into the CLT? Watch this video explanation using bunnies and dragons: https://www.youtube.com/watch?v=jvoxEYmQHNM"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-5-using-the-clt",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-5-using-the-clt",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 5: Using the CLT",
    "text": "Exercise 5: Using the CLT\nLet \\(\\hat{\\beta}_1\\) be an estimate of the population slope parameter \\(\\beta_1\\) calculated from a sample of 10 counties.\nIn exercise 3, you approximated that \\(\\hat{\\beta}_1\\) has a standard error of roughly 0.16.\nThus, by the CLT, the sampling distribution of \\(\\hat{\\beta}_1\\) is:\n\\[\\hat{\\beta}_1 \\sim N(\\beta_1, 0.16^2)\\]\nUse this result with the 68-95-99.7 property of the Normal model to understand the potential error in a slope estimate.\n\nThere are many possible samples of 10 counties. What percent of these will produce an estimate \\(\\hat{\\beta}_1\\) that’s within 0.32, i.e. 2 standard errors, of the actual population slope \\(\\beta_1\\)?\nMore than 2 standard errors from \\(\\beta_1\\)?\nMore than 0.48, i.e. 3 standard errors, above \\(\\beta_1\\)?"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-6-clt-and-the-68-95-99.7-rule",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-6-clt-and-the-68-95-99.7-rule",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 6: CLT and the 68-95-99.7 Rule",
    "text": "Exercise 6: CLT and the 68-95-99.7 Rule\nFill in the blanks below to complete some general properties assumed by the CLT:\n\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 1 st. err. of \\(\\beta_1\\)\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 2 st. err. of \\(\\beta_1\\)\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 3 st. err. of \\(\\beta_1\\)"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-7-increasing-sample-size",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-7-increasing-sample-size",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 7: Increasing sample size",
    "text": "Exercise 7: Increasing sample size\nNow that we have a sense of the potential variability and error in sample estimates, let’s consider the impact of sample size. Suppose we were to increase our sample size from n = 10 to n = 50 or n = 200 counties. What impact do you anticipate this having on our sample estimates of the population parameters:\n\nDo you expect there to be more or less variability among the sample model lines?\nAround what value would you expect the sampling distribution of sample slopes to be centered?\nWhat general shape would you expect that sampling distribution to have?\nIn comparison to estimates based on the samples of size 10, do you think the estimates based on samples of size 50 will be closer to or farther from the true slope (on average)?"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-8-500-samples-of-size-n",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-8-500-samples-of-size-n",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 8: 500 samples of size n",
    "text": "Exercise 8: 500 samples of size n\nLet’s increase the sample size in our simulation. Fill in the blanks to take 500 samples of size 50, and build a sample model from each. Once you complete the code, remove eval = FALSE.\n\nset.seed(155)\nsample_models_50 &lt;- mosaic::do(___)*(\n  county_clean %&gt;% \n    ___(size = ___, replace = FALSE) %&gt;% \n    ___(___(pci_2019 ~ pci_2017))\n)\n\n# Check it out\nhead(sample_models_50)\n\nSimilarly, take 500 samples of size 200, and build a sample model from each. Once you complete the code, remove eval = FALSE.\n\nset.seed(155)\nsample_models_200 &lt;- mosaic::do(___)*(\n  county_clean %&gt;% \n    ___(size = ___, replace = FALSE) %&gt;% \n    ___(___(pci_2019 ~ pci_2017))\n)\n\n# Check it out\nhead(sample_models_200)"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-9-impact-of-sample-size-part-i",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-9-impact-of-sample-size-part-i",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 9: Impact of sample size (part I)",
    "text": "Exercise 9: Impact of sample size (part I)\nCompare and contrast the 500 sets of sample models when using samples of size 10, 50, and 200.\n\n# Remove eval = FALSE\n# 500 sample models using samples of size 10\ncounty_clean %&gt;% \n  ggplot(aes(x = pci_2017, y = pci_2019)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_10, \n              aes(intercept = Intercept, slope = pci_2017), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n# Remove eval = FALSE\n# 500 sample models using samples of size 50\ncounty_clean %&gt;% \n  ggplot(aes(x = pci_2017, y = pci_2019)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_50, \n              aes(intercept = Intercept, slope = pci_2017), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n# Remove eval = FALSE\n# 500 sample models using samples of size 200\ncounty_clean %&gt;% \n  ggplot(aes(x = pci_2017, y = pci_2019)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_200, \n              aes(intercept = Intercept, slope = pci_2017), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nReflect: What happens to our sample models as sample size increases? Was this what you expected?"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-10-impact-of-sample-size-part-ii",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-10-impact-of-sample-size-part-ii",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 10: Impact of sample size (part II)",
    "text": "Exercise 10: Impact of sample size (part II)\nLet’s focus on just the sampling distributions of our 500 slope estimates \\(\\hat{\\beta}_1\\). For easy comparison, plot the estimates based on samples of size 10, 50, and 200 on the same frame:\n\n# Remove eval = FALSE\n\n# Don't think too hard about this code!\n# Combine the estimates & sample size into a new data set\n# Then plot it\ndata.frame(estimates = c(sample_models_10$pci_2017, sample_models_50$pci_2017, sample_models_200$pci_2017),\n           sample_size = rep(c(\"10\",\"50\",\"200\"), each = 500)) %&gt;% \n  mutate(sample_size = fct_relevel(sample_size, c(\"10\", \"50\", \"200\"))) %&gt;% \n  ggplot(aes(x = estimates, color = sample_size)) + \n  geom_density() + \n  geom_vline(xintercept = 1.027, color = \"red\", linetype = \"dashed\") + \n  labs(title = \"Sampling distributions of the sample slope\")\n\nReflect: How do the shapes, centers, and spreads of these sampling distributions compare? Was this what you expected?"
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#exercise-11-properties-of-sampling-distributions",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#exercise-11-properties-of-sampling-distributions",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Exercise 11: Properties of sampling distributions",
    "text": "Exercise 11: Properties of sampling distributions\nIn light of your observations, complete the following statements about the sampling distribution of the sample slope.\n\nFor all sample sizes, the shape of the sampling distribution is roughly ___ and the sampling distribution is roughly centered around ___, the true population slope.\nAs sample size increases:\nThe average sample slope estimate INCREASES / DECREASES / IS FAIRLY STABLE.\nThe standard error of the sample slopes INCREASES / DECREASES / IS FAIRLY STABLE.\nThus, as sample size increases, our sample slopes become MORE RELIABLE / LESS RELIABLE."
  },
  {
    "objectID": "template_qmds/19-sampling-dist-clt-notes.html#done",
    "href": "template_qmds/19-sampling-dist-clt-notes.html#done",
    "title": "Sampling distributions & the CLT (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/21-confidence-intervals-notes.html",
    "href": "template_qmds/21-confidence-intervals-notes.html",
    "title": "Confidence intervals (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nConstruct (approximate) confidence intervals by hand using the 68-95-99.7 rule\nConstruct exact confidence intervals in R\nInterpret confidence intervals in context by referring to the coefficient of interest\nUse confidence intervals to make statements about whether there appear to be true population relationships, changes, and differences\n\n\n\n\nPlease complete the following reading before class.\n\nReading: Section 7 Introduction, Section 7.1, Section 7.2 (stop when you get to 7.2.4.3 Confidence Intervals for Prediction) in the STAT 155 Notes\n\nOptionally you can use the following videos as a companion to the reading (not in place of the reading):\n\nVideo 1: Introduction to Confidence Intervals\nVideo 2: Confidence Intervals: Construction and Interpretation"
  },
  {
    "objectID": "template_qmds/21-confidence-intervals-notes.html#learning-goals",
    "href": "template_qmds/21-confidence-intervals-notes.html#learning-goals",
    "title": "Confidence intervals (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nConstruct (approximate) confidence intervals by hand using the 68-95-99.7 rule\nConstruct exact confidence intervals in R\nInterpret confidence intervals in context by referring to the coefficient of interest\nUse confidence intervals to make statements about whether there appear to be true population relationships, changes, and differences"
  },
  {
    "objectID": "template_qmds/21-confidence-intervals-notes.html#readings-and-videos",
    "href": "template_qmds/21-confidence-intervals-notes.html#readings-and-videos",
    "title": "Confidence intervals (Notes)",
    "section": "",
    "text": "Please complete the following reading before class.\n\nReading: Section 7 Introduction, Section 7.1, Section 7.2 (stop when you get to 7.2.4.3 Confidence Intervals for Prediction) in the STAT 155 Notes\n\nOptionally you can use the following videos as a companion to the reading (not in place of the reading):\n\nVideo 1: Introduction to Confidence Intervals\nVideo 2: Confidence Intervals: Construction and Interpretation"
  },
  {
    "objectID": "template_qmds/21-confidence-intervals-notes.html#exercise-1",
    "href": "template_qmds/21-confidence-intervals-notes.html#exercise-1",
    "title": "Confidence intervals (Notes)",
    "section": "Exercise 1",
    "text": "Exercise 1\nResearch question: Is the relationship between wind speed (windspeed) (in miles per hour) and number of riders (riders_total) different across weekdays and weekends?\n\nPart a\nConstruct and interpret a visualization that would address this question.\n\n\nPart b\nFit a regression model that would address our research question. (Should it be a linear or a logistic regression model?) Interpret only the coefficient of interest.\n\nmod_bikes &lt;- ___\n## Error in parse(text = input): &lt;text&gt;:1:15: unexpected input\n## 1: mod_bikes &lt;- __\n##                   ^\n\n\n\nPart c\n\nConstruct an approximate 95% confidence interval (CI) for the coefficient of interest by hand using the 68-95-99.7 rule.\nCompare your confidence interval to the one given by confint() which gives an exact confidence interval. (The columns give the lower and upper ends of the CI for each coefficient.)\nInterpret the exact confidence interval in context.\nIs zero in the interval? Do we have evidence for a real difference in the windspeed-riders relationship across weekends and weekdays?\n\n\n# By hand (you fill in)\n\n\n# Using confint()\nconfint(mod_bikes, level = 0.95)\n## Error: object 'mod_bikes' not found\n\n\n\nPart d\nLet’s see if these results agree when looking at adjusted R-squared.\nFit another regression model that does not have the coefficient of interest from your Part b model. Compare the adjusted R-squared values between this model and the Part b model. Explain your findings."
  },
  {
    "objectID": "template_qmds/21-confidence-intervals-notes.html#exercise-2",
    "href": "template_qmds/21-confidence-intervals-notes.html#exercise-2",
    "title": "Confidence intervals (Notes)",
    "section": "Exercise 2",
    "text": "Exercise 2\nResearch question: How different is holiday ridership from non-holidays, after accounting for confounding factors?\n\nPart a\nWe believe that weather category (weather_cat), temperature (temp_actual), and wind speed (windspeed) confound the relationship of interest.\n\nDraw a causal graph that shows the 5 variables of interest. Based on your graph do you believe that the 3 potential confounders are indeed confounders (and not mediators or colliders)?\nConstruct visualizations that allow you how each potential confounder relates to riders_total and to holiday.\n\n\n\nPart b\nBased on your Part a explorations, fit an appropriate regression model to answer our research question. Interpret only the coefficient of interest.\nA note about scientific notation in R: Sometimes you may see numbers with the letter e in the middle. This is R’s way of expressing scientific notation. Whenever you see e, replace that with 10 to the power of .... So:\n\n1.234e+02 is 1.234 x 10^2 = 123.4\n1.234e-02 is 1.234 x 10^(-2) = 0.01234\n\n\n\nPart c\n\nUse confint() to construct a 95% confidence interval for the coefficient of interest.\nInterpret this confidence interval in context.\nIs zero in the interval? Do we have evidence for a real holiday effect on ridership?"
  },
  {
    "objectID": "template_qmds/21-confidence-intervals-notes.html#exercise-3",
    "href": "template_qmds/21-confidence-intervals-notes.html#exercise-3",
    "title": "Confidence intervals (Notes)",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe Western Collaborative Group Study (WCGS) was designed in order to investigate a possible link between Type A behavior and coronary heart disease (CHD), and to develop a framework to select patients for intervention in order to decrease risk of CHD. The study contained 3154 cis men between the ages of 39 and 59 in California who had no history of CHD. They were enrolled in the study in 1960 and 1961, underwent a medical examination and covered their medical history, and they were re-examined annually for interim cardiovascular history.\nA full codebook is available here. We will focus on the following variables:\n\nchd: Presence (1) or absence (0) of CHD over followup (outcome)\ntabp: Presence (1) or absence (0) of Type A behavior (main variable of interest)\nage: Age at time of enrollment in the study (years)\nsbp: Systolic blood pressure\ndbp: Diastolic blood pressure\nchol: Cholesterol (mg/dL)\nncigs: Number of cigarettes smoked per day\narcus: Presence (1) or absence (0) of arcus senilis (a colored ring around the cornea made up of lipids like cholesterol and believed to be a risk factor for CHD)\nbmi: BMI = weight * 703 / height^2\n\nResearch question: Is there a causal effect of Type A/B personality on developing coronary heart disease?\n\nwcgs &lt;- read_csv(\"https://mac-stat.github.io/data/wcgs.csv\")\n\n\nPart a\nWe believe that the following variables are confounders of the relationship between Type A/B personality tabp and coronary heart disease (CHD): age + sbp + dbp + chol + ncigs + arcus + bmi.\nFit a regression model that would address our research question. (Should it be a linear or a logistic regression model?) Interpret only the coefficient of interest.\n\ntypea_mod &lt;- ___\n## Error in parse(text = input): &lt;text&gt;:1:15: unexpected input\n## 1: typea_mod &lt;- __\n##                   ^\n\n\n\nPart b\n\nConstruct a 95% confidence interval for the odds ratio of interest using the following code.\nInterpret the confidence interval in context.\nIs 1 contained in the interval? Why is 1 a relevant value to look for here?\n\n\n\nPart c\n(On your own time)\nThe data context in this exercise has a fraught history with the smoking industry. Read this article for some context about how the Type A personality came to be defined and studied. (One big takeaway: The smoking industry had a large incentive to find something to blame health problems on other than smoking!)"
  },
  {
    "objectID": "template_qmds/21-confidence-intervals-notes.html#exercise-4",
    "href": "template_qmds/21-confidence-intervals-notes.html#exercise-4",
    "title": "Confidence intervals (Notes)",
    "section": "Exercise 4",
    "text": "Exercise 4\nFor each of the following MISINTERPRETATIONS of a 95% confidence interval (a,b), explain why the statement is a misinterpretation.\n\nMisinterpretation 1: “There is a 95% probability that the population parameter is within (a,b).”\n\nResponse: The population parameter is not random. It is either in the interval or not, so the probability is 1 or 0. The 95% means that 95% of random samples (that are representative of the population of interest) are expected to contain the true population parameter—“95% confidence” is describing confidence in the interval construction process.\n\nMisinterpretation 2: “There is a 5% probability that the population parameter is not within (a,b).”\n\nResponse: This is incorrect for the same reason as the first misinterpretation.\n\nMisinterpretation 3: “There is a 95% chance that the sample estimate in (a,b).”\n\nResponse: The sample estimate is always in the interval by construction."
  },
  {
    "objectID": "template_qmds/21-confidence-intervals-notes.html#reflection",
    "href": "template_qmds/21-confidence-intervals-notes.html#reflection",
    "title": "Confidence intervals (Notes)",
    "section": "Reflection",
    "text": "Reflection\nHow are you feeling about your ability to translate research questions into appropriate statistical investigations and addressing those questions using output from those investigations? What has gotten easier? What remains challenging?\n\nResponse:"
  },
  {
    "objectID": "template_qmds/21-confidence-intervals-notes.html#done",
    "href": "template_qmds/21-confidence-intervals-notes.html#done",
    "title": "Confidence intervals (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/23-hypothesis-testing-details-notes.html",
    "href": "template_qmds/23-hypothesis-testing-details-notes.html",
    "title": "Hypothesis testing details and practice (Notes)",
    "section": "",
    "text": "You can download a template file to work with here.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.\n\n\n\nBy the end of this lesson, you should be able to:\n\nApply the procedure for a formal hypothesis test\nArticulate how we can formalize a research question as a testable, statistical hypothesis\n\n\n\n\nPlease complete the following reading or videos before class:\n\nReading: Section 7.3 (stop when you get to Section 7.3.4) in the STAT 155 Notes\nVideo 1: Introduction to Statistical Inference\nVideo 2: Hypothesis Testing Framework\nVideo 3: Hypothesis Testing Procedure"
  },
  {
    "objectID": "template_qmds/23-hypothesis-testing-details-notes.html#learning-goals",
    "href": "template_qmds/23-hypothesis-testing-details-notes.html#learning-goals",
    "title": "Hypothesis testing details and practice (Notes)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nApply the procedure for a formal hypothesis test\nArticulate how we can formalize a research question as a testable, statistical hypothesis"
  },
  {
    "objectID": "template_qmds/23-hypothesis-testing-details-notes.html#readings-and-videos",
    "href": "template_qmds/23-hypothesis-testing-details-notes.html#readings-and-videos",
    "title": "Hypothesis testing details and practice (Notes)",
    "section": "",
    "text": "Please complete the following reading or videos before class:\n\nReading: Section 7.3 (stop when you get to Section 7.3.4) in the STAT 155 Notes\nVideo 1: Introduction to Statistical Inference\nVideo 2: Hypothesis Testing Framework\nVideo 3: Hypothesis Testing Procedure"
  },
  {
    "objectID": "template_qmds/23-hypothesis-testing-details-notes.html#exercise-1",
    "href": "template_qmds/23-hypothesis-testing-details-notes.html#exercise-1",
    "title": "Hypothesis testing details and practice (Notes)",
    "section": "Exercise 1",
    "text": "Exercise 1\nResearch Question: Can we predict whether or not a mushroom is poisonous based on the shape of its cap?\nFor this exercise, we will look at data from various species of gilled mushrooms in the Agaricus and Lepiota Family. We have information on whether a mushroom is poisonous (TRUE if it is, FALSE if it’s edible), the shape of its cap (cap_shape, a categorical variable with 6 categories), the texture of its cap surface (cap_surface, a categorical variable with 4 categories), and the size of its gills (gill_size, a categorical variable with two categories)\n\n# Load the data & packages\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(broom)\n\nmushrooms &lt;- read_csv(\"https://Mac-STAT.github.io/data/mushrooms.csv\")\n\nmushrooms &lt;- mushrooms %&gt;%\n  mutate(cap_shape = relevel(as.factor(cap_shape), ref=\"flat\")) %&gt;%\n  dplyr::select(poisonous, cap_shape)\n\nhead(mushrooms)\n## # A tibble: 6 × 2\n##   poisonous cap_shape\n##   &lt;lgl&gt;     &lt;fct&gt;    \n## 1 TRUE      convex   \n## 2 FALSE     convex   \n## 3 FALSE     bell     \n## 4 TRUE      convex   \n## 5 FALSE     convex   \n## 6 FALSE     convex\n\n\nPart a\nOne of the most poisonous species of mushrooms is the Amanita phalloides or “Death Cap” mushroom, which typically has a flat cap shape when mature. Based on this anecdote, we hypothesize that species of mushrooms with flat caps in general may be more likely to be poisonous than edible.\nFirst, let’s translate this question to an appropriate null and alternative hypothesis that we can compare with a formal hypothesis test. Remember that poisonous is a binary outcome, so we need to frame our null and alternative hypotheses in terms of odds (i.e., Odds(poisionous | flat cap) = P(poisonous|flat cap)/P(edible | flat cap)).\n\nYour answer\n\n\n\nPart b\n\nFit a logistic regression model to investigate whether cap_shape is associated with a mushroom being poisonous. (Note that in the setup code above, we have forced the reference category for the cap_shape predictor to be flat; without this, the reference category by default would be set as bell, which is the first category when sorted alphabetically).\n\n\nmushroom_mod1 &lt;- ()\n\ncoef(mushroom_mod1)\n## Error in parse(text = input): &lt;text&gt;:1:19: unexpected ')'\n## 1: mushroom_mod1 &lt;- ()\n##                       ^\n\n\n\nPart c\nProvide an appropriate interpretation of the intercept coefficient on the odds scale. Based on this interpretation, do you believe mushrooms with flat caps are more likely to be poisonous, or more likely to be edible?\n\nYour answer here\n\n\n\nPart d\nLet’s look at the full model summary:\n\nsummary(mushroom_mod1)\n## Error: object 'mushroom_mod1' not found\n\nReport and interpret the test statistic for the intercept term (our coefficient of interest):\n\nYour answer\n\n\n\nPart e\n\nReport and interpret the p-value for the intercept term.\nBased on this p-value and a significance level of 0.05, do we have evidence that mushrooms with flat caps are more likely to be poisonous than edible?\n\n\nYour answer\n\n\n\nPart f\nNow suppose we are interested in whether the odds of being poisonous are different for mushrooms with other cap shapes.\nBy hand, calculate the odds of being poisonous for mushrooms with knobbed caps, conical caps, and sunken caps (remember that the non-exponentiated coefficients represent a difference in log-odds compared to the reference category):\n\nodds(poisonous | knobbed cap) =\n\n\nodds(poisonous | conical cap) =\n\n\nodds(poisonous | sunken cap) =\n\n\n\nPart g\nBased on these odds, which of the 4 mushroom cap shapes we’ve investigated (flat, knobbed, conical, and sunken) do you believe is the best indicator that it’s edible? Which cap shape do you expect is most likely to be poisonous?\n\nYour answer\n\n\n\nPart h\nLet’s get the full model summary again:\n\ntidy(mushroom_mod1) %&gt;% \n    mutate(exp_estimate = exp(estimate)) %&gt;% \n    select(term, estimate, exp_estimate, everything())\n## Error: object 'mushroom_mod1' not found\n\nNow report and interpret the p-values for the coefficients corresponding to cap_shapeknobbed, cap_shapeconical, and cap_shapesunken:\n\nYour answer\n\n\n\nPart i\nBased on the model summary output in part h above, if you were given a plate of mushrooms with different cap shapes and had to pick one to eat, which one would you choose? Which cap shape would you absolutely avoid at all costs? Are your decisions guided by the coefficient estimates, the p-values, or both?\n\nYour answer\n\n\n\nPart j\nLet’s look at the data a slightly different way, using a 6x2 table of counts:\n\nmushrooms %&gt;% \n  mutate(cap_shape=as.factor(cap_shape),\n         poisonous=as.factor(poisonous)) %&gt;%\n  dplyr::count(cap_shape, poisonous, .drop=FALSE) %&gt;% \n  pivot_wider(names_from=poisonous, values_from=n, names_prefix=\"Poisonous = \")\n## # A tibble: 6 × 3\n##   cap_shape `Poisonous = FALSE` `Poisonous = TRUE`\n##   &lt;fct&gt;                   &lt;int&gt;              &lt;int&gt;\n## 1 flat                     1596               1556\n## 2 bell                      404                 48\n## 3 conical                     0                  4\n## 4 convex                   1948               1708\n## 5 knobbed                   228                600\n## 6 sunken                     32                  0\n\nNow, if you were given a plate of mushrooms with different cap shapes and had to pick one shape to eat and one to absolutely avoid, would you choose the same shapes? Why or why not?\n\nYour answer"
  },
  {
    "objectID": "template_qmds/23-hypothesis-testing-details-notes.html#exercise-2",
    "href": "template_qmds/23-hypothesis-testing-details-notes.html#exercise-2",
    "title": "Hypothesis testing details and practice (Notes)",
    "section": "Exercise 2",
    "text": "Exercise 2\nFor this exercise, let’s return to the fish dataset from a previous activity.\n\nfish &lt;- read_csv(\"https://Mac-STAT.github.io/data/Mercury.csv\")\n\nhead(fish)\n## # A tibble: 6 × 5\n##   River  Station Length Weight Concen\n##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1 Lumber       0   47     1616   1.6 \n## 2 Lumber       0   48.7   1862   1.5 \n## 3 Lumber       0   55.7   2855   1.7 \n## 4 Lumber       0   45.2   1199   0.73\n## 5 Lumber       0   44.7   1320   0.56\n## 6 Lumber       0   43.8   1225   0.51\n\nResearch question: We believe the length of a fish (measured in centimeters) is causally associated with its mercury concentration (measured in parts per million [ppm]). We suspect that the river a fish is sampled from may be a confounder, since differences in the river environment may causally influence both the average length of fish (e.g. due to differences in water temperature or food availability) as well as mercury concentration (e.g. due to differences between the two rivers in mercury pollution levels).\n\nPart a\nFit a linear regression model that can be used to answer our research question.\n\nmod_fish1 &lt;- ___\nsummary(mod_fish1)\n## Error in parse(text = input): &lt;text&gt;:1:15: unexpected input\n## 1: mod_fish1 &lt;- __\n##                   ^\n\n\n\nPart b\nInterpret the coefficient estimate, test statistic, and p-value for the RiverWacamaw coefficient. Assume we have specified a significance level of 0.05.\n\nResponse\n\n\n\nPart c\nSuppose we now want to determine if the causal effect of fish length on mercury concentration differs according to the river a fish was sampled from.\nFirst, modify the code chunk below to visualize the 3-way relationship between the Concen, Length, and River variables.\n\nfish %&gt;% \n  ggplot(aes(x = ___, y = ___, colour = ___)) + \n  # [ADDITIONAL GGPLOT LAYER(S)]\n## Error in parse(text = input): &lt;text&gt;:2:19: unexpected input\n## 1: fish %&gt;% \n## 2:   ggplot(aes(x = __\n##                      ^\n\nNext, fit an appropriate linear regression model with an interaction term to investigate this question.\n\nmod_fish2 &lt;- ___\nsummary(mod_fish2)\n## Error in parse(text = input): &lt;text&gt;:1:15: unexpected input\n## 1: mod_fish2 &lt;- __\n##                   ^\n\n\n\nPart d\nInterpret the coefficient estimate, test statistic, and p-value for the RiverWacamaw:Length interaction term in this revised model (mod_fish2). Assume we’ve set a significance level of 0.05.\n\nResponse\n\n\n\nPart e\nInterpret the coefficient estimate, test statistic, and p-value for the RiverWacamaw coefficient in this revised model (mod_fish2). (again, you can assume we’ve set a significance level of 0.05).\n\n\nPart f (CHALLENGE)\nSuppose another researcher runs the same model we fit in part c above (mod_fish2), but they claim that a more appropriate alternative hypothesis should be Beta_1 &lt; 0, (and not Beta_1 ≠ 0, as is assumed by default when running a regression model). Because of this, they reported a smaller p-value for the coefficient, and claim that the Wacamaw River has a lower baseline mercury concentration (i.e., when Length = 0cm).\nWhat is the p-value they would have reported for the RiverWacamaw coefficient in mod_fish2?\n\nResponse\n\nWhat is a potential ethical problem with the other researcher’s claim that the alternative hypothesis should be Beta_1 &lt; 0?\n\nResponse\n\n\n\nPart g (CHALLENGE)\nYou point out to the other researcher that the intercept and RiverWacamaw coefficients are both negative, so whatever difference in mercury concentration between the two rivers your model predicts “at baseline” is not useful or meaningful–you cannot have a fish that is 0cm long, nor a mercury concentration &lt;0ppm.\nYou propose that a more appropriate model should transform the Length variable in some way to make the intercept more interpretable. Create a new variable named Length_adj with this transformation and use it to re-fit the model:\n\nmod_fish3 &lt;- lm(Concen ~ Length_adj*River, data=fish)\n## Error in eval(predvars, data, env): object 'Length_adj' not found\nsummary(mod_fish3)\n## Error: object 'mod_fish3' not found\n\nCompare the output of this model to that of mod_fish2. What happened to the estimate, test statistic, and p-value for the RiverWacamaw coefficient? How does this affect your conclusion? How about the other researcher’s conclusion?\n\nResponse"
  },
  {
    "objectID": "template_qmds/23-hypothesis-testing-details-notes.html#done",
    "href": "template_qmds/23-hypothesis-testing-details-notes.html#done",
    "title": "Hypothesis testing details and practice (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html",
    "href": "template_qmds/25-f-tests-notes.html",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "",
    "text": "“Nested models” are models where the covariates of one model are a subset of another model. As an example, consider the following models for estimating the association between forced expiratory volume (FEV) and smoking status:\nModel 1:\n\\[\nE[FEV \\mid smoke] = \\beta_0 + \\beta_1 smoke\n\\]\nModel 2:\n\\[\nE[FEV \\mid smoke, age] = \\beta_0 + \\beta_1 smoke + \\beta_2 age\n\\] Here, Model 1 is “nested” inside Model 2, since the covariates included in Model 1 (only smoke) are a subset of those in Model 2 (both smoke and age).\nAn example of non-nested models are…\nModel 3:\n\\[\nE[FEV \\mid smoke, height] = \\beta_0 + \\beta_1 smoke + \\beta_2 height\n\\]\nModel 4:\n\\[\nE[FEV \\mid smoke, sex] = \\beta_0 + \\beta_1 smoke + \\beta_2 sex\n\\]\nHere, even though Model 3 and Model 4 both contain smoke as explanatory variables, neither is nested in the other, since sex is not a part of Model 3, and height is not a part of Model 4.\n\n\n\nBy the end of this activity, you should be able to:\n\nDetermine if one model is nested within another\nDetermine which null and alternative hypotheses require an f-test\nDetermine which f-tests require the use of the anova function in R vs. the overall f-test given in regular regression output\nInterpret the results of an f-test in context\n\n\n\n\nPlease read the following notes and watch the following video before class:\n\nReading: Section 7.3.4 in the STAT 155 Notes\nVideo: F-Tests (script)"
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#nested-models",
    "href": "template_qmds/25-f-tests-notes.html#nested-models",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "",
    "text": "“Nested models” are models where the covariates of one model are a subset of another model. As an example, consider the following models for estimating the association between forced expiratory volume (FEV) and smoking status:\nModel 1:\n\\[\nE[FEV \\mid smoke] = \\beta_0 + \\beta_1 smoke\n\\]\nModel 2:\n\\[\nE[FEV \\mid smoke, age] = \\beta_0 + \\beta_1 smoke + \\beta_2 age\n\\] Here, Model 1 is “nested” inside Model 2, since the covariates included in Model 1 (only smoke) are a subset of those in Model 2 (both smoke and age).\nAn example of non-nested models are…\nModel 3:\n\\[\nE[FEV \\mid smoke, height] = \\beta_0 + \\beta_1 smoke + \\beta_2 height\n\\]\nModel 4:\n\\[\nE[FEV \\mid smoke, sex] = \\beta_0 + \\beta_1 smoke + \\beta_2 sex\n\\]\nHere, even though Model 3 and Model 4 both contain smoke as explanatory variables, neither is nested in the other, since sex is not a part of Model 3, and height is not a part of Model 4."
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#learning-goals",
    "href": "template_qmds/25-f-tests-notes.html#learning-goals",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "",
    "text": "By the end of this activity, you should be able to:\n\nDetermine if one model is nested within another\nDetermine which null and alternative hypotheses require an f-test\nDetermine which f-tests require the use of the anova function in R vs. the overall f-test given in regular regression output\nInterpret the results of an f-test in context"
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#readings-and-videos",
    "href": "template_qmds/25-f-tests-notes.html#readings-and-videos",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "",
    "text": "Please read the following notes and watch the following video before class:\n\nReading: Section 7.3.4 in the STAT 155 Notes\nVideo: F-Tests (script)"
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#exercise-1-nested-models",
    "href": "template_qmds/25-f-tests-notes.html#exercise-1-nested-models",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "Exercise 1: Nested Models",
    "text": "Exercise 1: Nested Models\n\nWhich of the following models are nested in the model \\(E[A \\mid B, C, D] = \\beta_0 + \\beta_1 D + \\beta_2 B + \\beta_3 C + \\beta_4 B * C\\)?\n\n\nModel 1: \\(E[A \\mid B] = \\beta_0 + \\beta_1 B\\)\nModel 2: \\(E[A \\mid B, D] = \\beta_0 + \\beta_1 B + \\beta_2 D\\)\nModel 3: \\(E[B \\mid C] = \\beta_0 + \\beta_1 C\\)\nModel 4: \\(E[A \\mid B, C, D] = \\beta_0 + \\beta_1 B + \\beta_2 C + \\beta_3 D\\)\nModel 5: \\(E[A \\mid B, C, D] = \\beta_0 + \\beta_1 C + \\beta_2 B + \\beta_3 D + \\beta_4 B * D\\)\nModel 6: \\(E[A \\mid D] = \\beta_0 + \\beta_1 D\\)\n\n\nConsider the following models involving variables A, B, C, and D:\n\n\nModel 1: \\(E[A \\mid B] = \\beta_0 + \\beta_1 B\\)\nModel 2: \\(E[A \\mid B, C] = \\beta_0 + \\beta_1 B + \\beta_2 C\\)\nModel 3: \\(E[A \\mid B, C] = \\beta_0 + \\beta_1 B + \\beta_2 C + \\beta_3 BC\\)\nModel 4: \\(E[A \\mid C, D] = \\beta_0 + \\beta_1 C + \\beta_2 D\\)\nModel 5: \\(E[B \\mid A] = \\beta_0 + \\beta_1 A\\)\nModel 6: \\(E[B \\mid A, C] = \\beta_0 + \\beta_1 A + \\beta_2 C + \\beta_3 AC\\)\n\nDetermine for each of the following statements whether that statement is True or False.\n\nModel 1 is nested in Model 2\nModel 1 is nested in Model 3\nModel 1 is nested in Model 4\nModel 2 is nested in Model 3\nModel 3 is nested in Model 2\nModel 2 is nested in Model 6\n\n\nWhat is one (numeric) way to compare nested models? Explain how you would determine which model is “better” based on this metric."
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#exercise-2-f-tests",
    "href": "template_qmds/25-f-tests-notes.html#exercise-2-f-tests",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "Exercise 2: F-Tests",
    "text": "Exercise 2: F-Tests\nThis exercise involves the MacGrades.csv dataset, which contains a sub-sample (to help preserve anonymity) of every grade assigned to a former Macalester graduating class. For each of the 6414 rows of data, the following information is provided (with a few missing values):\n\nsessionID: A section ID number\nsid: A student ID number\ngrade: The grade obtained, as a numerical value (i.e. an A is a 4, an A- is a 3.67, etc.)\ndept: A department identifier (these have been made ambiguous to maintain anonymity)\nlevel: The course level (e.g. 100-, 200-, 300-, and 600-)\nsem: A semester identifier\nenroll: The section enrollment\niid: An instructor identifier (these have been made ambiguous to maintain anonymity)\n\n\n# load necessary packages\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readr)\n\n# load datasets\nMacGrades &lt;- read_csv(\"https://mac-stat.github.io/data/MacGrades.csv\")\n\nNOTE: Questions (a) and (b), since they are exploratory in nature, can suck up a lot of time if you let them! For the sake of getting to the rest of the activity, please spend no more than ~5 minutes on them.\n\nHypothesize two relationships between the variables in the dataset (pick any two relationships you want!). Your response should be written in a paragraph form.\n\n\nResponse Put your response here\n\n\nExplore the relationship between course grades and other variables in the data. Make two visualizations, and describe any patterns you observe.\nNote that the level variable is currently quantitative. For this activity, we’d like to treat it as categorical. Create a new variable level_cat so that we can consider level categorically in the following analysis.\nSuppose we are interested in the relationship between course level (categorical) and student grades. Using grade as your outcome variable, fit a linear regression model to investigate this question.\n\nComment on the nature of the relationship between course level and student grades (this should not be a coefficient interpretation, but instead a description of a general trend, or lack thereof).\n\nState the null and alternative hypotheses associated with the research question in part (d).\n\n\\[\nH_0:\n\\]\n\\[\nH_1:\n\\]\n\nWhat is the p-value associated with this hypothesis test? Do we have enough evidence to reject the null hypothesis, using a significance threshold of 0.05?\nSuppose we are interested in the relationship between course enrollment and student grades. Again, use grade as your outcome variable, and fit a linear regression model to investigate this question.\nState the null and alternative hypotheses associated with the research question in part (g).\n\n\\[\nH_0:\n\\]\n\\[\nH_1:\n\\]\n\nWhat is the p-value associated with this hypothesis test? Do we have enough evidence to reject the null hypothesis, using a significance threshold of 0.05?\n\n\nDo we need to conduct a nested F-test using the anova function to complete our hypothesis testing procedure for the research question posed in part (g)? Explain why or why not."
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#exercise-3-more-f-tests",
    "href": "template_qmds/25-f-tests-notes.html#exercise-3-more-f-tests",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "Exercise 3: More F-tests",
    "text": "Exercise 3: More F-tests\n\nSuppose we are now interested in the association between course grade and enrollment for classes of the same level. Write a model statement in the form \\(E[Y | X] = ...\\) that will produce a statistical model that will allow us to answer our scientific question. Replace Y and X, where appropriate, with response and predictor variables.\n\n\\[\nE[Y | X] = ___\n\\]\nWhich coefficient(s) in your model is the one that is relevant to your research question?\n\nWhat are the relevant null and alternative hypotheses that address the scientific question in part (a)?\nFit the model you wrote in part (a), calculate a p-value, and report the results of the hypothesis test in part (b)."
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#reflection",
    "href": "template_qmds/25-f-tests-notes.html#reflection",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "Reflection",
    "text": "Reflection\nF-tests are useful when the null hypothesis you wish to test is such that more than one covariate is simultaneously equal to a specific number (typically zero). What scenarios, outside of those shown in this example, can you think of where a relevant scientific hypothesis you want to test involves more than one covariate being simultaneously equal to zero?\n\nResponse Put your response here."
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#exercise-4",
    "href": "template_qmds/25-f-tests-notes.html#exercise-4",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "Exercise 4",
    "text": "Exercise 4\nRepeat Exercise 3, supposing we are instead interested in the association between course grade and course level for classes of the same enrollment."
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#exercise-5-reference-categories",
    "href": "template_qmds/25-f-tests-notes.html#exercise-5-reference-categories",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "Exercise 5: Reference categories",
    "text": "Exercise 5: Reference categories\nOur final research question pertains to whether or not there is a relationship between course grade and department. Again, use course grade as the outcome variable in your linear regression model.\n\nState the null and alternative hypotheses in colloquial language associated with the relevant hypothesis test.\n\nH0:\nH1:\n\nFit a linear regression model, and conduct your hypothesis testing procedure to answer the research question posed in this Exercise. State your conclusions accordingly (you do not need to interpret any regression coefficients, just state and interpret the results of your hypothesis test!).\nAre any of the individual department p-values significant?\n\nWhat do these p-values tell us, and why is this not contradictory to your answer in part (b)?"
  },
  {
    "objectID": "template_qmds/25-f-tests-notes.html#done",
    "href": "template_qmds/25-f-tests-notes.html#done",
    "title": "Nested Models & F-Tests (Notes)",
    "section": "Done!",
    "text": "Done!\n\nFinalize your notes: (1) Render your notes to an HTML file; (2) Inspect this HTML in your Viewer – check that your work translated correctly; and (3) Outside RStudio, navigate to your ‘Activities’ subfolder within your ‘STAT155’ folder and locate the HTML file – you can open it again in your browser.\nClean up your RStudio session: End the rendering process by clicking the ‘Stop’ button in the ‘Background Jobs’ pane.\nCheck the solutions in the course website, at the bottom of the corresponding chapter.\nWork on homework!"
  }
]
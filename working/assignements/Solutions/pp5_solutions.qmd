---
title: "Practice Problems 5"
author: "SOLUTIONS"
date: now
date-format: "YYYY-MM-DDTHH:mm:ssZ"
format:
  html:
    embed-resources: true
    toc: true
    code-tools: true    
editor_options: 
  chunk_output_type: inline
---

# Purpose

The goal of this set of practice problems is to practice the following skills:

- Formulate descriptive, predictive, and causal research questions
- Connect the concepts of redundancy and multicollinearity to multiple $R^2$ and adjusted $R^2$
- Construct, interpret, and evaluate logistic regression models



# Directions

1. Create a code chunk in which you load the `ggplot2`, `dplyr`, and `readr` packages. Include the following command in the code chunk to read in the data: `games <- read_csv("https://mac-stat.github.io/data/boardgamegeeks.csv")`

2. Continue with the exercises below. You will need to create new code chunks to construct visualizations and models and write interpretations beneath. Put text responses in blockquotes as shown below:

> Response here. (The > at the start of the line starts a blockquote and makes the text larger and easier to read.)

3. Render your work for submission:
    - Click the "Render" button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.
    - Scroll through and inspect the document to check that your work translated to the HTML format correctly.
    - Close the browser tab.
    - Go to the "Background Jobs" pane in RStudio and click the Stop button to end the rendering process.
    - Locate the rendered HTML file in the folder where this file is saved. Open the HTML to ensure that your work looks as it should (code appears, output displays, interpretations appear). Upload this HTML file to Moodle.

```{r}
library(ggplot2)
library(dplyr)
library(readr)

games <- read_csv("https://mac-stat.github.io/data/boardgamegeeks.csv")
```



# Exercises

## Context

We will be looking at data on the play characteristics and popularity of board games from the [Board Game Geek](https://boardgamegeek.com/) database. More information about the data and a codebook are available [here](https://github.com/Mac-STAT/data/blob/main/boardgamegeeks_codebook.md). The dataset contains many measures of game popularity (summaries of user ratings) and game attributes (categories, themes, and gameplay mechanics).

We will be exploring a range of research questions related to this data.



## Exercise 1: Descriptive, predictive, and causal questions

Suppose that you are an analyst helping out a local board game convention. Your job is to help convention attendees have a great time.

After exploring the [codebook](https://github.com/Mac-STAT/data/blob/main/boardgamegeeks_codebook.md), consider the following:

- Would investigating descriptive research questions help you do your job? If so, list some relevant descriptive questions that you came up with. If not, explain why descriptive research questions are not useful here.
- Repeat the above questions for predictive and causal research questions.

> Thinking about **descriptive questions**
> 
> The following questions might be of interest:
> - What are the most popular games overall?
> - What are the most popular games by genre? By number of players?
> 
> The answers to the above questions would directly give board game recommendations. Another way that we could frame those questions from a more descriptive standpoint is to ask:
> - How does popularity vary by genre? By number of players?
>
> The answers to these questions give convention attendees an overall sense of the types of games that tend to be more popular.
> 
> Another consideration: a convention attendee might not necessarily be interested in playing the most popular games. For example, one attendee might know that they like family games with a short play time, and another might know that they like strategy games with a longer play time. It would be helpful for them to know how many (and what) games meet their criteria.

> Thinking about **predictive questions**
> 
> Predictive questions are focused on building models that explain a lot of variation in an outcome. In this context, they would be focused on identifying factors that predict board game popularity well. Building a strong model for game popularity and looking at the coefficient interpretations could help us understand what variables are most helpful in predicting popularity and *how* those variables relate to popularity.

> Thinking about **causal questions**
>
> Causal questions focus on the effect of a particular variable on an outcome. If we can answer causal research questions, we have some information to potentially make changes and take actions that improve outcomes.
>
> Consider the following question causally-worded question (because of the word "affect"): How does a game's complexity (ease of learning) affect popularity?
>
> While I would say that this is a causal question (changing the complexity of a game could indeed affect its popularity), this likely isn't of interest to convention attendees because they are *playing* games--not designing them. The causal question above is more of interest to game designers. We could reframe the question slightly: How does a game's complexity relate to popularity? This could be answered in a descriptive context (look at a scatterplot of popularity vs. complexity) or as part of answering a predictive question (interpreting the complexity coefficient in a multiple regression model with additional relevant predictors).
> 
> Causal questions that convention attendees might be interested in are things like "Is playing game X more fun with 3 players vs 4 players?" But we don't have the data to answer this question.

> **Feedback guide:** Answers may differ from above. What matters is that the students are providing appropriate examples of each of predictive, descriptive, and causal questions.





## Exercise 2: Addressing your questions

Pick two of your research questions from the previous exercise, and create visualizations and models to address those questions. Make sure to:

- Include helpful labels on your visualizations
- Explain why your plots and models address your research questions
- Interpret only the relevant coefficients from your models
- If relevant, comment on model quality metrics.

> **Feedback guide:**
> 
> - Descriptive questions should be addressed with appropriate plots and summary statistics.
> - Predictive questions should involve fitting a multiple linear regression model and report on multiple R-squared. If multiple models are explored, adjusted R-squared should be compared between then. Students may choose to interpret some of the coefficients here or in Exercise 3.
> - Causal questions should involve discussing what variables are believed to be confounding variables and fitting a multiple linear regression model that adjusts for those confounders.


Example questions and explorations are below:

> **Question 1 (Descriptive):** How does popularity (as measured by `mean_rating`) vary across genres? (`mean_rating` describes the mean rating across users who rated the game.)

```{r}
boxplot_and_summ <- function(data, var, xlab) {
    p <- ggplot(data, aes(x = factor({{ var }}), y = mean_rating)) +
        geom_boxplot() +
        labs(x = xlab, y = "Mean ratings")

    summ <- games %>%
        group_by({{ var }}) %>% 
        summarize(mean(mean_rating))
    
    print(p)
    print(summ)
}

boxplot_and_summ(games, cat_thematic, "Category: Thematic")
boxplot_and_summ(games, cat_strategy, "Category: Strategy")
boxplot_and_summ(games, cat_war, "Category: War")
boxplot_and_summ(games, cat_cgs, "Category: Card Games")
boxplot_and_summ(games, cat_abstract, "Category: Abstract")
boxplot_and_summ(games, cat_party, "Category: Party")
boxplot_and_summ(games, cat_childrens, "Category: Children's")
```

> **Question 2 (Predictive):** I explored two different predictive models: one with game complexity (`game_weight`) and `kickstarted` as predictors, and a second that also included indicators for the major game categories. The 2nd model had only a marginally higher multiple R-squared and adjusted R-squared, so I prefer the first model because it explains almost the same amount of variation in popularity (mean ratings) but with way fewer predictors---it's simpler to interpret (and less likely to be overfit).

```{r}
mod_predictive_1 <- lm(mean_rating ~ game_weight + kickstarted, data = games)
mod_predictive_2 <- lm(mean_rating ~ game_weight + kickstarted + cat_thematic + cat_strategy + cat_war + cat_cgs + cat_abstract + cat_party + cat_childrens, data = games)

summary(mod_predictive_1)
summary(mod_predictive_2)
```
In keeping with the first model, I wanted to explore if there might be an interaction between complexity and whether a game was kickstarted, but it doesn't look like there is because the slopes for the two groups look identical.

```{r}
ggplot(games, aes(x = game_weight, y = mean_rating, color = factor(kickstarted))) +
    geom_point(alpha = 0.1) +
    geom_smooth() +
    theme_classic()
```





## Exercise 3: Communicating your findings

Write a paragraph addressed to the convention organizers detailing how your findings in the previous exercise can help attendees have more fun at the convention.

> War games, strategy games, and card games have the highest average mean ratings (7.21, 7.13, and 7.11 out of 10 points respectively), so if you're looking broadly for a popular game, check out games in these categories!
>
> Regardless of being kickstarted or not, higher complexity games tend to have higher ratings. Further, regardless of complexity, kickstarted games tend to have higher ratings. So if you want to find a particularly popular game, look for ones that are complex and kickstarted!

> **Feedback guide:** There will be a lot of variety here, but the writing here should involve giving some recommendations to convention attendees.





## Exercise 4: Family and children's categories

**Question:** Does a game being in the family category (`cat_family`) provide meaningfully different information from a game being in the children's category (`cat_childrens`) in terms of explaining average ratings?

Fit 2 models that will allow you to address this question. Report and compare the multiple and adjusted R-squared measures in these 2 models. Use this comparison to answer our question.

> We can fit a model with just `cat_childrens` as a predictor and another model with both `cat_childrens` and `cat_family`. We can compare the adjusted R-squared to answer this question.
>
> The adjusted R-squared increases from 0.07862 to 0.1339 when including the family category predictor, so being in the family category DOES provide meaningfully different information than being in the children's category. (**Feedback guide:** As long as students say roughly what is in this paragraph, that is a good response. I provide extra explanation about adjusted R-squared below.)
>
> Adjusted R-squared will not automatically increase with the addition of a predictor, so the fact that adjusted R-squared increased here indicates that the family category predictor is able to explain enough more variation in popularity to warrant its inclusion in the model.

```{r}
mod_childrens <- lm(mean_rating ~ cat_childrens, data = games)
mod_childrens_family <- lm(mean_rating ~ cat_childrens + cat_family, data = games)

summary(mod_childrens)
summary(mod_childrens_family)
```





## Exercise 5: Define binary outcome

Use the `mutate()` function from `dplyr` to create a binary outcome variable called `popular` that is TRUE if the `mean_rating` is over 8 AND the `p25_rating` is over 6.5. In R, you can use `&` to combine logical statements. For example, `x1 < 1 & x2 < 2` results in TRUE if both `x1` is less than 1 AND `x2` is less than 2.

> **Feedback guide:** Students just need the correct code.

```{r}
games <- games %>% 
    mutate(popular = mean_rating > 8 & p25_rating > 6.5)
```





## Exercise 6: Visual explorations

We want to investigate how a game's complexity and whether or not it was kickstarted relate to its popularity.

### Part a

Construct and interpret a visualization that shows how popularity is related to a game's complexity (`game_weight`).

> It looks like popular games tend to be more complex, though there is a bit of spread---some popular games are relatively simple (have close to the lowest complexity rating). Game complexity is a relevant predictor for popularity.

```{r}
# Look at summary statistics for the complexity variable to get a sense of the range
summary(games$game_weight)

# Boxplot
ggplot(games, aes(x = popular, y = game_weight)) +
    geom_boxplot() +
    theme_classic() +
    labs(x = "Popularity", y = "Game complexity")

# Overlaid density plots
ggplot(games, aes(color = popular, x = game_weight)) +
    geom_density() +
    theme_classic() +
    labs(color = "Popularity", x = "Game complexity")
```


### Part b

Construct and interpret a visualization that shows how popularity is related to whether or not a game was kickstarted (`kickstarted`). (Note: you will want to use `factor(kickstarted)` in your code to ensure that it is treated as a categorical variable.)

> **Feedback guide:** Either a proportional bar plot or a mosaic plot is fine. Other bar plots don't easily show the proportion of popular games in the kickstarted games vs. non-kickstarted games.

> From both the proportional bar plot and the mosaic plot, we see that kickstarted games have a higher proportion of popular games than non-kickstarted games. From the mosaic plot, we see the additional information that kickstarted games are much less common than non-kickstarted games. Whether or not a game was kickstarted is a relevant predictor for popularity.

```{r}
# Proportional bar plot
ggplot(games, aes(x = factor(kickstarted), fill = popular)) +
    geom_bar(position = "fill")

# Mosaic plot
library(ggmosaic)
ggplot(games) +
    geom_mosaic(aes(x = product(kickstarted), fill = popular))
```





## Exercise 7: Logistic regression modeling

### Part a

Fit a simple logistic regression model called that models popularity as a function of complexity (`game_weight`). Display the exponentiated coefficients.

```{r}
log_mod_complexity <- glm(popular ~ game_weight, data = games, family = "binomial")

# Non-exponentiated coefficients
coef(summary(log_mod_complexity))

# Exponentiated coefficients
exp(-6.802196) # intercept
exp(1.506265) # game_weight (complexity) coefficient
```


### Part b

Interpret each coefficient from Part a in a contextually meaningful way. Is the intercept meaningful in this context?

> Intercept: The odds of a game with a complexity score of zero being popular is 0.001111332. This is not meaningful because the lowest complexity score is 1, so interpreting the intercept extrapolates beyond the range of the data.


> `game_weight`: There are different ways to express the interpretation:
> 
> - Each 1 unit increase in complexity score is associated with a 1.51 multiplicative change in the odds of a game being popular.
> - When comparing games who differ in complexity score by 1 unit, games with the higher complexity have 1.51 times the odds of being popular than games with the lower complexity score.
>
> **Feedback guide:** Students need to mention units (complexity score is unitless so they can just say "units"). They need to interpret the *exponentiated* coefficient in terms of multiplicative changes in odds. (If they refer to "chance", tell them that "chance" implies *probability*, which is different from odds. They also need to say the event associated with the odds (odds *of a game being popular*).

### Part c

Fit a simple logistic regression model called that models popularity as a function of whether or not a game was kickstarted (`kickstarted`). Display the exponentiated coefficients.

```{r}
log_mod_kick <- glm(popular ~ kickstarted, data = games, family = "binomial")

# Non-exponentiated coefficients
coef(summary(log_mod_kick))

# Exponentiated coefficients
exp(-3.171581) # intercept
exp(1.190258) # game_weight (complexity) coefficient
```

### Part d

Interpret each coefficient from Part c in a contextually meaningful way. Is the intercept meaningful in this context?

> Intercept: The odds of a non-kickstarted game being popular is 0.04193724. This is meaningful because it refers to a particular group of games.


> `kickstarted`: Games that are kickstarted have 3.29 times the odds of being popular than games that are not kickstarted.
>
> **Feedback guide:** Students need to interpret the *exponentiated* coefficient in terms of multiplicative changes in odds. They need to say the event associated with the odds (odds *of a game being popular*). They also need to make the reference category clear---if they say "kickstarted games have 3.29 times the odds of being popular", this is incomplete because it doesn't make clear what group kickstarted games are being compared to (non-kickstarted games).

